@article{park2020fully,
  title={Fully automated lung lobe segmentation in volumetric chest CT with 3D U-Net: validation with intra-and extra-datasets},
  author={Park, Jongha and Yun, Jihye and Kim, Namkug and Park, Beomhee and Cho, Yongwon and Park, Hee Jun and Song, Mijeong and Lee, Minho and Seo, Joon Beom},
  journal={Journal of digital imaging},
  volume={33},
  pages={221--230},
  year={2020},
  publisher={Springer}
}

@article{lassen2012automatic,
  title={Automatic segmentation of the pulmonary lobes from chest CT scans based on fissures, vessels, and bronchi},
  author={Lassen, Bianca and van Rikxoort, Eva M and Schmidt, Michael and Kerkstra, Sjoerd and van Ginneken, Bram and Kuhnigk, Jan-Martin},
  journal={IEEE transactions on medical imaging},
  volume={32},
  number={2},
  pages={210--222},
  year={2012},
  publisher={IEEE}
}

@article{steele2012clinical,
  title={Clinical decision rule to predict the presence of interstitial lung disease in systemic sclerosis},
  author={Steele, Russell and Hudson, Marie and Lo, Ernest and Baron, Murray and Canadian Scleroderma Research Group},
  journal={Arthritis care \& research},
  volume={64},
  number={4},
  pages={519--524},
  year={2012},
  publisher={Wiley Online Library}
}

@article{denton2017systemic,
  title={Systemic sclerosis},
  author={Denton, Christopher P and Khanna, Dinesh},
  journal={The Lancet},
  volume={390},
  number={10103},
  pages={1685--1699},
  year={2017},
  publisher={Elsevier}
}

@article{codes2023systemic,
  title={Systemic sclerosis and interstitial lung disease: From pathogenesis, to screening, diagnosis, and classification},
  author={Codes, Helena and Guler, Aslihan Avanoglu and Campochiaro, Corrado and Cerinic, Marco Matucci and Castellvi, Ivan},
  journal={Revista Colombiana de Reumatolog{\'\i}a},
  year={2023},
  publisher={Elsevier}
}

@article{silver2015management,
  title={Management of systemic-sclerosis-associated interstitial lung disease},
  author={Silver, Katherine Culp and Silver, Richard M},
  journal={Rheumatic Disease Clinics},
  volume={41},
  number={3},
  pages={439--457},
  year={2015},
  publisher={Elsevier}
}


@article{showalter2018performance,
  title={Performance of forced vital capacity and lung diffusion cutpoints for associated radiographic interstitial lung disease in systemic sclerosis},
  author={Showalter, Kimberly and Hoffmann, Aileen and Rouleau, Gerald and Aaby, David and Lee, Jungwha and Richardson, Carrie and Dematte, Jane and Agrawal, Rishi and Chang, Rowland W and Hinchcliff, Monique},
  journal={The Journal of rheumatology},
  volume={45},
  number={11},
  pages={1572--1576},
  year={2018},
  publisher={The Journal of Rheumatology}
}



@article{hoffmann2020identification,
  title={The identification and management of interstitial lung disease in systemic sclerosis: evidence-based European consensus statements},
  author={Hoffmann-Vold, Anna-Maria and Maher, Toby M and Philpot, Edward E and Ashrafzadeh, Ali and Barake, Rafic and Barsotti, Simone and Bruni, Cosimo and Carducci, Paolo and Carreira, Patricia E and Castellv{\'\i}, Ivan and others},
  journal={The Lancet Rheumatology},
  volume={2},
  number={2},
  pages={e71--e83},
  year={2020},
  publisher={Elsevier}
}


@article{gerard2018fissurenet,
  title={FissureNet: a deep learning approach for pulmonary fissure detection in CT images},
  author={Gerard, Sarah E and Patton, Taylor J and Christensen, Gary E and Bayouth, John E and Reinhardt, Joseph M},
  journal={IEEE transactions on medical imaging},
  volume={38},
  number={1},
  pages={156--166},
  year={2018},
  publisher={IEEE}
}

@inproceedings{george2017pathological,
  title={Pathological pulmonary lobe segmentation from CT images using progressive holistically nested neural networks and random walker},
  author={George, Kevin and Harrison, Adam P and Jin, Dakai and Xu, Ziyue and Mollura, Daniel J},
  booktitle={International Workshop on Deep Learning in Medical Image Analysis},
  pages={195--203},
  year={2017},
  organization={Springer}
}

@inproceedings{ferreira2018end,
  title={End-to-end supervised lung lobe segmentation},
  author={Ferreira, Filipe T and Sousa, Patrick and Galdran, Adrian and Sousa, Marta R and Campilho, Aur{\'e}lio},
  booktitle={2018 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2018},
  organization={IEEE}
}

@article{chen2019med3d,
  title={Med3d: Transfer learning for 3d medical image analysis},
  author={Chen, Sihong and Ma, Kai and Zheng, Yefeng},
  journal={arXiv preprint arXiv:1904.00625},
  year={2019}
}

@inproceedings{chen2019multi,
  title={Multi-task attention-based semi-supervised learning for medical image segmentation},
  author={Chen, Shuai and Bortsova, Gerda and Garc{\'\i}a-Uceda Ju{\'a}rez, Antonio and Van Tulder, Gijs and De Bruijne, Marleen},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2019: 22nd International Conference, Shenzhen, China, October 13--17, 2019, Proceedings, Part III 22},
  pages={457--465},
  year={2019},
  organization={Springer}
}

@article{mehra2017evaluation,
  title={Evaluation and Monitoring of Respiratory Function},
  author={Mehra, Reena and Walia, Harneet K},
  journal={Sleep Disorders Medicine: Basic Science, Technical Considerations and Clinical Aspects},
  pages={339--352},
  year={2017},
  publisher={Springer}
}

@article{macintyre2005standardisation,
  title={Standardisation of the single-breath determination of carbon monoxide uptake in the lung},
  author={Macintyre, N and Crapo, RO and Viegi, G and Johnson, DC and Van Der Grinten, CPM and Brusasco, V and Burgos, F and Casaburi, R and Coates, A and Enright, P and others},
  journal={European Respiratory Journal},
  volume={26},
  number={4},
  pages={720--735},
  year={2005},
  publisher={Eur Respiratory Soc}
}

@inproceedings{milletari2016v,
  title={V-net: Fully convolutional neural networks for volumetric medical image segmentation},
  author={Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed-Ahmad},
  booktitle={2016 fourth international conference on 3D vision (3DV)},
  pages={565--571},
  year={2016},
  organization={Ieee}
}

@article{jia2020package,
  title={A package to compute segmentation metrics: seg-metrics},
  author={Jia, J},
  journal={online at https://pypi. org/project/seg-metrics},
  year={2020}
}

@article{xiao2016pulmonary,
  title={Pulmonary fissure detection in CT images using a derivative of stick filter},
  author={Xiao, Changyan and Stoel, Berend C and Bakker, M Els and Peng, Yuanyuan and Stolk, Jan and Staring, Marius},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={6},
  pages={1488--1500},
  year={2016},
  publisher={IEEE}
}

@article{nguyen2016using,
  title={Using and interpreting carbon monoxide diffusing capacity (DLCO) correctly},
  author={Nguyen, Lam-Phuong and Harper, Richart W and Louie, Samuel},
  journal={Consultant},
  volume={56},
  number={5},
  pages={440--445},
  year={2016}
}

@article{Zhai2019automatic,
  title={Automatic quantitative analysis of pulmonary vascular morphology in CT images},
  author={Zhai, Zhiwei and Staring, Marius and Hern{\'a}ndez Gir{\'o}n, Irene and Veldkamp, Wouter JH and Kroft, Lucia J and Ninaber, Maarten K and Stoel, Berend C},
  journal={Medical physics},
  volume={46},
  number={9},
  pages={3985--3997},
  year={2019},
  publisher={Wiley Online Library}
}

@article{setio2017validation,
  title={Validation, comparison, and combination of algorithms for automatic detection of pulmonary nodules in computed tomography images: the LUNA16 challenge},
  author={Setio, Arnaud Arindra Adiyoso and Traverso, Alberto and De Bel, Thomas and Berens, Moira SN and Van Den Bogaard, Cas and Cerello, Piergiorgio and Chen, Hao and Dou, Qi and Fantacci, Maria Evelina and Geurts, Bram and others},
  journal={Medical image analysis},
  volume={42},
  pages={1--13},
  year={2017},
  publisher={Elsevier}
}


@inproceedings{zhai2016lung,
  title={Lung vessel segmentation in CT images using graph-cuts},
  author={Zhai, Zhiwei and Staring, Marius and Stoel, Berend C},
  booktitle={Medical Imaging 2016: Image Processing},
  volume={9784},
  pages={699--706},
  year={2016},
  organization={SPIE}
}



@article{Behr2008,
    title = {Pulmonary function tests},
    author = {Behr, JÃ¼rgen and Furst, Daniel E.},
    journal = {Rheumatology},
    number = {suppl\_5},
    pages = {v65--v67},
    publisher = {Oxford Academic},
    volume = {47},
    year = {2008}
}


@article{Caron2018,
author = {Caron, Melissa and Hoa, Sabrina and Hudson, Marie and Schwartzman, Kevin and Steele, Russell},
doi = {10.1183/16000617.0102-2017},
issn = {0905-9180},
journal = {European Respiratory Review},
month = {jun},
number = {148},
pmid = {29769294},
publisher = {European Respiratory Society},
title = {Pulmonary function tests as outcomes for systemic sclerosis interstitial lung disease},
url = {https://err.ersjournals.com/content/27/148/170102 https://err.ersjournals.com/content/27/148/170102.abstract},
volume = {27},
year = {2018}
}

@article{Ninaber2015,
  title={Lung structure and function relation in systemic sclerosis: application of lung densitometry},
  author={Ninaber, Maarten K and Stolk, Jan and Smit, Jasper and Le Roy, Ernest J and Kroft, Lucia JM and Bakker, M Els and de Vries Bouwstra, Jeska K and Schouffoer, Anne A and Staring, Marius and Stoel, Berend C},
  journal={European Journal of Radiology},
  volume={84},
  number={5},
  pages={975--979},
  year={2015},
  publisher={Elsevier}
}

@article{Graham2019,
  title={Standardization of spirometry 2019 update. An official American thoracic society and European respiratory society technical statement},
  author={Graham, Brian L and Steenbruggen, Irene and Miller, Martin R and Barjaktarevic, Igor Z and Cooper, Brendan G and Hall, Graham L and Hallstrand, Teal S and Kaminsky, David A and McCarthy, Kevin and McCormack, Meredith C and others},
  journal={American journal of respiratory and critical care medicine},
  volume={200},
  number={8},
  pages={e70--e88},
  year={2019},
  publisher={American Thoracic Society}
}

@inproceedings{choi2022automated,
  title={Automated Pulmonary Function Measurements from Preoperative CT Scans with Deep Learning},
  author={Choi, Young Sang and Oh, Jieun and Ahn, Seonhui and Hwangbo, Yul and Choi, Jin-Ho},
  booktitle={2022 IEEE-EMBS International Conference on Biomedical and Health Informatics (BHI)},
  pages={01--04},
  year={2022},
  organization={IEEE}
}

@article{McGowan2022,
author = {McGowan, Aisling and Laveneziana, Pierantonio and Bayat, Sam and Beydon, Nicole and Boros, P. W. and Burgos, Felip and Fle{\v{z}}ar, Matja{\v{z}} and Franczuk, Monika and Galarza, Maria Alejandra and Kendrick, Adrian H. and Lombardi, Enrico and Makonga-Braaksma, Jellien and McCormack, Meredith C. and Plantier, Laurent and Stanojevic, Sanja and Steenbruggen, Irene and Thompson, Bruce and Coates, Allan L. and Wanger, Jack and Cockcroft, Donald W. and Culver, Bruce and Sylvester, Karl and {De Jongh}, Frans},
doi = {10.1183/23120541.00602-2021},
issn = {2312-0541},
journal = {ERJ open research},
month = {jan},
number = {1},
pmid = {35261912},
publisher = {ERJ Open Res},
title = {International consensus on lung function testing during the COVID-19 pandemic and beyond},
url = {https://pubmed.ncbi.nlm.nih.gov/35261912/},
volume = {8},
year = {2022}
}

@article{Cooper,
  title={An update on contraindications for lung function testing},
  author={Cooper, Brendan G},
  journal={Thorax},
  volume={66},
  number={8},
  pages={714--723},
  year={2011},
  publisher={BMJ Publishing Group Ltd}
}

@article{Meng2023,
  title={A machine learning approach for preoperatively assessing pulmonary function with computed tomography in patients with lung cancer},
  author={Meng, Hongjia and Liu, Yun and Xu, Xiaoyin and Liao, Yuting and Liang, Hengrui and Chen, Huai},
  journal={Quantitative Imaging in Medicine and Surgery},
  volume={13},
  number={3},
  pages={1510},
  year={2023},
  publisher={AME Publications}
}

@article{Goh2007,
  title={Bronchoalveolar lavage cellular profiles in patients with systemic sclerosis--associated interstitial lung disease are not predictive of disease progression},
  author={Goh, Nicole SL and Veeraraghavan, Srihari and Desai, Sujal R and Cramer, Derek and Hansell, David M and Denton, Christopher P and Black, Carol M and du Bois, Roland M and Wells, Athol U},
  journal={Arthritis \& Rheumatism},
  volume={56},
  number={6},
  pages={2005--2012},
  year={2007},
  publisher={Wiley Online Library}
}

@article{Zhai2019,
  title={Pulmonary vascular morphology associated with gas exchange in systemic sclerosis without lung fibrosis},
  author={Zhai, Zhiwei and Staring, Marius and Ninaber, Maarten K and Vries-Bouwstra, Jeska K de and Schouffoer, Anne A and Kroft, Lucia J and Stolk, Jan and Stoel, Berend C},
  journal={Journal of thoracic imaging},
  volume={34},
  number={6},
  pages={373--379},
  year={2019},
  publisher={Wolters Kluwer}
}

@article{Park2023,
  title={Deep Learning--based Approach to Predict Pulmonary Function at Chest CT},
  author={Park, Hyunjung and Yun, Jihye and Lee, Sang Min and Hwang, Hye Jeon and Seo, Joon Beom and Jung, Young Ju and Hwang, Jeongeun and Lee, Se Hee and Lee, Sei Won and Kim, Namkug},
  journal={Radiology},
  volume={307},
  number={2},
  pages={e221488},
  year={2023},
  publisher={Radiological Society of North America}
}

@article{Miller2005,
  title={Standardisation of spirometry},
  author={Miller, Martin R and Hankinson, JATS and Brusasco, Vito and Burgos, F and Casaburi, R and Coates, A and Crapo, R and Enright, Pvd and Van Der Grinten, CPM and Gustafsson, P and others},
  journal={European respiratory journal},
  volume={26},
  number={2},
  pages={319--338},
  year={2005},
  publisher={Eur Respiratory Soc}
}


@article{Graham2017,
  title={2017 ERS/ATS standards for single-breath carbon monoxide uptake in the lung},
  author={Graham, Brian L and Brusasco, Vito and Burgos, Felip and Cooper, Brendan G and Jensen, Robert and Kendrick, Adrian and MacIntyre, Neil R and Thompson, Bruce R and Wanger, Jack},
  journal={European Respiratory Journal},
  volume={49},
  number={1},
  year={2017},
  publisher={Eur Respiratory Soc}
}

@article{Hall2021,
  title={Official ERS technical standard: Global Lung Function Initiative reference values for static lung volumes in individuals of European ancestry},
  author={Hall, Graham L and Filipow, Nicole and Ruppel, Gregg and Okitika, Tolu and Thompson, Bruce and Kirkby, Jane and Steenbruggen, Irene and Cooper, Brendan G and Stanojevic, Sanja and others},
  journal={European Respiratory Journal},
  volume={57},
  number={3},
  year={2021},
  publisher={Eur Respiratory Soc}
}



@article{Stanojevic2017,
  title={Official ERS technical standards: Global Lung Function Initiative reference values for the carbon monoxide transfer factor for Caucasians},
  author={Stanojevic, Sanja and Graham, Brian L and Cooper, Brendan G and Thompson, Bruce R and Carter, Kim W and Francis, Richard W and Hall, Graham L},
  journal={European Respiratory Journal},
  volume={50},
  number={3},
  year={2017},
  publisher={Eur Respiratory Soc}
}

@article{Quanjer2012,
  doi = {10.1183/09031936.00080312},
  url = {https://doi.org/10.1183/09031936.00080312},
  year = {2012},
  month = jun,
  publisher = {European Respiratory Society ({ERS})},
  volume = {40},
  number = {6},
  pages = {1324--1343},
  author = {Philip H. Quanjer and Sanja Stanojevic and Tim J. Cole and Xaver Baur and Graham L. Hall and Bruce H. Culver and Paul L. Enright and John L. Hankinson and Mary S.M. Ip and Jinping Zheng and Janet Stocks and},
  title = {Multi-ethnic reference values for spirometry for the 3{\textendash}95-yr age range: the global lung function 2012 equations},
  journal = {European Respiratory Journal}
}



@inproceedings{Feichtenhofer,
  title={X3d: Expanding architectures for efficient video recognition},
  author={Feichtenhofer, Christoph},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={203--213},
  year={2020}
}

@article{Cheplygina2019,
  title={Cats or CAT scans: Transfer learning from natural or medical image source data sets?},
  author={Cheplygina, Veronika},
  journal={Current Opinion in Biomedical Engineering},
  volume={9},
  pages={21--27},
  year={2019},
  publisher={Elsevier}
}

@article{Kay,
  title={The kinetics human action video dataset},
  author={Kay, Will and Carreira, Joao and Simonyan, Karen and Zhang, Brian and Hillier, Chloe and Vijayanarasimhan, Sudheendra and Viola, Fabio and Green, Tim and Back, Trevor and Natsev, Paul and others},
  journal={arXiv preprint arXiv:1705.06950},
  year={2017}
}

@inproceedings{Selvaraju,
  title={Grad-cam: Visual explanations from deep networks via gradient-based localization},
  author={Selvaraju, Ramprasaath R and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={618--626},
  year={2017}
}

@article{Schober2018,
  title={Correlation coefficients: appropriate use and interpretation},
  author={Schober, Patrick and Boer, Christa and Schwarte, Lothar A},
  journal={Anesthesia \& analgesia},
  volume={126},
  number={5},
  pages={1763--1768},
  year={2018},
  publisher={Wolters Kluwer}
}

@article{Vallat2018,
  title={Pingouin: statistics in Python.},
  author={Vallat, Raphael},
  journal={J. Open Source Softw.},
  volume={3},
  number={31},
  pages={1026},
  year={2018}
}

@article{Koo2016,
  title={A guideline of selecting and reporting intraclass correlation coefficients for reliability research},
  author={Koo, Terry K and Li, Mae Y},
  journal={Journal of chiropractic medicine},
  volume={15},
  number={2},
  pages={155--163},
  year={2016},
  publisher={Elsevier}
}

@article{Sylvester2020,
  title={ARTP statement on pulmonary function testing 2020},
  author={Sylvester, Karl Peter and Clayton, Nigel and Cliff, Ian and Hepple, Michael and Kendrick, Adrian and Kirkby, Jane and Miller, Martin and Moore, Alan and Rafferty, Gerrard Francis and O'Reilly, Liam and others},
  journal={BMJ Open Respiratory Research},
  volume={7},
  number={1},
  pages={e000575},
  year={2020},
  publisher={Archives of Disease in childhood}
}

@article{LeGouellec2017,
  title={Predictors of lung function test severity and outcome in systemic sclerosis-associated interstitial lung disease},
  author={Le Gouellec, No{\'e}mie and Duhamel, Alain and Perez, Thierry and Hachulla, Anne-Lise and Sobanski, Vincent and Faivre, Jean-Baptiste and Morell-Dubois, Sandrine and Lambert, Marc and Hatron, Pierre-Yves and Hachulla, Eric and others},
  journal={PLoS One},
  volume={12},
  number={8},
  pages={e0181692},
  year={2017},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{Iwano2009,
author = {Iwano, Shingo and Okada, Tohru and Satake, Hiroko and Naganawa, Shinji},
doi = {10.1016/J.ACRA.2008.09.019},
issn = {1076-6332},
journal = {Academic Radiology},
keywords = {3D image,Computed tomography,lung density,lung neoplasms,pulmonary function},
month = {mar},
number = {3},
pages = {250--256},
pmid = {19201353},
publisher = {Elsevier},
title = {3D-CT Volumetry of the Lung Using Multidetector Row CT: Comparison with Pulmonary Function Tests},
volume = {16},
year = {2009}
}

@misc{vallejos2020association,
  title={Association of FVC/DLCO with pulmonary hypertension risk and interstitial disease in systemic sclerosis patients},
  author={Vallejos, Eva Ail{\'\i}n and Martinez, John and Cabrera, Florencia and Mastandrea, Noelia and Pertuz, Milerna and Marengo, Zullie and Meiller, M Jos{\'e} L{\'o}pez and Volberg, Veronica and Tejada, Ricardo G{\'o}mez},
  year={2020},
  publisher={Eur Respiratory Soc}
}


@article{wang2017diabetic,
  title={Diabetic retinopathy detection via deep convolutional networks for discriminative localization and visual explanation},
  author={Wang, Zhiguang and Yang, Jianbo},
  journal={arXiv preprint arXiv:1703.10757},
  year={2017}
}








































@article{Carreira,
abstract = {The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks. This paper re-evaluates state-of-the-art architec-tures in light of the new Kinetics Human Action Video dataset. Kinetics has two orders of magnitude more data, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos. We provide an analysis on how current architectures fare on the task of action classification on this dataset and how much performance improves on the smaller benchmark datasets after pre-training on Kinetics. We also introduce a new Two-Stream Inflated 3D Con-vNet (I3D) that is based on 2D ConvNet inflation: filters and pooling kernels of very deep image classification ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters. We show that, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.9% on HMDB-51 and 98.0% on UCF-101.},
archivePrefix = {arXiv},
arxivId = {1705.07750v3},
author = {Carreira, Jo{\~{a}}o and Zisserman, Andrew and Com, Zisserman@google and Deepmind, â },
eprint = {1705.07750v3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Carreira et al. - Unknown - Quo Vadis, Action Recognition A New Model and the Kinetics Dataset.pdf:pdf},
title = {{Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset}}
}
@article{Siami-Namini2019,
abstract = {Machine and deep learning-based algorithms are the emerging approaches in addressing prediction problems in time series. These techniques have been shown to produce more accurate results than conventional regression-based modeling. It has been reported that artificial Recurrent Neural Networks (RNN) with memory, such as Long Short-Term Memory (LSTM), are superior compared to Autoregressive Integrated Moving Average (ARIMA) with a large margin. The LSTM-based models incorporate additional 'gates' for the purpose of memorizing longer sequences of input data. The major question is that whether the gates incorporated in the LSTM architecture already offers a good prediction and whether additional training of data would be necessary to further improve the prediction. Bidirectional LSTMs (BiLSTMs) enable additional training by traversing the input data twice (i.e., 1) left-to-right, and 2) right-to-left). The research question of interest is then whether BiLSTM, with additional training capability, outperforms regular unidirectional LSTM. This paper reports a behavioral analysis and comparison of BiLSTM and LSTM models. The objective is to explore to what extend additional layers of training of data would be beneficial to tune the involved parameters. The results show that additional training of data and thus BiLSTM-based modeling offers better predictions than regular LSTM-based models. More specifically, it was observed that BiLSTM models provide better predictions compared to ARIMA and LSTM models. It was also observed that BiLSTM models reach the equilibrium much slower than LSTM-based models.},
author = {Siami-Namini, Sima and Tavakoli, Neda and Namin, Akbar Siami},
doi = {10.1109/BIGDATA47090.2019.9005997},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Siami-Namini, Tavakoli, Namin - 2019 - The Performance of LSTM and BiLSTM in Forecasting Time Series.pdf:pdf},
isbn = {9781728108582},
journal = {Proceedings - 2019 IEEE International Conference on Big Data, Big Data 2019},
month = {dec},
pages = {3285--3292},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The Performance of LSTM and BiLSTM in Forecasting Time Series}},
year = {2019}
}
@article{Isensee2020,
abstract = {Biomedical imaging is a driver of scientific discovery and a core component of medical care and is being stimulated by the field of deep learning. While semantic segmentation algorithms enable image analysis and quantification in many applications, the design of respective specialized solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We developed nnU-Net, a deep learning-based segmentation method that automatically configures itself, including preprocessing, network architecture, training and post-processing for any new task. The key design choices in this process are modeled as a set of fixed parameters, interdependent rules and empirical decisions. Without manual intervention, nnU-Net surpasses most existing approaches, including highly specialized solutions on 23 public datasets used in international biomedical segmentation competitions. We make nnU-Net publicly available as an out-of-the-box tool, rendering state-of-the-art segmentation accessible to a broad audience by requiring neither expert knowledge nor computing resources beyond standard network training. nnU-Net is a deep learning-based image segmentation method that automatically configures itself for diverse biological and medical image segmentation tasks. nnU-Net offers state-of-the-art performance as an out-of-the-box tool.},
author = {Isensee, Fabian and Jaeger, Paul F. and Kohl, Simon A.A. and Petersen, Jens and Maier-Hein, Klaus H.},
doi = {10.1038/s41592-020-01008-z},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Isensee et al. - 2020 - nnU-Net a self-configuring method for deep learning-based biomedical image segmentation.pdf:pdf},
issn = {1548-7105},
journal = {Nature Methods 2020 18:2},
keywords = {Image processing,Translational research},
month = {dec},
number = {2},
pages = {203--211},
pmid = {33288961},
publisher = {Nature Publishing Group},
title = {{nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation}},
url = {https://www.nature.com/articles/s41592-020-01008-z},
volume = {18},
year = {2020}
}
@article{Yang,
abstract = {Figure 1: 3D models of intracranial aneurysm segments with segmentation annotation in our dataset. Hot pink shows the healthy blood vessel part, and aqua shows the aneurysm part for each model. Abstract Medicine is an important application area for deep learning models. Research in this field is a combination of medical expertise and data science knowledge. In this paper, instead of 2D medical images, we introduce an open-access 3D intracranial aneurysm dataset, IntrA, that makes the application of points-based and mesh-based classification and segmentation models available. Our dataset can be used to diagnose intracranial aneurysms and to extract the neck for a clipping operation in medicine and other areas of deep learning, such as normal estimation and surface reconstruction. We provide a large-scale benchmark of classification and part segmentation by testing state-of-the-art networks. We also discuss the performance of each method and demonstrate the challenges of our dataset. The published dataset can be accessed here: https://github.com/intra3d2019/IntrA.},
author = {Yang, Xi and Xia, Ding and Kin, Taichi and Igarashi, Takeo},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang et al. - Unknown - IntrA 3D Intracranial Aneurysm Dataset for Deep Learning.pdf:pdf},
title = {{IntrA: 3D Intracranial Aneurysm Dataset for Deep Learning}},
url = {https://github.com/intra3d2019/IntrA.}
}
@article{Jia2023,
abstract = {The COVID-19 pandemic has extremely threatened human health, and automated algorithms are needed to segment infected regions in the lung using computed tomography (CT). Although several deep convolutional neural networks (DCNNs) have proposed for this purpose, their performance on this task is suppressed due to the limited local receptive field and deficient global reasoning ability. To address these issues, we propose a segmentation network with a novel pixel-wise sparse graph reasoning (PSGR) module for the segmentation of COVID-19 infected regions in CT images. The PSGR module, which is inserted between the encoder and decoder of the network, can improve the modeling of global contextual information. In the PSGR module, a graph is first constructed by projecting each pixel on a node based on the features produced by the encoder. Then, we convert the graph into a sparsely-connected one by keeping K strongest connections to each uncertainly segmented pixel. Finally, the global reasoning is performed on the sparsely-connected graph. Our segmentation network was evaluated on three publicly available datasets and compared with a variety of widely-used segmentation models. Our results demonstrate that (1) the proposed PSGR module can capture the long-range dependencies effectively and (2) the segmentation model equipped with this PSGR module can accurately segment COVID-19 infected regions in CT images and outperform all other competing models.},
author = {Jia, Haozhe and Tang, Haoteng and Ma, Guixiang and Cai, Weidong and Huang, Heng and Zhan, Liang and Xia, Yong},
doi = {10.1016/J.COMPBIOMED.2023.106698},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - 2023 - A convolutional neural network with pixel-wise sparse graph reasoning for COVID-19 lesion segmentation in CT images.pdf:pdf},
issn = {0010-4825},
journal = {Computers in Biology and Medicine},
keywords = {COVID-19 pneumonia segmentation,Global reasoning,Long range dependencies,Sparse graph},
month = {mar},
pages = {106698},
pmid = {36842219},
publisher = {Pergamon},
title = {{A convolutional neural network with pixel-wise sparse graph reasoning for COVID-19 lesion segmentation in CT images}},
volume = {155},
year = {2023}
}
@article{Guo2021,
abstract = {Point cloud learning has lately attracted increasing attention due to its wide applications in many areas, such as computer vision, autonomous driving, and robotics. As a dominating technique in AI, deep learning has been successfully used to solve various 2D vision problems. However, deep learning on point clouds is still in its infancy due to the unique challenges faced by the processing of point clouds with deep neural networks. Recently, deep learning on point clouds has become even thriving, with numerous methods being proposed to address different problems in this area. To stimulate future research, this paper presents a comprehensive review of recent progress in deep learning methods for point clouds. It covers three major tasks, including 3D shape classification, 3D object detection and tracking, and 3D point cloud segmentation. It also presents comparative results on several publicly available datasets, together with insightful observations and inspiring future research directions.},
archivePrefix = {arXiv},
arxivId = {1912.12033},
author = {Guo, Yulan and Wang, Hanyun and Hu, Qingyong and Liu, Hao and Liu, Li and Bennamoun, Mohammed},
doi = {10.1109/TPAMI.2020.3005434},
eprint = {1912.12033},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guo et al. - 2021 - Deep Learning for 3D Point Clouds A Survey.pdf:pdf},
issn = {19393539},
journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
keywords = {3D data,Deep learning,instance segmentation,object detection,object tracking,part segmentation,point clouds,scene flow,semantic segmentation,shape classification,shape retrieval},
month = {dec},
number = {12},
pages = {4338--4364},
pmid = {32750799},
publisher = {IEEE Computer Society},
title = {{Deep Learning for 3D Point Clouds: A Survey}},
volume = {43},
year = {2021}
}
@article{Zhuang2022,
abstract = {With the rapid advancement of medical imaging technologies, the high-resolution CT image data is becoming increasingly valuable for both medical research and clinical diagnosis. The paper takes lung CT image as an example. Retrieving images similar to the input one can help physicians with clinical diagnosis. In comparison to traditional content-based image retrieval, similarity retrieval of lung CT images requires higher retrieval accuracy, with similar requirements in external shape as well as internal vascular and lesion location similarity. In the state-of-the-art supervised deep learning networks, the learning of the network is based on labeling. The labeling of medical images, however, requires time and effort from professionals to label each image, which is prohibitively expensive. In this paper, we propose a weakly supervised deep learning network model for similarity analysis of lung CT images that is called a Weakly Supervised s imilarity Analysis Network (WSAN). Extensive experiments show that the WSAN model achieves satisfactory results in measuring the similarity between lung CT images and can be used for similarity retrieval tasks.},
author = {Zhuang, Yi and Jiang, Nan and Chen, Shuai},
doi = {10.1109/ACCESS.2022.3174099},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhuang, Jiang, Chen - 2022 - WSAN An Effective Model of Weakly Supervised Similarity Analysis Network for the Lung CT Images.pdf:pdf},
issn = {21693536},
journal = {IEEE Access},
keywords = {CT$\sim$image,Content-based retrieval,deep learning,similarity retrieval},
pages = {53777--53787},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{WSAN: An Effective Model of Weakly Supervised Similarity Analysis Network for the Lung CT Images}},
volume = {10},
year = {2022}
}
@article{SchweitzerPASCAL2011,
abstract = {In this article, we propose a family of efficient kernels for large graphs with discrete node labels. Key to our method is a rapid feature extraction scheme based on the Weisfeiler-Lehman test of isomorphism on graphs. It maps the original graph to a sequence of graphs, whose node attributes capture topological and label information. A family of kernels can be defined based on this Weisfeiler-Lehman sequence of graphs, including a highly efficient kernel comparing subtree-like patterns. Its runtime scales only linearly in the number of edges of the graphs and the length of the Weisfeiler-Lehman graph sequence. In our experimental evaluation, our kernels outperform state-of-the-art graph kernels on several graph classification benchmark data sets in terms of accuracy and runtime. Our kernels open the door to large-scale applications of graph kernels in various disciplines such as computational biology and social network analysis.},
author = {{Schweitzer PASCAL}, Pascal and {Jan van Leeuwen EJVANLEEUWEN}, Erik and Shervashidze, Nino and Schweitzer, Pascal and {Jan van Leeuwen}, Erik and Mehlhorn, Kurt and {Borgwardt SHERVASHIDZE}, Karsten M and Leeuwen, Van},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Schweitzer PASCAL et al. - 2011 - Weisfeiler-Lehman Graph Kernels Nino Shervashidze Kurt Mehlhorn Karsten M. Borgwardt.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Weisfeiler-Lehman algorithm,graph classification,graph kernels,similarity measures for graphs},
pages = {2539--2561},
title = {{Weisfeiler-Lehman Graph Kernels Nino Shervashidze Kurt Mehlhorn Karsten M. Borgwardt}},
volume = {12},
year = {2011}
}
@article{Defferrard2016,
abstract = {In this work, we are interested in generalizing convolutional neural networks
(CNNs) from low-dimensional regular grids, where image, video and speech are
represented, to high-dimensional irregular domains, such as social networks,
brain connectomes or words' embedding, represented by graphs. We present a
formulation of CNNs in the context of spectral graph theory, which provides the
necessary mathematical background and efficient numerical schemes to design
fast localized convolutional filters on graphs. Importantly, the proposed
technique offers the same linear computational complexity and constant learning
complexity as classical CNNs, while being universal to any graph structure.
Experiments on MNIST and 20NEWS demonstrate the ability of this novel deep
learning system to learn local, stationary, and compositional features on
graphs.},
archivePrefix = {arXiv},
arxivId = {1606.09375},
author = {Defferrard, Micha{\"{e}}l and Bresson, Xavier and Vandergheynst, Pierre},
eprint = {1606.09375},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Defferrard, Bresson, Vandergheynst - 2016 - Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {jun},
pages = {3844--3852},
publisher = {Neural information processing systems foundation},
title = {{Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering}},
url = {https://arxiv.org/abs/1606.09375v3},
year = {2016}
}
@article{vaswani2017attention,
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
journal = {Advances in neural information processing systems},
title = {{Attention is all you need}},
volume = {30},
year = {2017}
}
@article{Hu2019,
abstract = {The convolution layer has been the dominant feature extractor in computer
vision for years. However, the spatial aggregation in convolution is basically
a pattern matching process that applies fixed filters which are inefficient at
modeling visual elements with varying spatial distributions. This paper
presents a new image feature extractor, called the local relation layer, that
adaptively determines aggregation weights based on the compositional
relationship of local pixel pairs. With this relational approach, it can
composite visual elements into higher-level entities in a more efficient manner
that benefits semantic inference. A network built with local relation layers,
called the Local Relation Network (LR-Net), is found to provide greater
modeling capacity than its counterpart built with regular convolution on
large-scale recognition tasks such as ImageNet classification.},
archivePrefix = {arXiv},
arxivId = {1904.11491},
author = {Hu, Han and Zhang, Zheng and Xie, Zhenda and Lin, Stephen},
doi = {10.1109/ICCV.2019.00356},
eprint = {1904.11491},
isbn = {9781728148038},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
month = {apr},
pages = {3463--3472},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Local Relation Networks for Image Recognition}},
url = {https://arxiv.org/abs/1904.11491v1},
volume = {2019-October},
year = {2019}
}
@article{Carreira2017,
abstract = {The paucity of videos in current action classification datasets (UCF-101 and
HMDB-51) has made it difficult to identify good video architectures, as most
methods obtain similar performance on existing small-scale benchmarks. This
paper re-evaluates state-of-the-art architectures in light of the new Kinetics
Human Action Video dataset. Kinetics has two orders of magnitude more data,
with 400 human action classes and over 400 clips per class, and is collected
from realistic, challenging YouTube videos. We provide an analysis on how
current architectures fare on the task of action classification on this dataset
and how much performance improves on the smaller benchmark datasets after
pre-training on Kinetics. We also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on
2D ConvNet inflation: filters and pooling kernels of very deep image
classification ConvNets are expanded into 3D, making it possible to learn
seamless spatio-temporal feature extractors from video while leveraging
successful ImageNet architecture designs and even their parameters. We show
that, after pre-training on Kinetics, I3D models considerably improve upon the
state-of-the-art in action classification, reaching 80.9% on HMDB-51 and 98.0%
on UCF-101.},
archivePrefix = {arXiv},
arxivId = {1705.07750},
author = {Carreira, Jo{\~{a}}o and Zisserman, Andrew and Com, Zisserman@google and Deepmind, â },
doi = {10.1109/CVPR.2017.502},
eprint = {1705.07750},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
month = {may},
pages = {4724--4733},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset}},
url = {https://arxiv.org/abs/1705.07750v3},
volume = {2017-January},
year = {2017}
}
@article{Qian2022,
abstract = {PointNet++ is one of the most influential neural architectures for point
cloud understanding. Although the accuracy of PointNet++ has been largely
surpassed by recent networks such as PointMLP and Point Transformer, we find
that a large portion of the performance gain is due to improved training
strategies, i.e. data augmentation and optimization techniques, and increased
model sizes rather than architectural innovations. Thus, the full potential of
PointNet++ has yet to be explored. In this work, we revisit the classical
PointNet++ through a systematic study of model training and scaling strategies,
and offer two major contributions. First, we propose a set of improved training
strategies that significantly improve PointNet++ performance. For example, we
show that, without any change in architecture, the overall accuracy (OA) of
PointNet++ on ScanObjectNN object classification can be raised from 77.9% to
86.1%, even outperforming state-of-the-art PointMLP. Second, we introduce an
inverted residual bottleneck design and separable MLPs into PointNet++ to
enable efficient and effective model scaling and propose PointNeXt, the next
version of PointNets. PointNeXt can be flexibly scaled up and outperforms
state-of-the-art methods on both 3D classification and segmentation tasks. For
classification, PointNeXt reaches an overall accuracy of 87.7 on ScanObjectNN,
surpassing PointMLP by 2.3%, while being 10x faster in inference. For semantic
segmentation, PointNeXt establishes a new state-of-the-art performance with
74.9% mean IoU on S3DIS (6-fold cross-validation), being superior to the recent
Point Transformer. The code and models are available at
https://github.com/guochengqian/pointnext.},
archivePrefix = {arXiv},
arxivId = {2206.04670},
author = {Qian, Guocheng and Li, Yuchen and Peng, Houwen and Mai, Jinjie and Hammoud, Hasan Abed Al Kader and Elhoseiny, Mohamed and Ghanem, Bernard},
eprint = {2206.04670},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qian et al. - 2022 - PointNeXt Revisiting PointNet with Improved Training and Scaling Strategies.pdf:pdf},
isbn = {9781713871088},
issn = {10495258},
month = {jun},
title = {{PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies}},
url = {https://arxiv.org/abs/2206.04670v2},
year = {2022}
}
@article{Zhao2020,
abstract = {Self-attention networks have revolutionized natural language processing and
are making impressive strides in image analysis tasks such as image
classification and object detection. Inspired by this success, we investigate
the application of self-attention networks to 3D point cloud processing. We
design self-attention layers for point clouds and use these to construct
self-attention networks for tasks such as semantic scene segmentation, object
part segmentation, and object classification. Our Point Transformer design
improves upon prior work across domains and tasks. For example, on the
challenging S3DIS dataset for large-scale semantic scene segmentation, the
Point Transformer attains an mIoU of 70.4% on Area 5, outperforming the
strongest prior model by 3.3 absolute percentage points and crossing the 70%
mIoU threshold for the first time.},
archivePrefix = {arXiv},
arxivId = {2012.09164},
author = {Zhao, Hengshuang and Jiang, Li and Jia, Jiaya and Torr, Philip and Koltun, Vladlen},
doi = {10.1109/ICCV48922.2021.01595},
eprint = {2012.09164},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2020 - Point Transformer.pdf:pdf},
isbn = {9781665428125},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
month = {dec},
pages = {16239--16248},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Point Transformer}},
url = {https://arxiv.org/abs/2012.09164v2},
year = {2020}
}
@article{Li,
abstract = {We present a simple and general framework for feature learning from point clouds. The key to the success of CNNs is the convolution operator that is capable of leveraging spatially-local correlation in data represented densely in grids (e.g. images). However, point clouds are irregular and unordered, thus directly convolving kernels against features associated with the points will result in desertion of shape information and variance to point ordering. To address these problems, we propose to learn an X-transformation from the input points to simultaneously promote two causes: the first is the weighting of the input features associated with the points, and the second is the permutation of the points into a latent and potentially canonical order. Element-wise product and sum operations of the typical convolution operator are subsequently applied on the X-transformed features. The proposed method is a generalization of typical CNNs to feature learning from point clouds, thus we call it PointCNN. Experiments show that PointCNN achieves on par or better performance than state-of-the-art methods on multiple challenging benchmark datasets and tasks.},
archivePrefix = {arXiv},
arxivId = {1801.07791v5},
author = {Li, Yangyan and Bu, Rui and Sun, Mingchao and Wu, Wei and Di, Xinhan and Chen, Baoquan},
eprint = {1801.07791v5},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - Unknown - PointCNN Convolution On X-Transformed Points.pdf:pdf},
title = {{PointCNN: Convolution On X-Transformed Points}}
}
@article{Ma2022,
abstract = {Point cloud analysis is challenging due to irregularity and unordered data
structure. To capture the 3D geometries, prior works mainly rely on exploring
sophisticated local geometric extractors using convolution, graph, or attention
mechanisms. These methods, however, incur unfavorable latency during inference,
and the performance saturates over the past few years. In this paper, we
present a novel perspective on this task. We notice that detailed local
geometrical information probably is not the key to point cloud analysis -- we
introduce a pure residual MLP network, called PointMLP, which integrates no
sophisticated local geometrical extractors but still performs very
competitively. Equipped with a proposed lightweight geometric affine module,
PointMLP delivers the new state-of-the-art on multiple datasets. On the
real-world ScanObjectNN dataset, our method even surpasses the prior best
method by 3.3% accuracy. We emphasize that PointMLP achieves this strong
performance without any sophisticated operations, hence leading to a superior
inference speed. Compared to most recent CurveNet, PointMLP trains 2x faster,
tests 7x faster, and is more accurate on ModelNet40 benchmark. We hope our
PointMLP may help the community towards a better understanding of point cloud
analysis. The code is available at https://github.com/ma-xu/pointMLP-pytorch.},
archivePrefix = {arXiv},
arxivId = {2202.07123},
author = {Ma, Xu and Qin, Can and You, Haoxuan and Ran, Haoxi and Fu, Yun},
eprint = {2202.07123},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ma et al. - 2022 - Rethinking Network Design and Local Geometry in Point Cloud A Simple Residual MLP Framework.pdf:pdf},
journal = {ICLR 2022 - 10th International Conference on Learning Representations},
month = {feb},
publisher = {International Conference on Learning Representations, ICLR},
title = {{Rethinking Network Design and Local Geometry in Point Cloud: A Simple Residual MLP Framework}},
url = {https://arxiv.org/abs/2202.07123v2},
year = {2022}
}
@article{Park2020,
abstract = {After stroke, limited ribcage movement may lead to impaired respiratory function. Combining threshold inspiratory muscle training with rib cage joint mobilization has been shown to enhance the recovery of respiratory function in patients with stroke. The present study investigated whether the combination of rib cage joint mobilization and inspiratory muscle training would improve chest expansion, inspiratory muscle activity, and pulmonary function after stroke. Thirty stroke patients were recruited and randomly assigned to one of the two groups, namely 6-week rib cage joint mobilization with inspiratory muscle training (experimental group) or inspiratory muscle training alone (control group). Outcome measures included upper and lower chest expansion, activity of accessory inspiratory muscles (latissimus dorsi (LD) and upper trapezius (UT)), and pulmonary function (forced vital capacity (FVC), forced expiratory volume in 1 s (FEV1), and peak expiratory flow (PEF)). All evaluations were conducted at baseline and after 6 weeks of inspiratory muscle training. Significant increases were observed in upper and lower chest expansion, LD and UT muscle activity, FVC, FEV1, and PEF in both the groups. Upper and lower chest expansion and muscle activity of UT and LD were significantly higher in the experimental group than in the control group. No significant differences were observed in FVC, FEV1, and PEF between the groups. Inspiratory muscle training is effective in improving chest expansion, inspiratory muscle activity, and pulmonary function after stroke. The addition of rib cage joint mobilization further increases chest expansion and inspiratory muscle activity.},
author = {Park, Shin Jun},
doi = {10.3390/APP10155178},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Park - 2020 - Effects of Inspiratory Muscles Training Plus Rib Cage Mobilization on Chest Expansion, Inspiratory Accessory Muscles Activ.pdf:pdf},
issn = {2076-3417},
journal = {Applied Sciences 2020, Vol. 10, Page 5178},
keywords = {chest expansion,inspiratory muscle training,joint mobilization,muscle activity,pulmonary function},
month = {jul},
number = {15},
pages = {5178},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{Effects of Inspiratory Muscles Training Plus Rib Cage Mobilization on Chest Expansion, Inspiratory Accessory Muscles Activity and Pulmonary Function in Stroke Patients}},
url = {https://www.mdpi.com/2076-3417/10/15/5178/htm https://www.mdpi.com/2076-3417/10/15/5178},
volume = {10},
year = {2020}
}
@article{Zhou2020,
abstract = {Graph neural networks (GNNs), which learn the representation of a node by
aggregating its neighbors, have become an effective computational tool in
downstream applications. Over-smoothing is one of the key issues which limit
the performance of GNNs as the number of layers increases. It is because the
stacked aggregators would make node representations converge to
indistinguishable vectors. Several attempts have been made to tackle the issue
by bringing linked node pairs close and unlinked pairs distinct. However, they
often ignore the intrinsic community structures and would result in sub-optimal
performance. The representations of nodes within the same community/class need
be similar to facilitate the classification, while different classes are
expected to be separated in embedding space. To bridge the gap, we introduce
two over-smoothing metrics and a novel technique, i.e., differentiable group
normalization (DGN). It normalizes nodes within the same group independently to
increase their smoothness, and separates node distributions among different
groups to significantly alleviate the over-smoothing issue. Experiments on
real-world datasets demonstrate that DGN makes GNN models more robust to
over-smoothing and achieves better performance with deeper GNNs.},
archivePrefix = {arXiv},
arxivId = {2006.06972},
author = {Zhou, Kaixiong and Huang, Xiao and Li, Yuening and Zha, Daochen and Chen, Rui and Hu, Xia},
eprint = {2006.06972},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2020 - Towards Deeper Graph Neural Networks with Differentiable Group Normalization.pdf:pdf},
isbn = {2006.06972v1},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
month = {jun},
publisher = {Neural information processing systems foundation},
title = {{Towards Deeper Graph Neural Networks with Differentiable Group Normalization}},
url = {https://arxiv.org/abs/2006.06972v1},
volume = {2020-December},
year = {2020}
}
@article{Cai2020a,
abstract = {Normalization is known to help the optimization of deep neural networks.
Curiously, different architectures require specialized normalization methods.
In this paper, we study what normalization is effective for Graph Neural
Networks (GNNs). First, we adapt and evaluate the existing methods from other
domains to GNNs. Faster convergence is achieved with InstanceNorm compared to
BatchNorm and LayerNorm. We provide an explanation by showing that InstanceNorm
serves as a preconditioner for GNNs, but such preconditioning effect is weaker
with BatchNorm due to the heavy batch noise in graph datasets. Second, we show
that the shift operation in InstanceNorm results in an expressiveness
degradation of GNNs for highly regular graphs. We address this issue by
proposing GraphNorm with a learnable shift. Empirically, GNNs with GraphNorm
converge faster compared to GNNs using other normalization. GraphNorm also
improves the generalization of GNNs, achieving better performance on graph
classification benchmarks.},
archivePrefix = {arXiv},
arxivId = {2009.03294},
author = {Cai, Tianle and Luo, Shengjie and Xu, Keyulu and He, Di and Liu, Tie Yan and Wang, Liwei},
eprint = {2009.03294},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai et al. - 2020 - GraphNorm A Principled Approach to Accelerating Graph Neural Network Training.pdf:pdf},
isbn = {9781713845065},
issn = {26403498},
journal = {Proceedings of Machine Learning Research},
month = {sep},
pages = {1204--1215},
publisher = {ML Research Press},
title = {{GraphNorm: A Principled Approach to Accelerating Graph Neural Network Training}},
url = {https://arxiv.org/abs/2009.03294v3},
volume = {139},
year = {2020}
}
@article{Ba2016,
abstract = {Training state-of-the-art, deep neural networks is computationally expensive.
One way to reduce the training time is to normalize the activities of the
neurons. A recently introduced technique called batch normalization uses the
distribution of the summed input to a neuron over a mini-batch of training
cases to compute a mean and variance which are then used to normalize the
summed input to that neuron on each training case. This significantly reduces
the training time in feed-forward neural networks. However, the effect of batch
normalization is dependent on the mini-batch size and it is not obvious how to
apply it to recurrent neural networks. In this paper, we transpose batch
normalization into layer normalization by computing the mean and variance used
for normalization from all of the summed inputs to the neurons in a layer on a
single training case. Like batch normalization, we also give each neuron its
own adaptive bias and gain which are applied after the normalization but before
the non-linearity. Unlike batch normalization, layer normalization performs
exactly the same computation at training and test times. It is also
straightforward to apply to recurrent neural networks by computing the
normalization statistics separately at each time step. Layer normalization is
very effective at stabilizing the hidden state dynamics in recurrent networks.
Empirically, we show that layer normalization can substantially reduce the
training time compared with previously published techniques.},
archivePrefix = {arXiv},
arxivId = {1607.06450},
author = {Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E.},
eprint = {1607.06450},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ba, Kiros, Hinton - 2016 - Layer Normalization.pdf:pdf},
month = {jul},
title = {{Layer Normalization}},
url = {https://arxiv.org/abs/1607.06450v1},
year = {2016}
}
@article{Ulyanov2016,
abstract = {It this paper we revisit the fast stylization method introduced in Ulyanov
et. al. (2016). We show how a small change in the stylization architecture
results in a significant qualitative improvement in the generated images. The
change is limited to swapping batch normalization with instance normalization,
and to apply the latter both at training and testing times. The resulting
method can be used to train high-performance architectures for real-time image
generation. The code will is made available on github at
https://github.com/DmitryUlyanov/texture_nets. Full paper can be found at
arXiv:1701.02096.},
archivePrefix = {arXiv},
arxivId = {1607.08022},
author = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
eprint = {1607.08022},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ulyanov, Vedaldi, Lempitsky - 2016 - Instance Normalization The Missing Ingredient for Fast Stylization.pdf:pdf},
month = {jul},
title = {{Instance Normalization: The Missing Ingredient for Fast Stylization}},
url = {https://arxiv.org/abs/1607.08022v3},
year = {2016}
}
@article{Ioffe2015,
abstract = {Training Deep Neural Networks is complicated by the fact that the
distribution of each layer's inputs changes during training, as the parameters
of the previous layers change. This slows down the training by requiring lower
learning rates and careful parameter initialization, and makes it notoriously
hard to train models with saturating nonlinearities. We refer to this
phenomenon as internal covariate shift, and address the problem by normalizing
layer inputs. Our method draws its strength from making normalization a part of
the model architecture and performing the normalization for each training
mini-batch. Batch Normalization allows us to use much higher learning rates and
be less careful about initialization. It also acts as a regularizer, in some
cases eliminating the need for Dropout. Applied to a state-of-the-art image
classification model, Batch Normalization achieves the same accuracy with 14
times fewer training steps, and beats the original model by a significant
margin. Using an ensemble of batch-normalized networks, we improve upon the
best published result on ImageNet classification: reaching 4.9% top-5
validation error (and 4.8% test error), exceeding the accuracy of human raters.},
archivePrefix = {arXiv},
arxivId = {1502.03167},
author = {Ioffe, Sergey and Szegedy, Christian},
eprint = {1502.03167},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ioffe, Szegedy - 2015 - Batch Normalization Accelerating Deep Network Training by Reducing Internal Covariate Shift.pdf:pdf},
isbn = {9781510810587},
journal = {32nd International Conference on Machine Learning, ICML 2015},
keywords = {()},
month = {feb},
pages = {448--456},
publisher = {International Machine Learning Society (IMLS)},
title = {{Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift}},
url = {https://arxiv.org/abs/1502.03167v3},
volume = {1},
year = {2015}
}
@article{Morris2018,
abstract = {In recent years, graph neural networks (GNNs) have emerged as a powerful
neural architecture to learn vector representations of nodes and graphs in a
supervised, end-to-end fashion. Up to now, GNNs have only been evaluated
empirically -- showing promising results. The following work investigates GNNs
from a theoretical point of view and relates them to the $1$-dimensional
Weisfeiler-Leman graph isomorphism heuristic ($1$-WL). We show that GNNs have
the same expressiveness as the $1$-WL in terms of distinguishing non-isomorphic
(sub-)graphs. Hence, both algorithms also have the same shortcomings. Based on
this, we propose a generalization of GNNs, so-called $k$-dimensional GNNs
($k$-GNNs), which can take higher-order graph structures at multiple scales
into account. These higher-order structures play an essential role in the
characterization of social networks and molecule graphs. Our experimental
evaluation confirms our theoretical findings as well as confirms that
higher-order information is useful in the task of graph classification and
regression.},
archivePrefix = {arXiv},
arxivId = {1810.02244},
author = {Morris, Christopher and Ritzert, Martin and Fey, Matthias and Hamilton, William L. and Lenssen, Jan Eric and Rattan, Gaurav and Grohe, Martin},
doi = {10.1609/aaai.v33i01.33014602},
eprint = {1810.02244},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Morris et al. - 2018 - Weisfeiler and Leman Go Neural Higher-order Graph Neural Networks.pdf:pdf},
isbn = {9781577358091},
issn = {2159-5399},
journal = {33rd AAAI Conference on Artificial Intelligence, AAAI 2019, 31st Innovative Applications of Artificial Intelligence Conference, IAAI 2019 and the 9th AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2019},
month = {oct},
pages = {4602--4609},
publisher = {AAAI Press},
title = {{Weisfeiler and Leman Go Neural: Higher-order Graph Neural Networks}},
url = {https://arxiv.org/abs/1810.02244v5},
year = {2018}
}
@article{Wu2019,
abstract = {Graph Convolutional Networks (GCNs) and their variants have experienced
significant attention and have become the de facto methods for learning graph
representations. GCNs derive inspiration primarily from recent deep learning
approaches, and as a result, may inherit unnecessary complexity and redundant
computation. In this paper, we reduce this excess complexity through
successively removing nonlinearities and collapsing weight matrices between
consecutive layers. We theoretically analyze the resulting linear model and
show that it corresponds to a fixed low-pass filter followed by a linear
classifier. Notably, our experimental evaluation demonstrates that these
simplifications do not negatively impact accuracy in many downstream
applications. Moreover, the resulting model scales to larger datasets, is
naturally interpretable, and yields up to two orders of magnitude speedup over
FastGCN.},
archivePrefix = {arXiv},
arxivId = {1902.07153},
author = {Wu, Felix and Zhang, Tianyi and de Souza, Amauri Holanda and Fifty, Christopher and Yu, Tao and Weinberger, Kilian Q.},
eprint = {1902.07153},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wu et al. - 2019 - Simplifying Graph Convolutional Networks.pdf:pdf},
isbn = {9781510886988},
journal = {36th International Conference on Machine Learning, ICML 2019},
month = {feb},
pages = {11884--11894},
publisher = {International Machine Learning Society (IMLS)},
title = {{Simplifying Graph Convolutional Networks}},
url = {https://arxiv.org/abs/1902.07153v2},
volume = {2019-June},
year = {2019}
}
@article{Xu2018,
abstract = {Graph Neural Networks (GNNs) are an effective framework for representation
learning of graphs. GNNs follow a neighborhood aggregation scheme, where the
representation vector of a node is computed by recursively aggregating and
transforming representation vectors of its neighboring nodes. Many GNN variants
have been proposed and have achieved state-of-the-art results on both node and
graph classification tasks. However, despite GNNs revolutionizing graph
representation learning, there is limited understanding of their
representational properties and limitations. Here, we present a theoretical
framework for analyzing the expressive power of GNNs to capture different graph
structures. Our results characterize the discriminative power of popular GNN
variants, such as Graph Convolutional Networks and GraphSAGE, and show that
they cannot learn to distinguish certain simple graph structures. We then
develop a simple architecture that is provably the most expressive among the
class of GNNs and is as powerful as the Weisfeiler-Lehman graph isomorphism
test. We empirically validate our theoretical findings on a number of graph
classification benchmarks, and demonstrate that our model achieves
state-of-the-art performance.},
archivePrefix = {arXiv},
arxivId = {1810.00826},
author = {Xu, Keyulu and Jegelka, Stefanie and Hu, Weihua and Leskovec, Jure},
eprint = {1810.00826},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xu et al. - 2018 - How Powerful are Graph Neural Networks.pdf:pdf},
isbn = {1810.00826v3},
journal = {7th International Conference on Learning Representations, ICLR 2019},
month = {oct},
publisher = {International Conference on Learning Representations, ICLR},
title = {{How Powerful are Graph Neural Networks?}},
url = {https://arxiv.org/abs/1810.00826v3},
year = {2018}
}
@article{Zhou2020a,
abstract = {Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics systems, learning molecular fingerprints, predicting protein interface, and classifying diseases demand a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures (like the dependency trees of sentences and the scene graphs of images) is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are neural models that capture the dependence of graphs via message passing between the nodes of graphs. In recent years, variants of GNNs such as graph convolutional network (GCN), graph attention network (GAT), graph recurrent network (GRN) have demonstrated ground-breaking performances on many deep learning tasks. In this survey, we propose a general design pipeline for GNN models and discuss the variants of each component, systematically categorize the applications, and propose four open problems for future research.},
archivePrefix = {arXiv},
arxivId = {1812.08434},
author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
doi = {10.1016/J.AIOPEN.2021.01.001},
eprint = {1812.08434},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2020 - Graph neural networks A review of methods and applications.pdf:pdf},
issn = {2666-6510},
journal = {AI Open},
keywords = {Deep learning,Graph neural network},
month = {jan},
pages = {57--81},
publisher = {Elsevier},
title = {{Graph neural networks: A review of methods and applications}},
volume = {1},
year = {2020}
}
@article{Lia,
abstract = {Few prior works study deep learning on point sets. PointNet [20] is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds.},
archivePrefix = {arXiv},
arxivId = {1706.02413v1},
author = {Li, Charles R Qi and Hao, Yi and Leonidas, Su and Guibas, J},
eprint = {1706.02413v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Li et al. - Unknown - PointNet Deep Hierarchical Feature Learning on Point Sets in a Metric Space.pdf:pdf},
title = {{PointNet++: Deep Hierarchical Feature Learning on Point Sets in a Metric Space}}
}
@article{Setio2016,
abstract = {We propose a novel Computer-Aided Detection (CAD) system for pulmonary nodules using multi-view convolutional networks (ConvNets), for which discriminative features are automatically learnt from the training data. The network is fed with nodule candidates obtained by combining three candidate detectors specifically designed for solid, subsolid, and large nodules. For each candidate, a set of 2-D patches from differently oriented planes is extracted. The proposed architecture comprises multiple streams of 2-D ConvNets, for which the outputs are combined using a dedicated fusion method to get the final classification. Data augmentation and dropout are applied to avoid overfitting. On 888 scans of the publicly available LIDC-IDRI dataset, our method reaches high detection sensitivities of 85.4% and 90.1% at 1 and 4 false positives per scan, respectively. An additional evaluation on independent datasets from the ANODE09 challenge and DLCST is performed. We showed that the proposed multi-view ConvNets is highly suited to be used for false positive reduction of a CAD system.},
author = {Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Litjens, Geert and Gerke, Paul and Jacobs, Colin and {Van Riel}, Sarah J. and Wille, Mathilde Marie Winkler and Naqibullah, Matiullah and Sanchez, Clara I. and {Van Ginneken}, Bram},
doi = {10.1109/TMI.2016.2536809},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Setio et al. - 2016 - Pulmonary Nodule Detection in CT Images False Positive Reduction Using Multi-View Convolutional Networks.pdf:pdf},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Computed tomography,computer-aided detection,convolutional networks,deep learning,lung cancer,pulmonary nodule},
month = {may},
number = {5},
pages = {1160--1169},
pmid = {26955024},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Pulmonary Nodule Detection in CT Images: False Positive Reduction Using Multi-View Convolutional Networks}},
volume = {35},
year = {2016}
}
@article{Qi2016,
abstract = {3D shape models are becoming widely available and easier to capture, making
available 3D information crucial for progress in object classification. Current
state-of-the-art methods rely on CNNs to address this problem. Recently, we
witness two types of CNNs being developed: CNNs based upon volumetric
representations versus CNNs based upon multi-view representations. Empirical
results from these two types of CNNs exhibit a large gap, indicating that
existing volumetric CNN architectures and approaches are unable to fully
exploit the power of 3D representations. In this paper, we aim to improve both
volumetric CNNs and multi-view CNNs according to extensive analysis of existing
approaches. To this end, we introduce two distinct network architectures of
volumetric CNNs. In addition, we examine multi-view CNNs, where we introduce
multi-resolution filtering in 3D. Overall, we are able to outperform current
state-of-the-art methods for both volumetric CNNs and multi-view CNNs. We
provide extensive experiments designed to evaluate underlying design choices,
thus providing a better understanding of the space of methods available for
object classification on 3D data.},
archivePrefix = {arXiv},
arxivId = {1604.03265},
author = {Qi, Charles R. and Su, Hao and Niebner, Matthias and Dai, Angela and Yan, Mengyuan and Guibas, Leonidas J.},
doi = {10.1109/CVPR.2016.609},
eprint = {1604.03265},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi et al. - 2016 - Volumetric and Multi-View CNNs for Object Classification on 3D Data.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
month = {apr},
pages = {5648--5656},
publisher = {IEEE Computer Society},
title = {{Volumetric and Multi-View CNNs for Object Classification on 3D Data}},
url = {https://arxiv.org/abs/1604.03265v2},
volume = {2016-December},
year = {2016}
}
@article{Qi,
abstract = {Point cloud is an important type of geometric data structure. Due to its irregular format, most researchers transform such data to regular 3D voxel grids or collections of images. This, however, renders data unnecessarily voluminous and causes issues. In this paper, we design a novel type of neural network that directly consumes point clouds, which well respects the permutation invariance of points in the input. Our network, named PointNet, provides a unified architecture for applications ranging from object classification, part segmentation, to scene semantic parsing. Though simple, PointNet is highly efficient and effective. Empirically, it shows strong performance on par or even better than state of the art. Theoretically, we provide analysis towards understanding of what the network has learnt and why the network is robust with respect to input perturbation and corruption.},
archivePrefix = {arXiv},
arxivId = {1612.00593v2},
author = {Qi, Charles R and Su, Hao and Mo, Kaichun and Guibas, Leonidas J},
eprint = {1612.00593v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qi et al. - Unknown - PointNet Deep Learning on Point Sets for 3D Classification and Segmentation.pdf:pdf},
title = {{PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation}}
}
@article{Dai,
abstract = {A key requirement for leveraging supervised deep learning methods is the availability of large, labeled datasets. Unfortunately, in the context of RGB-D scene understanding , very little data is available-current datasets cover a small range of scene views and have limited semantic annotations. To address this issue, we introduce ScanNet, an RGB-D video dataset containing 2.5M views in 1513 scenes annotated with 3D camera poses, surface reconstructions, and semantic segmentations. To collect this data, we designed an easy-to-use and scalable RGB-D capture system that includes automated surface reconstruction and crowd-sourced semantic annotation.We show that using this data helps achieve state-of-the-art performance on several 3D scene understanding tasks, including 3D object classification , semantic voxel labeling, and CAD model retrieval.},
author = {Dai, Angela and Chang, Angel X and Savva, Manolis and Halber, Maciej and Funkhouser, Thomas and Nie{\ss}ner, Matthias},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dai et al. - Unknown - ScanNet Richly-annotated 3D Reconstructions of Indoor Scenes.pdf:pdf},
title = {{ScanNet: Richly-annotated 3D Reconstructions of Indoor Scenes}},
url = {www.scan-net.org}
}
@article{Kipf2016,
abstract = {We present a scalable approach for semi-supervised learning on
graph-structured data that is based on an efficient variant of convolutional
neural networks which operate directly on graphs. We motivate the choice of our
convolutional architecture via a localized first-order approximation of
spectral graph convolutions. Our model scales linearly in the number of graph
edges and learns hidden layer representations that encode both local graph
structure and features of nodes. In a number of experiments on citation
networks and on a knowledge graph dataset we demonstrate that our approach
outperforms related methods by a significant margin.},
archivePrefix = {arXiv},
arxivId = {1609.02907},
author = {Kipf, Thomas N. and Welling, Max},
eprint = {1609.02907},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kipf, Welling - 2016 - Semi-Supervised Classification with Graph Convolutional Networks.pdf:pdf},
journal = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
month = {sep},
publisher = {International Conference on Learning Representations, ICLR},
title = {{Semi-Supervised Classification with Graph Convolutional Networks}},
url = {https://arxiv.org/abs/1609.02907v4},
year = {2016}
}
@article{Scarselli2009,
abstract = {Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function $\tau$ (G,n) â Rm that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities. {\textcopyright} 2008 IEEE.},
author = {Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
doi = {10.1109/TNN.2008.2005605},
issn = {10459227},
journal = {IEEE Transactions on Neural Networks},
keywords = {Graph neural networks (GNNs),Graph processing,Graphical domains,Recursive neural networks},
month = {jan},
number = {1},
pages = {61--80},
pmid = {19068426},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The graph neural network model}},
volume = {20},
year = {2009}
}
@article{Velickovivelickovic,
abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
archivePrefix = {arXiv},
arxivId = {1710.10903v3},
author = {Veli{\v{c}}koviÂ´veli{\v{c}}koviÂ´c, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and L{\`{i}}, Pietro and Bengio, Yoshua},
eprint = {1710.10903v3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Veli{\v{c}}koviÂ´veli{\v{c}}koviÂ´c et al. - Unknown - GRAPH ATTENTION NETWORKS(2).pdf:pdf},
isbn = {1710.10903v3},
title = {{GRAPH ATTENTION NETWORKS}}
}
@article{Engelmann,
abstract = {Fig. 1. We present a deep learning framework that predicts a semantic label for each point in a given 3D point cloud. The main components of our approach are point neighborhoods in different feature spaces and dedicated loss functions which help to refine the learned feature spaces. Left: point clouds from indoor and outdoor scenes. Right: semantic segmentation results produced by the presented method. Abstract. In this paper, we present a deep learning architecture which addresses the problem of 3D semantic segmentation of unstructured point clouds. Compared to previous work, we introduce grouping techniques which define point neighborhoods in the initial world space and the learned feature space. Neighborhoods are important as they allow to compute local or global point features depending on the spatial extend of the neighborhood. Additionally, we incorporate dedicated loss functions to further structure the learned point feature space: the pairwise distance loss and the centroid loss. We show how to apply these mechanisms to the task of 3D semantic segmentation of point clouds and report state-of-the-art performance on indoor and outdoor datasets. 2 F. Engelmann et al.},
author = {Engelmann, Francis and Kontogianni, Theodora and Schult, Jonas and Leibe, Bastian},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Engelmann et al. - Unknown - Know What Your Neighbors Do 3D Semantic Segmentation of Point Clouds.pdf:pdf},
title = {{Know What Your Neighbors Do: 3D Semantic Segmentation of Point Clouds}}
}
@article{Vallejos2020,
abstract = {Introduction: Pulmonary hypertension (PH) and interstitial lung disease (ILD) are associated with poor outcomes in patients with systemic sclerosis (SSc). Forced Vital Capacity/Diffusion capacity for carbon monoxide(FVC/DLCO) has been proposed as a mortality predictor marker.

Objective: To analyze the association of FVC/DLCO with PH and ILD in a Latin-American cohort.

Methods: Retrospective cohort study. Patients who complied ACR/EULAR diagnosis criteria of SSc during 2014 to 2019 were analyzed. 75 offered complete clinical record, high resolution computed tomography (HRCT), Pulmonary function test (PFT) and Echocardiography at baseline. We defined âPH-riskâ group as the presence of â¥1 feature of â¥2 echocardiographic categories described in the 6th world symposium (ventricle / pulmonary artery / inferior vena cava-right atrium) or a pulmonary artery systolic pressure (PASP)> 35 mmHg. ILD was defined as an extent of >20% in the HRCT.

Results: Among the 75 patients: 72 (96%) were women and mean age was 60 (+/-13) years. When comparing the 2 groups: 

View this table:

![Figure][1]</img>



Conclusion: In our cohort FVC/DLCO was significantly higher between the PH-risk patients, regardless of the presence of ILD. This index could be used as a PH screening tool even in patients with SSc associated ILD.

Footnotes 

Cite this article as: European Respiratory Journal 2020; 56: Suppl. 64, 302.

This abstract was presented at the 2020 ERS International Congress, in session âRespiratory viruses in the "pre COVID-19" eraâ.

This is an ERS International Congress abstract. No full-text version is available. Further material to accompany this abstract may be available at [www.ers-education.org][2] (ERS member access only).

 [1]: pending:yes
 [2]: http://www.ers-education.org},
author = {Vallejos, Eva Ail{\'{i}}n and Martinez, John and Cabrera, Florencia and Mastandrea, Noelia and Pertuz, Milerna and Marengo, Zullie and Meiller, M. Jos{\'{e}} L{\'{o}}pez and Volberg, Veronica and Tejada, Ricardo G{\'{o}}mez},
doi = {10.1183/13993003.CONGRESS-2020.302},
issn = {0903-1936},
journal = {European Respiratory Journal},
month = {sep},
number = {suppl 64},
pages = {302},
publisher = {European Respiratory Society},
title = {{Association of FVC/DLCO with pulmonary hypertension risk and interstitial disease in systemic sclerosis patients}},
url = {https://erj.ersjournals.com/content/56/suppl_64/302 https://erj.ersjournals.com/content/56/suppl_64/302.abstract},
volume = {56},
year = {2020}
}
@article{Velickovivelickovica,
abstract = {We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).},
archivePrefix = {arXiv},
arxivId = {1710.10903v3},
author = {Veli{\v{c}}koviÂ´veli{\v{c}}koviÂ´c, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and L{\`{i}}, Pietro and Bengio, Yoshua},
eprint = {1710.10903v3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Veli{\v{c}}koviÂ´veli{\v{c}}koviÂ´c et al. - Unknown - GRAPH ATTENTION NETWORKS.pdf:pdf},
isbn = {1710.10903v3},
title = {{GRAPH ATTENTION NETWORKS}}
}



@article{Wanger,
author = {Wanger, J and Clausen, J L and Coates, A and Pedersen, O F and Brusasco, V and Burgos, F and Casaburi, R and Crapo, R and Enright, P and {Van Der Grinten}, C P M and Gustafsson, P and Hankinson, J and Jensen, R and Johnson, D and Macintyre, N and Mckay, R and Miller, M R and Navajas, D and Pellegrino, R and Viegi, G},
doi = {10.1183/09031936.05.00035005},
title = {{Standardisation of the measurement of lung volumes}}
}


@article{Cotes1993,
abstract = {### 1.1 What is being measured

The lung is the organ of external respiration for the exchange of oxygen and carbon dioxide between the blood and the surrounding air. The stages in the process of gas transfer include:

1. Ventilation of the airways and some air spaces by bulk flow of gas;

2. Mixing and diffusion of gases in the alveolar ducts, air sacs and alveoli;

3. Transfer of gases across the gaseous to liquid interface of the alveolar membrane;

4. Mixing and diffusion in the lung parenchyma and alveolar capillary plasma;

5. Chemical reaction with constituents of blood;

6. Circulation of blood between the pulmonary and systemic vascular beds.

The capacity of the lung to exchange gas is determined by the structural and functional dimensions of these processes. The structural dimensions include the lung volume, the path length for diffusion in the gas phase, the thickness and area of the alveolar capillary membrane including any effects of airway closure, and the volume of blood in capillaries supplying alveoli which are ventilated. The principal functional dimensions are the absolute levels of ventilation and perfusion and the uniformity of their distribution with respect to both each other and the diffusion characteristics of the membrane. Other functional dimensions are the quantity of haemoglobin in the alveolar capillaries, the composition of the alveolar gas, the gas tensions in blood entering the alveolar capillaries, the rates of chemical reaction with haemoglobin and of dissociation of the compound so formed, the transit time of blood through that part of the pulmonary vascular bed which exchanges gas with the alveoli and the slope of the relevant haemoglobin dissociation curve. The latter is a function of the temperature of the lung and the prevailing levels of oxygen, carbon dioxide, hydrogen ions and 2,3-diphosphoglycerate; many of these variables are dependent on the level of {\ldots}},
author = {Cotes, J. E. and Chinn, D. J. and Quanjer, P. H. and Roca, J. and Yernault, J. C.},
doi = {10.1183/09041950.041S1693},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cotes et al. - 1993 - Standardization of the measurement of transfer factor (diffusing capacity).pdf:pdf},
isbn = {87-16-15024-4},
issn = {0903-1936},
journal = {European Respiratory Journal},
month = {mar},
number = {Suppl 16},
pages = {41--52},
pmid = {24576916},
publisher = {European Respiratory Society},
title = {{Standardization of the measurement of transfer factor (diffusing capacity)}},
url = {https://erj.ersjournals.com/content/6/Suppl_16/41 https://erj.ersjournals.com/content/6/Suppl_16/41.abstract},
volume = {6},
year = {1993}
}

@article{Horita2015,
abstract = {Background: The minimum clinically important difference (MCID) for diffusing capacity of the lungs for carbon monoxide (DLCO) has not yet been solidly established. Methods: We used the dataset of surgical cohort of National Emphysema Treatment Trial. Briefly, severe and very severe chronic obstructive pulmonary disease (COPD) patients who were candidate for volume reduction surgery and who could provide sufficient data at 12-month follow-up were included. We used two anchor methods using 6-minute walk distance (6MWD. MCID = 40 m) and forced expiratory volume in 1 sec (FEV1. MCID = 100 ml) as anchors, and two distribution methods. We proposed MCID with a median of estimated values. We estimated MCID for DLCO in raw value and % change from the baseline independently. Results: The surgical cohort included 356 patients, whose average age was 66.6 Â± 5.5 years, and the average % predicted FEV1 was 27.8 Â± 7.3%. The estimated MCID for DLCO in raw value and % change from the baseline were as follows: anchor method (average, 6MWD) 1.2 ml/min/mmHg, 17%; anchor method (average, FEV1) 0.7 ml/min/mmHg, 11%; anchor method (receiver operating characteristic, 6MWD) 1.1 ml/min/mmHg, 10%; anchor method (receiver operating characteristic, FEV1) 1.2 ml/min/mmHg, 3%; distribution method (0.3 units of standard deviation), 0.9 ml/min/mmHg, 11%; distribution method (standard error of measurement), 1.1 ml/min/mmHg. The median of these values was 1.1 ml/min/mmHg and 11%. Conclusion: We estimated the group-level MCID for DLCO for patients with severe and very severe COPD patients as 1.1 ml/min/mmHg and 11% of baseline DLCO.},
author = {Horita, Nobuyuki and Miyazawa, Naoki and Kojima, Ryota and Inoue, Miyo and Ishigatsubo, Yoshiaki and Kaneko, Takeshi},
doi = {10.3109/15412555.2014.898051},
issn = {1541-2563},
journal = {COPD},
keywords = {Aged,Biomarkers / metabolism,Carbon Monoxide / metabolism*,Chronic Obstructive / physiopathology*,Chronic Obstructive / surgery,Chronic Obstructive / therapy,Evaluation Study,Exercise Test,Female,Follow-Up Studies,Forced Expiratory Volume,Humans,MEDLINE,Male,Middle Aged,NCBI,NIH,NLM,Naoki Miyazawa,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Nobuyuki Horita,Pneumonectomy,PubMed Abstract,Pulmonary Diffusing Capacity*,Pulmonary Disease,Reproducibility of Results,Severity of Illness Index*,Takeshi Kaneko,Treatment Outcome,doi:10.3109/15412555.2014.898051,pmid:24915470},
month = {feb},
number = {1},
pages = {31--37},
pmid = {24915470},
publisher = {COPD},
title = {{Minimum clinically important difference in diffusing capacity of the lungs for carbon monoxide among patients with severe and very severe chronic obstructive pulmonary disease}},
url = {https://pubmed.ncbi.nlm.nih.gov/24915470/},
volume = {12},
year = {2015}
}
@article{MohamedHamdyIbrahim,
abstract = {Background: Systemic sclerosis is a connective tissue disease that affects multiple systems and causes fibrosis of the skin and internal organs. There are two ways in which the lungs can be involved in patients with systemic sclerosis, either isolated pulmonary hypertension or interstitial lung fibrosis. The purpose of this study is to correlate the high resolution CT findings with pulmonary function tests in patients with systemic sclerosis to evaluate the severity of lung changes.},
author = {{Mohamed Hamdy Ibrahim}, Iman and {Mohamed Gamal}, Sherif and {Mamdouh Salama}, Adham and {Ahmed Khairy}, Mostafa},
doi = {10.1186/s43055-020-00220-3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mohamed Hamdy Ibrahim et al. - Unknown - Systemic sclerosis correlation between lung abnormalities on high-resolution computed tomograph.pdf:pdf},
title = {{Systemic sclerosis: correlation between lung abnormalities on high-resolution computed tomography (HRCT) and pulmonary function tests (PFTs)}},
url = {https://doi.org/10.1186/s43055-020-00220-3}
}
@article{Iwano2009,
abstract = {Rationale and Objectives: The aim of this study was to evaluate the accuracy of measurements of lung volumes reconstructed using three-dimensional computed tomographic (CT) imaging from thin-section multidetector-row CT images compared to standard pulmonary function testing. Materials and Methods: Preoperative three-dimensional CT images and pulmonary function test results of 64 patients with solitary pulmonary nodules who were considered candidates for lung resection were reviewed. On the three-dimensional CT images, total lung capacity (TLCCTV), emphysematous lung capacity (ELCCTV), and normal lung capacity (NLCCTV) were calculated. Total lung capacity (TLC), vital capacity, and forced expiratory volume in 1 second were measured using spirometry. Results: There was a strong positive correlation between estimated TLCCTV and measured TLC values (r = 0.87, P < .001). Estimated ELCCTV at the threshold value of -900 Hounsfield units was negatively correlated with forced expiratory volume in 1 second (r = -0.56, P < .001). NLCCTV values were more strongly correlated with vital capacity values than TLCCTV values (r = 0.74, P < .001). Conclusions: Lung volume calculated using three-dimensional CT volumetry was well correlated with lung volume measured using spirometry. Three-dimensional CT volumetry can be used to evaluate pulmonary function. {\textcopyright} 2009 AUR.},
author = {Iwano, Shingo and Okada, Tohru and Satake, Hiroko and Naganawa, Shinji},
doi = {10.1016/J.ACRA.2008.09.019},
issn = {1076-6332},
journal = {Academic Radiology},
keywords = {3D image,Computed tomography,lung density,lung neoplasms,pulmonary function},
month = {mar},
number = {3},
pages = {250--256},
pmid = {19201353},
publisher = {Elsevier},
title = {{3D-CT Volumetry of the Lung Using Multidetector Row CT: Comparison with Pulmonary Function Tests}},
volume = {16},
year = {2009}
}

@article{Suliman2015,
abstract = {Objective Validated methods for the screening and early diagnosis of systemic sclerosis (SSc; scleroderma)-related interstitial lung disease (ILD) are needed. The aim of this study was to evaluate the performance of pulmonary function tests (PFTs) compared with that of high-resolution computed tomography (HRCT) of the chest for the detection of SSc-related ILD in clinical practice, and to identify predictors of lung involvement that is functionally occult but significant on HRCT. Methods Prospectively enrolled patients with SSc were assessed according to the European League Against Rheumatism (EULAR)/EULAR Scleroderma Trial and Research standards. The assessment included PFTs and HRCT. The HRCT images were evaluated in a blinded manner by 2 experienced radiologists. The performance parameters of PFTs for the diagnosis of SSc-related ILD were calculated. Predictors of significant ILD as determined by HRCT in patients with normal forced vital capacity (FVC) values were identified through logistic regression. Results Among the 102 patients, 64 (63.0%) showed significant ILD on HRCT, while only 27 (26.0%) had an FVC <80% of predicted, and 54 (53.0%) had a decrease in the results of at least 1 PFT. Forty (62.5%) of 64 patients with significant ILD on HRCT had a normal FVC value, translating into a high false-negative rate. Notably, 5 of 40 patients with a normal FVC value had severe, functionally occult lung fibrosis; in 2 of these patients, the results of all of the PFTs were within normal limits. Patients with normal FVC values despite evidence of fibrosis on HRCT more frequently had anti-Scl-70 antibodies and diffuse SSc and less frequently had anticentromere antibodies (ACAs) compared with patients with both normal FVC values and normal HRCT results. Conclusion The derived evidence-based data reveal a high risk of missing significant SSc-related ILD when relying solely on PFTs. More comprehensive screening algorithms for early detection are warranted. In particular, additional imaging investigations for the early detection of SSc-related ILD should be considered in ACA-negative patients with normal FVC values.},
author = {Suliman, Yossra A. and Dobrota, Rucsandra and Huscher, D{\"{o}}rte and Nguyen-Kim, Thi D.L. and Maurer, Britta and Jordan, Suzana and Speich, Rudolf and Frauenfelder, Thomas and Distler, Oliver},
doi = {10.1002/ART.39405},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Suliman et al. - 2015 - Brief Report Pulmonary Function Tests High Rate of False-Negative Results in the Early Detection and Screening o.pdf:pdf},
issn = {2326-5205},
journal = {Arthritis & rheumatology (Hoboken, N.J.)},
keywords = {80 and over,Adult,Aged,Antibodies,Antinuclear,Cohort Studies,Diagnostic Errors*,Early Diagnosis,False Negative Reactions,Female,Humans,Interstitial / diagnosis*,Interstitial / diagnostic imaging,Interstitial / etiology,Interstitial / immunology,Logistic Models,Lung Diseases,MEDLINE,Male,Middle Aged,Multidetector Computed Tomography,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Oliver Distler,Prospective Studies,PubMed Abstract,Pulmonary Diffusing Capacity,Pulmonary Fibrosis / diagnosis*,Pulmonary Fibrosis / diagnostic imaging,Pulmonary Fibrosis / etiology,Pulmonary Fibrosis / immunology,Research Support,Respiratory Function Tests*,Rucsandra Dobrota,Scleroderma,Systemic / complications,Systemic / diagnosis*,Systemic / diagnostic imaging,Systemic / immunology,Total Lung Capacity,Vital Capacity,Yossra A Suliman,doi:10.1002/art.39405,pmid:26316389},
month = {dec},
number = {12},
pages = {3256--3261},
pmid = {26316389},
publisher = {Arthritis Rheumatol},
title = {{Brief Report: Pulmonary Function Tests: High Rate of False-Negative Results in the Early Detection and Screening of Scleroderma-Related Interstitial Lung Disease}},
url = {https://pubmed.ncbi.nlm.nih.gov/26316389/},
volume = {67},
year = {2015}
}
@article{Graham2019a,
abstract = {Background: Spirometry is the most common pulmonary function test. It is widely used in the assessment of lung function to provide objective information used in the diagnosis of lung diseases and m...},
author = {Graham, Brian L. and Steenbruggen, Irene and Barjaktarevic, Igor Z. and Cooper, Brendan G. and Hall, Graham L. and Hallstrand, Teal S. and Kaminsky, David A. and McCarthy, Kevin and McCormack, Meredith C. and Miller, Martin R. and Oropez, Cristine E. and Rosenfeld, Margaret and Stanojevic, Sanja and Swanney, Maureen P. and Thompson, Bruce R.},
doi = {10.1164/RCCM.201908-1590ST},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Graham et al. - 2019 - Standardization of Spirometry 2019 Update. An Official American Thoracic Society and European Respiratory Society.pdf:pdf},
issn = {15354970},
journal = {https://doi.org/10.1164/rccm.201908-1590ST},
keywords = {pulmonary function,spirometer,spirometry,technical standards},
month = {oct},
number = {8},
pages = {E70--E88},
pmid = {31613151},
publisher = {American Thoracic Society},
title = {{Standardization of Spirometry 2019 Update. An Official American Thoracic Society and European Respiratory Society Technical Statement}},
url = {http://www.atsjournals.org/doi/suppl/10.1164/rccm.201908-1590ST.},
volume = {200},
year = {2019}
}

@article{Daghighi2019,
abstract = {Background: Scoliosis is a three-dimensional deformity which is believed to impact lung function, mechanics of respiratory muscles, lung compliance, etc. It is thus of interest to investigated the relationship between degree of scoliosis in terms of apex rotation or Cobb angle respectively and normalized vital capacity (VC). Furthermore it is interesting to study the possibility of estimating lung volumes (and indirectly lung function) using CT volumetric reconstruction. Methods: The inclusion criteria were consecutive patients for whom surgery was planned and who underwent preoperative low-dose chest CT and preoperative spirometry/plethysmography. Lung capacities were normalized (based upon previous work involving the parameters gender, age, height and smoking). Preoperative CT-scans were used to measure apical rotation and scoliosis. We investigated the relationship between degree of scoliosis in terms of apex rotation or Cobb angle respectively and normalized VC from spirometry 63 patients who had a thoracic scoliosis curve (not necessarily as primary curve). We have tested a method for estimating normalized total lung capacity (TLC) from inspiratory chest CT of a group of 61 patients. Results: The statistical level of significance used throughout the paper of 0.05. In the first part, we show that the group of 63 patients can, with respect to apical rotation or Cobb angle respectively, be divided into three subgroups in each case respectively, such that, pairwise, the mean of the normalized VC, for the group with higher apical rotation or Cobb angle respectively, is in some sense, at least 9% lower. We also give the result of the more simplistic analysis of subdividing into only two groups which give approximately 13% decrease for the group with higher spine deformation. A linear regression model seems inappropriate, due to the correlation coefficient for normalized VC versus apical rotation or Cobb angle respectively, being â0.53 (or in the case of Cobb angle â0.35). The correlation coefficient between apical rotation and Cobb angles, for the 63 patients, was 0.64. In the second part, the attempted linear regression model for describing the relation between lung volume estimation from inspiratory CT, and the normalized TLC from spirometry/plethysmography yields a correlation coefficient â0.71. Conclusions: In the first part, we show that there is a group subdivision with respect to apical rotation or Cobb angle respectively, whereby groups with a higher degree of thoracic vertebral deviation have, in some sense, a lower normalized VC. We propose that a linear regression model is inappropriate. In the second part, we propose that a linear regression model could describe the relationship between estimations of lung volume from inspiratory CT, and the normalized TLC from spirometry/plethysmography.},
author = {Daghighi, Abtin and Tropp, Hans},
doi = {10.21037/JSS.2018.12.14},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Daghighi, Tropp - 2019 - Computed tomography lung volume estimation and its relation to lung capacities and spine deformation.pdf:pdf},
issn = {24144630},
journal = {Journal of Spine Surgery},
keywords = {CT estimation,Scoliosis,apex rotation,total lung capacity (TLC),vital capacity (VC)},
month = {mar},
number = {1},
pages = {132},
pmid = {31032448},
publisher = {OSS Press},
title = {{Computed tomography lung volume estimation and its relation to lung capacities and spine deformation}},
url = {/pmc/articles/PMC6465474/ /pmc/articles/PMC6465474/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6465474/},
volume = {5},
year = {2019}
}

@article{Bakker2017,
abstract = {Purpose: The aim was to evaluate computed tomography (CT)-measured pulmonary artery diameter (PAD) and lung density as predictors of pulmonary hypertension (PH) in subjects with systemic sclerosis (SSc). We compared these PAD values with normal values and between SSc subgroups with PH and/or interstitial lung disease (ILD). We investigated whether PAD predicts PH and whether lung densitometry, by using the 85th percentile density value (Perc85) as a measure for ILD, can predict PH. Materials and Methods: PAD and Perc85 were measured in axial CT scans and compared between 54 SSc and 76 control subjects. Four SSc subgroups were defined on the basis of PH (systolic PA pressure â¥35 mm Hg) and/or ILD (fibrosis score â¥7): PH-/ILD-, PH-/ILD+, PH+/ILD-, and PH+/ILD+. The association of PAD with age, body mass index, Perc85, lung function, and hemodynamic measures was investigated using univariate correlation along with the predictive value of these measures with respect to PH. Results: PAD in SSc was larger than that in controls (30.1Â±4.9 vs. 26.9Â±2.7 mm, P<0.001). PH+ patients showed increased PAD compared with PH- patients (34.2Â±4.2 vs. 28.6Â±4.3 mm, P<0.001), where PH+/ILD+ subjects showed the widest diameter (34.6Â±4.1 mm). In SSc patients, hemodynamic measures, age, body mass index, Perc85, and lung function correlated with PAD. PAD was best explained by Perc85, together with age (R 2 =0.358). PAD best predicted PH (AUC, 0.877; P<0.001), and PADâ¥30.7 mm showed 80% sensitivity and 87% specificity. Perc85 also predicted PH (AUC, 0.733; P=0.024). Conclusions: In subjects with SSc, lung density and PAD are CT markers, each with predictive value for PH.},
author = {Bakker, Margreet E. and Ninaber, Maarten K. and Stolk, Jan and Kroft, Lucia J.M. and Schouffoer, Anne A. and {De Vries Bouwstra}, Jeska K. and {Van Wijngaarden}, Suzanne E. and Stoel, Berend C.},
doi = {10.1097/RTI.0000000000000279},
issn = {15360237},
journal = {Journal of Thoracic Imaging},
keywords = {computed tomography,lung density,pulmonary artery diameter,pulmonary hypertension,systemic sclerosis},
number = {6},
pages = {391--397},
pmid = {28549020},
publisher = {Lippincott Williams and Wilkins},
title = {{Lung Density and Pulmonary Artery Diameter are Predictors of Pulmonary Hypertension in Systemic Sclerosis}},
url = {https://journals.lww.com/thoracicimaging/Fulltext/2017/11000/Lung_Density_and_Pulmonary_Artery_Diameter_are.8.aspx},
volume = {32},
year = {2017}
}
@article{Walsh2022,
abstract = {Rationale: Reliable outcome prediction in patients with fibrotic lung disease using baseline high-resolution computed tomography (HRCT) data remains challenging. Objectives: To evaluate the prognostic accuracy of a deep learning algorithm (SOFIA [Systematic Objective Fibrotic Imaging Analysis Algorithm]), trained and validated in the identification of usual interstitial pneumonia (UIP)-like features on HRCT (UIP probability), in a large cohort of well-characterized patients with progressive fibrotic lung disease drawn from a national registry. Methods: SOFIA and radiologist UIP probabilities were converted to Prospective Investigation of Pulmonary Embolism Diagnosis (PIOPED)-based UIP probability categories (UIP not included in the differential, 0-4%; low probability of UIP, 5-29%; intermediate probability of UIP, 30-69%; high probability of UIP, 70-94%; and pathognomonic for UIP, 95-100%), and their prognostic utility was assessed using Cox proportional hazards modeling. Measurements and Main Results: In multivariable analysis adjusting for age, sex, guideline-based radiologic diagnosis, anddisease severity (using total interstitial lung disease [ILD] extent on HRCT, percent predicted FVC, DlCO, or the composite physiologic index), only SOFIA UIP probability PIOPED categories predicted survival. SOFIA-PIOPED UIP probability categories remained prognostically significant in patients considered indeterminate (nâ=â83) by expert radiologist consensus (hazard ratio, 1.73; Pâ<â0.0001; 95% confidence interval, 1.40-2.14). In patients undergoing surgical lung biopsy (nâ=â86), after adjusting for guideline-based histologic pattern and total ILD extent on HRCT, only SOFIA-PIOPED probabilities were predictive of mortality (hazard ratio, 1.75; Pâ<â0.0001; 95% confidence interval, 1.37-2.25). Conclusions: Deep learning-based UIP probability on HRCT provides enhanced outcome prediction in patients with progressive fibrotic lung disease when compared with expert radiologist evaluation or guideline-based histologic pattern. In principle, this tool may be useful in multidisciplinary characterization of fibrotic lung disease. The utility of this technology as a decision support system when ILD expertise is unavailable requires further investigation.},
author = {Walsh, Simon L.F. and Mackintosh, John A. and Calandriello, Lucio and Silva, Mario and Sverzellati, Nicola and Larici, Anna Rita and Humphries, Stephen M. and Lynch, David A. and Jo, Helen E. and Glaspole, Ian and Grainge, Christopher and Goh, Nicole and Hopkins, Peter M.A. and Moodley, Yuben and Reynolds, Paul N. and Zappala, Christopher and Keir, Gregory and Cooper, Wendy A. and Mahar, Annabelle M. and Ellis, Samantha and Wells, Athol U. and Corte, Tamera J.},
doi = {10.1164/RCCM.202112-2684OC},
issn = {1535-4970},
journal = {American journal of respiratory and critical care medicine},
keywords = {Deep Learning*,Humans,Idiopathic Pulmonary Fibrosis* / diagnosis,Interstitial*,John A Mackintosh,Lung / diagnostic imaging,Lung / pathology,Lung Diseases,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Non-U.S. Gov't,Prognosis,Prospective Studies,PubMed Abstract,Research Support,Retrospective Studies,Simon L F Walsh,Tamera J Corte,Tomography,X-Ray Computed / methods,doi:10.1164/rccm.202112-2684OC,pmid:35696341},
month = {oct},
number = {7},
pages = {883--891},
pmid = {35696341},
publisher = {Am J Respir Crit Care Med},
title = {{Deep Learning-based Outcome Prediction in Progressive Fibrotic Lung Disease Using High-Resolution Computed Tomography}},
url = {https://pubmed.ncbi.nlm.nih.gov/35696341/},
volume = {206},
year = {2022}
}
@article{Walsh2018,
abstract = {Background: Based on international diagnostic guidelines, high-resolution CT plays a central part in the diagnosis of fibrotic lung disease. In the correct clinical context, when high-resolution CT appearances are those of usual interstitial pneumonia, a diagnosis of idiopathic pulmonary fibrosis can be made without surgical lung biopsy. We investigated the use of a deep learning algorithm for provision of automated classification of fibrotic lung disease on high-resolution CT according to criteria specified in two international diagnostic guideline statements: the 2011 American Thoracic Society (ATS)/European Respiratory Society (ERS)/Japanese Respiratory Society (JRS)/Latin American Thoracic Association (ALAT) guidelines for diagnosis and management of idiopathic pulmonary fibrosis and the Fleischner Society diagnostic criteria for idiopathic pulmonary fibrosis. Methods: In this case-cohort study, for algorithm development and testing, a database of 1157 anonymised high-resolution CT scans showing evidence of diffuse fibrotic lung disease was generated from two institutions. We separated the scans into three non-overlapping cohorts (training set, n=929; validation set, n=89; and test set A, n=139) and classified them using 2011 ATS/ERS/JRS/ALAT idiopathic pulmonary fibrosis diagnostic guidelines. For each scan, the lungs were segmented and resampled to create a maximum of 500 unique four slice combinations, which we converted into image montages. The final training dataset consisted of 420 096 unique montages for algorithm training. We evaluated algorithm performance, reported as accuracy, prognostic accuracy, and weighted $\kappa$ coefficient ($\kappa$w) of interobserver agreement, on test set A and a cohort of 150 high-resolution CT scans (test set B) with fibrotic lung disease compared with the majority vote of 91 specialist thoracic radiologists drawn from multiple international thoracic imaging societies. We then reclassified high-resolution CT scans according to Fleischner Society diagnostic criteria for idiopathic pulmonary fibrosis. We retrained the algorithm using these criteria and evaluated its performance on 75 fibrotic lung disease specific high-resolution CT scans compared with four specialist thoracic radiologists using weighted $\kappa$ coefficient of interobserver agreement. Findings: The accuracy of the algorithm on test set A was 76{\textperiodcentered}4%, with 92{\textperiodcentered}7% of diagnoses within one category. The algorithm took 2{\textperiodcentered}31 s to evaluate 150 four slice montages (each montage representing a single case from test set B). The median accuracy of the thoracic radiologists on test set B was 70{\textperiodcentered}7% (IQR 65{\textperiodcentered}3â74{\textperiodcentered}7), and the accuracy of the algorithm was 73{\textperiodcentered}3% (93{\textperiodcentered}3% were within one category), outperforming 60 (66%) of 91 thoracic radiologists. Median interobserver agreement between each of the thoracic radiologists and the radiologist's majority opinion was good ($\kappa$w=0{\textperiodcentered}67 [IQR 0{\textperiodcentered}58â0{\textperiodcentered}72]). Interobserver agreement between the algorithm and the radiologist's majority opinion was good ($\kappa$w=0{\textperiodcentered}69), outperforming 56 (62%) of 91 thoracic radiologists. The algorithm provided equally prognostic discrimination between usual interstitial pneumonia and non-usual interstitial pneumonia diagnoses (hazard ratio 2{\textperiodcentered}88, 95% CI 1{\textperiodcentered}79â4{\textperiodcentered}61, p<0{\textperiodcentered}0001) compared with the majority opinion of the thoracic radiologists (2{\textperiodcentered}74, 1{\textperiodcentered}67â4{\textperiodcentered}48, p<0{\textperiodcentered}0001). For Fleischner Society high-resolution CT criteria for usual interstitial pneumonia, median interobserver agreement between the radiologists was moderate ($\kappa$w=0{\textperiodcentered}56 [IQR 0{\textperiodcentered}55â0{\textperiodcentered}58]), but was good between the algorithm and the radiologists ($\kappa$w=0{\textperiodcentered}64 [0{\textperiodcentered}55â0{\textperiodcentered}72]). Interpretation: High-resolution CT evaluation by a deep learning algorithm might provide low-cost, reproducible, near-instantaneous classification of fibrotic lung disease with human-level accuracy. These methods could be of benefit to centres at which thoracic imaging expertise is scarce, as well as for stratification of patients in clinical trials. Funding: None.},
author = {Walsh, Simon L.F. and Calandriello, Lucio and Silva, Mario and Sverzellati, Nicola},
doi = {10.1016/S2213-2600(18)30286-8},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Walsh et al. - 2018 - Deep learning for classifying fibrotic lung disease on high-resolution computed tomography a case-cohort study.pdf:pdf},
issn = {22132619},
journal = {The Lancet Respiratory Medicine},
month = {nov},
number = {11},
pages = {837--845},
pmid = {30232049},
publisher = {Lancet Publishing Group},
title = {{Deep learning for classifying fibrotic lung disease on high-resolution computed tomography: a case-cohort study}},
url = {http://www.thelancet.com/article/S2213260018302868/fulltext http://www.thelancet.com/article/S2213260018302868/abstract https://www.thelancet.com/journals/lanres/article/PIIS2213-2600(18)30286-8/abstract},
volume = {6},
year = {2018}
}
@article{Walsh2020,
abstract = {Over the past decade, there has been a groundswell of research interest in computer-based methods for objectively quantifying fibrotic lung disease on high resolution CT of the chest. In the past 5 years, the arrival of deep learning-based image analysis has created exciting new opportunities for enhancing the understanding of, and the ability to interpret, fibrotic lung disease on CT. Specific unsolved problems for which computer-based imaging analysis might provide solutions include the development of reliable methods for assisting with diagnosis, detecting early disease, and predicting disease behaviour using baseline imaging data. However, to harness this technology, technical and societal challenges must be overcome. Large CT datasets will be needed to power the training of deep learning algorithms. Open science research and collaboration between academia and industry must be encouraged. Prospective clinical utility studies will be needed to test computer algorithm performance in real-world clinical settings and demonstrate patient benefit over current best practice. Finally, ethical standards, which ensure patient confidentiality and mitigate against biases in training datasets, that can be encoded in machine-learning systems will be needed as well as bespoke data governance and accountability frameworks to encourage buy-in from health-care professionals, patients, and the public.},
author = {Walsh, Simon L.F. and Humphries, Stephen M. and Wells, Athol U. and Brown, Kevin K.},
doi = {10.1016/S2213-2600(20)30003-5},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Walsh et al. - 2020 - Imaging research in fibrotic lung disease applying deep learning to unsolved problems.pdf:pdf},
issn = {2213-2600},
journal = {The Lancet Respiratory Medicine},
month = {nov},
number = {11},
pages = {1144--1153},
pmid = {32109428},
publisher = {Elsevier},
title = {{Imaging research in fibrotic lung disease; applying deep learning to unsolved problems}},
volume = {8},
year = {2020}
}
@article{Barnes2023,
abstract = {Challenges for the effective management of interstitial lung diseases (ILDs) include difficulties with the early detection of disease, accurate prognostication with baseline data, and accurate and precise response to therapy. The purpose of this Review is to describe the clinical and research gaps in the diagnosis and prognosis of ILD, and how machine learning can be applied to image biomarker research to close these gaps. Machine-learning algorithms can identify ILD in at-risk populations, predict the extent of lung fibrosis, correlate radiological abnormalities with lung function decline, and be used as endpoints in treatment trials, exemplifying how this technology can be used in care for people with ILD. Advances in image processing and analysis provide further opportunities to use machine learning that incorporates deep-learning-based image analysis and radiomics. Collaboration and consistency are required to develop optimal algorithms, and candidate radiological biomarkers should be validated against appropriate predictors of disease outcomes.},
author = {Barnes, Hayley and Humphries, Stephen M. and George, Peter M. and Assayag, Deborah and Glaspole, Ian and Mackintosh, John A. and Corte, Tamera J. and Glassberg, Marilyn and Johannson, Kerri A. and Calandriello, Lucio and Felder, Federico and Wells, Athol and Walsh, Simon},
doi = {10.1016/S2589-7500(22)00230-8},
issn = {25897500},
journal = {The Lancet Digital Health},
month = {jan},
number = {1},
pages = {e41--e50},
pmid = {36517410},
publisher = {Elsevier Ltd},
title = {{Machine learning in radiology: the new frontier in interstitial lung diseases}},
volume = {5},
year = {2023}
}
@article{Walsh2022a,
abstract = {Rationale: Reliable outcome prediction in patients with fibrotic lung disease using baseline high-resolution computed tomography (HRCT) data remains challenging. Objectives: To evaluate the prognostic accuracy of a deep learning algorithm (SOFIA [Systematic Objective Fibrotic Imaging Analysis Algorithm]), trained and validated in the identification of usual interstitial pneumonia (UIP)-like features on HRCT (UIP probability), in a large cohort of well-characterized patients with progressive fibrotic lung disease drawn from a national registry. Methods: SOFIA and radiologist UIP probabilities were converted to Prospective Investigation of Pulmonary Embolism Diagnosis (PIOPED)-based UIP probability categories (UIP not included in the differential, 0-4%; low probability of UIP, 5-29%; intermediate probability of UIP, 30-69%; high probability of UIP, 70-94%; and pathognomonic for UIP, 95-100%), and their prognostic utility was assessed using Cox proportional hazards modeling. Measurements and Main Results: In multivariable analysis adjusting for age, sex, guideline-based radiologic diagnosis, anddisease severity (using total interstitial lung disease [ILD] extent on HRCT, percent predicted FVC, DlCO, or the composite physiologic index), only SOFIA UIP probability PIOPED categories predicted survival. SOFIA-PIOPED UIP probability categories remained prognostically significant in patients considered indeterminate (nâ=â83) by expert radiologist consensus (hazard ratio, 1.73; Pâ<â0.0001; 95% confidence interval, 1.40-2.14). In patients undergoing surgical lung biopsy (nâ=â86), after adjusting for guideline-based histologic pattern and total ILD extent on HRCT, only SOFIA-PIOPED probabilities were predictive of mortality (hazard ratio, 1.75; Pâ<â0.0001; 95% confidence interval, 1.37-2.25). Conclusions: Deep learning-based UIP probability on HRCT provides enhanced outcome prediction in patients with progressive fibrotic lung disease when compared with expert radiologist evaluation or guideline-based histologic pattern. In principle, this tool may be useful in multidisciplinary characterization of fibrotic lung disease. The utility of this technology as a decision support system when ILD expertise is unavailable requires further investigation.},
author = {Walsh, Simon L.F. and Mackintosh, John A. and Calandriello, Lucio and Silva, Mario and Sverzellati, Nicola and Larici, Anna Rita and Humphries, Stephen M. and Lynch, David A. and Jo, Helen E. and Glaspole, Ian and Grainge, Christopher and Goh, Nicole and Hopkins, Peter M.A. and Moodley, Yuben and Reynolds, Paul N. and Zappala, Christopher and Keir, Gregory and Cooper, Wendy A. and Mahar, Annabelle M. and Ellis, Samantha and Wells, Athol U. and Corte, Tamera J.},
doi = {10.1164/RCCM.202112-2684OC/SUPPL_FILE/DISCLOSURES.PDF},
issn = {15354970},
journal = {American journal of respiratory and critical care medicine},
keywords = {deep learning,idiopathic pulmonary fibrosis,interstitial lung disease,radiology,usual interstitial pneumonia},
month = {oct},
number = {7},
pages = {883--891},
pmid = {35696341},
publisher = {NLM (Medline)},
title = {{Deep Learning-based Outcome Prediction in Progressive Fibrotic Lung Disease Using High-Resolution Computed Tomography}},
volume = {206},
year = {2022}
}
@article{Sinko2018,
abstract = {In this article, we are combining an advanced implementation of the popular ICP algorithm using the transformation of 3D invariant properties based on 3D scale-invariant feature transform to register 3D free-form closed surfaces (3D model of the human skull). Unlike point and surface registers, our method based on the ICP algorithm better captures the bulk nature of data such as bone thickness. The proposed ICP algorithm is divided into three main steps: The 3D function extraction, comparison of the Euclidean metric distance and gross alignment and ICP enhancement. The input to our system are biomedical data (CT, MRI). Our proposed method first performs image segmentation and then 3D reconstruction of the human skull. In addition, 3D models for the point clouds (PCs) are created. Finally, the differences between point clouds of 3D models are visualized. We compare the performance of three different algorithms with their accuracy and robustness. The proposed solution is fast and accurate compared to the state of art in the field of reconstruction and registration of medical imagery. We apply our algorithm to study skull deformities. Experiments on skull models demonstrate the efficiency and robustness of our algorithm.},
author = {Sinko, Martin and Kamencay, Patrik and Hudec, Robert and Benco, Miroslav},
doi = {10.1109/ELEKTRO.2018.8398245},
isbn = {9781538647592},
journal = {12th International Conference ELEKTRO 2018, 2018 ELEKTRO Conference Proceedings},
keywords = {3D registration,CT,ICP,MRI,point cloud},
month = {jun},
pages = {1--6},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{3D registration of the point cloud data using ICP algorithm in medical image analysis}},
year = {2018}
}
@article{Abe2014,
abstract = {Several respiratory diseases, such as COPD and asthma, requires periodical checkups and past data comparison. While this kind of analysis is usually done by a medical expert, it depends greatly on the medical expertise and the image quality. Image registration, a technique which compares images volumes automatically using predefined computational algorithms, is a great tool to assist on diagnosis and disease surveillance. Most studies analyze the registration on 3D CT images slice-by-slice. However, by segmenting a 3D point clouds from the 3D CT volumes, it is possible to analyze the data in different and more accurate ways. This paper proposes a high speed algorithm improvement that calculates the rigid registration between two point clouds, adapting the Iterative Closest Point (ICP) algorithm to use 3D Voronoi diagrams for point correspondence determination, reducing the processing time greatly. A benchmark performance test is done with a point-by-point variation of the algorithm, showing that the proposed algorithm yield the same results with a considerable processing time reduction.},
author = {Abe, Leonardo Ishida and Iwao, Yuma and Gotoh, Toshiyuki and Kagei, Seiichiro and Takimoto, Rogerio Yugo and Tsuzuki, Marcos De Sales Guerra and Iwasawa, Tae},
doi = {10.1109/BMEI.2014.7002771},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Abe et al. - 2014 - High-speed point cloud matching algorithm for medical volume images using 3D Voronoi diagram.pdf:pdf},
isbn = {9781479958382},
journal = {Proceedings - 2014 7th International Conference on BioMedical Engineering and Informatics, BMEI 2014},
pages = {205--210},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{High-speed point cloud matching algorithm for medical volume images using 3D Voronoi diagram}},
year = {2014}
}
@article{Su2021,
abstract = {In this article, we use the parameter-adaptive Super4PCS algorithm to achieve high-precision registration of medical point clouds. First, generate the corresponding point cloud from the biological data (CT, MRI) to be registered. Then analyze the characteristics of the point cloud to be registered, and use it to adaptively set the parameters of Super4PCS, and finally perform point cloud registration. We compare the performance of six different algorithms with their accuracy and robustness. The accuracy, robustness of our method are the best. At the same time, no parameter input is required which is very convenient for medical workers. Experiments on medical models demonstrate the efficiency and robustness of our algorithm.},
author = {Su, Shun and Song, Guoli and Zhao, Yiwen},
doi = {10.1145/3506651.3506652},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Su, Song, Zhao - 2021 - 3D Registration of the Point Cloud Data Using Parameter Adaptive Super4PCS Algorithm in Medical Image Analysis.pdf:pdf},
isbn = {9781450386487},
journal = {ACM International Conference Proceeding Series},
keywords = {Medical image registration,Point cloud registration},
month = {nov},
pages = {1--6},
publisher = {Association for Computing Machinery},
title = {{3D Registration of the Point Cloud Data Using Parameter Adaptive Super4PCS Algorithm in Medical Image Analysis}},
url = {https://dl.acm.org/doi/10.1145/3506651.3506652},
year = {2021}
}


@article{Stoel2020,
abstract = {After decades of basic research with many setbacks, artificial intelligence (AI) has recently obtained significant breakthroughs, enabling computer programs to outperform human interpretation of medical images in very specific areas. After this shock wave that probably exceeds the impact of the first AI victory of defeating the world chess champion in 1997, some reflection may be appropriate on the consequences for clinical imaging in rheumatology. In this narrative review, a short explanation is given about the various AI techniques, including âdeep learning', and how these have been applied to rheumatological imaging, focussing on rheumatoid arthritis and systemic sclerosis as examples. By discussing the principle limitations of AI and deep learning, this review aims to give insight into possible future perspectives of AI applications in rheumatology.},
author = {Stoel, Berend and Stoel@, ; B C},
doi = {10.1136/RMDOPEN-2019-001063},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Stoel, Stoel@ - 2020 - Use of artificial intelligence in imaging in rheumatology â current status and future perspectives.pdf:pdf},
isbn = {2019001063},
issn = {2056-5933},
journal = {RMD Open},
keywords = {magnetic resonance imaging,outcomes research,rheumatoid arthritis,systemic sclerosis},
month = {jan},
number = {1},
pages = {e001063},
pmid = {31958283},
publisher = {BMJ Specialist Journals},
title = {{Use of artificial intelligence in imaging in rheumatology â current status and future perspectives}},
url = {https://rmdopen.bmj.com/content/6/1/e001063 https://rmdopen.bmj.com/content/6/1/e001063.abstract},
volume = {6},
year = {2020}
}

@article{Simonyan2014,
abstract = {In this work we investigate the effect of the convolutional network depth on
its accuracy in the large-scale image recognition setting. Our main
contribution is a thorough evaluation of networks of increasing depth using an
architecture with very small (3x3) convolution filters, which shows that a
significant improvement on the prior-art configurations can be achieved by
pushing the depth to 16-19 weight layers. These findings were the basis of our
ImageNet Challenge 2014 submission, where our team secured the first and the
second places in the localisation and classification tracks respectively. We
also show that our representations generalise well to other datasets, where
they achieve state-of-the-art results. We have made our two best-performing
ConvNet models publicly available to facilitate further research on the use of
deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
doi = {10.48550/arxiv.1409.1556},
eprint = {1409.1556},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2014 - Very Deep Convolutional Networks for Large-Scale Image Recognition.pdf:pdf},
journal = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
keywords = {()},
month = {sep},
publisher = {International Conference on Learning Representations, ICLR},
title = {{Very Deep Convolutional Networks for Large-Scale Image Recognition}},
url = {https://arxiv.org/abs/1409.1556v6},
year = {2014}
}


@article{Bass2021,
abstract = {An important goal of medical imaging is to be able to precisely detect patterns of disease specific to individual scans; however, this is challenged in brain imaging by the degree of heterogeneity of shape and appearance. Traditional methods, based on image registration to a global template, historically fail to detect variable features of disease, as they utilise population-based analyses, suited primarily to studying group-average effects. In this paper we therefore take advantage of recent developments in generative deep learning to develop a method for simultaneous classification, or regression, and feature attribution (FA). Specifically, we explore the use of a VAE-GAN translation network called ICAM, to explicitly disentangle class relevant features from background confounds for improved interpretability and regression of neurological phenotypes. We validate our method on the tasks of Mini-Mental State Examination (MMSE) cognitive test score prediction for the Alzheimer's Disease Neuroimaging Initiative (ADNI) cohort, as well as brain age prediction, for both neurodevelopment and neurodegeneration, using the developing Human Connectome Project (dHCP) and UK Biobank datasets. We show that the generated FA maps can be used to explain outlier predictions and demonstrate that the inclusion of a regression module improves the disentanglement of the latent space. Our code is freely available on Github https://github.com/CherBass/ICAM.},
archivePrefix = {arXiv},
arxivId = {2103.02561},
author = {Bass, Cher and da Silva, Mariana and Sudre, Carole and Williams, Logan Z. J. and Tudosiu, Petru-Daniel and Alfaro-Almagro, Fidel and Fitzgibbon, Sean P. and Glasser, Matthew F. and Smith, Stephen M. and Robinson, Emma C.},
eprint = {2103.02561},
file = {:C\:/Users/jjia/Downloads/2103.02561.pdf:pdf},
number = {Xx},
pages = {1--13},
title = {{ICAM-reg: Interpretable Classification and Regression with Feature Attribution for Mapping Neurological Phenotypes in Individual Scans}},
url = {http://arxiv.org/abs/2103.02561},
volume = {XX},
year = {2021}
}
@article{Kidzinski2020,
abstract = {Many neurological and musculoskeletal diseases impair movement, which limits people's function and social participation. Quantitative assessment of motion is critical to medical decision-making but is currently possible only with expensive motion capture systems and highly trained personnel. Here, we present a method for predicting clinically relevant motion parameters from an ordinary video of a patient. Our machine learning models predict parameters include walking speed (râ=â0.73), cadence (râ=â0.79), knee flexion angle at maximum extension (râ=â0.83), and Gait Deviation Index (GDI), a comprehensive metric of gait impairment (râ=â0.75). These correlation values approach the theoretical limits for accuracy imposed by natural variability in these metrics within our patient population. Our methods for quantifying gait pathology with commodity cameras increase access to quantitative motion analysis in clinics and at home and enable researchers to conduct large-scale studies of neurological and musculoskeletal disorders. In the context of diseases impairing movement, quantitative assessment of motion is critical to medical decision-making but is currently possible only with expensive motion capture systems and trained personnel. Here, the authors present a method for predicting clinically relevant motion parameters from an ordinary video of a patient.},
author = {Kidzi{\'{n}}ski, {\L}ukasz and Yang, Bryan and Hicks, Jennifer L. and Rajagopal, Apoorva and Delp, Scott L. and Schwartz, Michael H.},
doi = {10.1038/s41467-020-17807-z},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kidzi{\'{n}}ski et al. - 2020 - Deep neural networks enable quantitative movement analysis using single-camera videos.pdf:pdf},
issn = {2041-1723},
journal = {Nature Communications 2020 11:1},
keywords = {Data processing,Diagnostic markers,Machine learning,Movement disorders},
month = {aug},
number = {1},
pages = {1--10},
pmid = {32792511},
publisher = {Nature Publishing Group},
title = {{Deep neural networks enable quantitative movement analysis using single-camera videos}},
url = {https://www.nature.com/articles/s41467-020-17807-z},
volume = {11},
year = {2020}
}
@article{zhang2019balance,
author = {Zhang, Junjie and Liu, Lingqiao and Wang, Peng and Shen, Chunhua},
journal = {arXiv preprint arXiv:1912.04486},
title = {{To balance or not to balance: A simple-yet-effective approach for learning with long-tailed distributions}},
year = {2019}
}
@inproceedings{shadmi2018fully,
author = {Shadmi, Ran and Mazo, Victoria and Bregman-Amitai, Orna and Elnekave, Eldad},
booktitle = {2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI 2018)},
organization = {IEEE},
pages = {24--28},
title = {{Fully-convolutional deep-learning based system for coronary calcium score prediction from non-contrast chest CT}},
year = {2018}
}
@inproceedings{huang2017densely,
author = {Huang, Gao and Liu, Zhuang and {Van Der Maaten}, Laurens and Weinberger, Kilian Q},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
pages = {4700--4708},
title = {{Densely connected convolutional networks}},
year = {2017}
}
@inproceedings{zhang2018shufflenet,
author = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
pages = {6848--6856},
title = {{Shufflenet: An extremely efficient convolutional neural network for mobile devices}},
year = {2018}
}
@inproceedings{xie2017aggregated,
author = {Xie, Saining and Girshick, Ross and Doll{\'{a}}r, Piotr and Tu, Zhuowen and He, Kaiming},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
pages = {1492--1500},
title = {{Aggregated residual transformations for deep neural networks}},
year = {2017}
}
@article{iandola2016squeezenet,
author = {Iandola, Forrest N and Han, Song and Moskewicz, Matthew W and Ashraf, Khalid and Dally, William J and Keutzer, Kurt},
journal = {arXiv preprint arXiv:1602.07360},
title = {{SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 0.5 MB model size}},
year = {2016}
}
@article{simonyan2014very,
author = {Simonyan, Karen and Zisserman, Andrew},
journal = {arXiv preprint arXiv:1409.1556},
title = {{Very deep convolutional networks for large-scale image recognition}},
year = {2014}
}
@inproceedings{he2016deep,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
pages = {770--778},
title = {{Deep residual learning for image recognition}},
year = {2016}
}
@inproceedings{zeiler2014visualizing,
author = {Zeiler, Matthew D and Fergus, Rob},
booktitle = {European conference on computer vision},
organization = {Springer},
pages = {818--833},
title = {{Visualizing and understanding convolutional networks}},
year = {2014}
}

@article{Graham,
abstract = {@ERSpublications Updated technical standards for measuring DLCO (TLCO) including the use of rapid gas analyser systems http://ow.ly/QUhv304PMsy Cite this article as: Graham BL, Brusasco V, Burgos F, et al. 2017 ERS/ATS standards for single-breath carbon monoxide uptake in the lung. Eur Respir J 2017; 49: 1600016 [https://doi. ABSTRACT This document provides an update to the European Respiratory Society (ERS)/American Thoracic Society (ATS) technical standards for single-breath carbon monoxide uptake in the lung that was last updated in 2005. Although both DLCO (diffusing capacity) and TLCO (transfer factor) are valid terms to describe the uptake of carbon monoxide in the lung, the term DLCO is used in this document. A joint taskforce appointed by the ERS and ATS reviewed the recent literature on the measurement of DLCO and surveyed the current technical capabilities of instrumentation being manufactured around the world. The recommendations in this document represent the consensus of the taskforce members in regard to the evidence available for various aspects of DLCO measurement. Furthermore, it reflects the expert opinion of the taskforce members on areas in which peer-reviewed evidence was either not available or was incomplete. The major changes in these technical standards relate to DLCO measurement with systems using rapidly responding gas analysers for carbon monoxide and the tracer gas, which are now the most common type of DLCO instrumentation being manufactured. Technical improvements and the increased capability afforded by these new systems permit enhanced measurement of DLCO and the opportunity to include other optional measures of lung function.},
author = {Graham, Brian L and Brusasco, Vito and Burgos, Felip and Cooper, Brendan G and Jensen, Robert and Kendrick, Adrian and Macintyre, Neil R and Thompson, Bruce R and Wanger, Jack},
doi = {10.1183/13993003.00016-2016},
title = {{2017 ERS/ATS standards for single-breath carbon monoxide uptake in the lung}},
url = {https://doi.org/10.1183/13993003.00016-2016}
}

@article{Zhang2017,
abstract = {We introduce an extremely computation-efficient CNN architecture named
ShuffleNet, which is designed specially for mobile devices with very limited
computing power (e.g., 10-150 MFLOPs). The new architecture utilizes two new
operations, pointwise group convolution and channel shuffle, to greatly reduce
computation cost while maintaining accuracy. Experiments on ImageNet
classification and MS COCO object detection demonstrate the superior
performance of ShuffleNet over other structures, e.g. lower top-1 error
(absolute 7.8%) than recent MobileNet on ImageNet classification task, under
the computation budget of 40 MFLOPs. On an ARM-based mobile device, ShuffleNet
achieves $\sim$13x actual speedup over AlexNet while maintaining comparable
accuracy.},
archivePrefix = {arXiv},
arxivId = {1707.01083},
author = {Zhang, Xiangyu and Zhou, Xinyu and Lin, Mengxiao and Sun, Jian},
doi = {10.48550/arxiv.1707.01083},
eprint = {1707.01083},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - 2017 - ShuffleNet An Extremely Efficient Convolutional Neural Network for Mobile Devices.pdf:pdf},
isbn = {9781538664209},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
month = {jul},
pages = {6848--6856},
publisher = {IEEE Computer Society},
title = {{ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices}},
url = {https://arxiv.org/abs/1707.01083v2},
year = {2017}
}
@article{Huang2016,
abstract = {Recent work has shown that convolutional networks can be substantially
deeper, more accurate, and efficient to train if they contain shorter
connections between layers close to the input and those close to the output. In
this paper, we embrace this observation and introduce the Dense Convolutional
Network (DenseNet), which connects each layer to every other layer in a
feed-forward fashion. Whereas traditional convolutional networks with L layers
have L connections - one between each layer and its subsequent layer - our
network has L(L+1)/2 direct connections. For each layer, the feature-maps of
all preceding layers are used as inputs, and its own feature-maps are used as
inputs into all subsequent layers. DenseNets have several compelling
advantages: they alleviate the vanishing-gradient problem, strengthen feature
propagation, encourage feature reuse, and substantially reduce the number of
parameters. We evaluate our proposed architecture on four highly competitive
object recognition benchmark tasks (CIFAR-10, CIFAR-100, SVHN, and ImageNet).
DenseNets obtain significant improvements over the state-of-the-art on most of
them, whilst requiring less computation to achieve high performance. Code and
pre-trained models are available at https://github.com/liuzhuang13/DenseNet .},
archivePrefix = {arXiv},
arxivId = {1608.06993},
author = {Huang, Gao and Liu, Zhuang and {Van Der Maaten}, Laurens and Weinberger, Kilian Q.},
doi = {10.48550/arxiv.1608.06993},
eprint = {1608.06993},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Huang et al. - 2016 - Densely Connected Convolutional Networks.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
month = {aug},
pages = {2261--2269},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Densely Connected Convolutional Networks}},
url = {https://arxiv.org/abs/1608.06993v5},
volume = {2017-Janua},
year = {2016}
}
@inproceedings{Xie2016,
abstract = {We present a simple, highly modularized network architecture for image classification. Our network is constructed by repeating a building block that aggregates a set of transformations with the same topology. Our simple design results in a homogeneous, multi-branch architecture that has only a few hyper-parameters to set. This strategy exposes a new dimension, which we call "cardinality" (the size of the set of transformations), as an essential factor in addition to the dimensions of depth and width. On the ImageNet-1K dataset, we empirically show that even under the restricted condition of maintaining complexity, increasing cardinality is able to improve classification accuracy. Moreover, increasing cardinality is more effective than going deeper or wider when we increase the capacity. Our models, named ResNeXt, are the foundations of our entry to the ILSVRC 2016 classification task in which we secured 2nd place. We further investigate ResNeXt on an ImageNet-5K set and the COCO detection set, also showing better results than its ResNet counterpart. The code and models are publicly available online.},
archivePrefix = {arXiv},
arxivId = {1611.05431},
author = {Xie, Saining and Girshick, Ross and Doll{\'{a}}r, Piotr and Tu, Zhuowen and He, Kaiming},
booktitle = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
doi = {10.48550/arxiv.1611.05431},
eprint = {1611.05431},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2016 - Aggregated Residual Transformations for Deep Neural Networks.pdf:pdf},
isbn = {9781538604571},
month = {nov},
pages = {5987--5995},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Aggregated Residual Transformations for Deep Neural Networks}},
url = {https://arxiv.org/abs/1611.05431v2},
volume = {2017-Janua},
year = {2016}
}
@article{Iandola2016,
abstract = {Recent research on deep neural networks has focused primarily on improving
accuracy. For a given accuracy level, it is typically possible to identify
multiple DNN architectures that achieve that accuracy level. With equivalent
accuracy, smaller DNN architectures offer at least three advantages: (1)
Smaller DNNs require less communication across servers during distributed
training. (2) Smaller DNNs require less bandwidth to export a new model from
the cloud to an autonomous car. (3) Smaller DNNs are more feasible to deploy on
FPGAs and other hardware with limited memory. To provide all of these
advantages, we propose a small DNN architecture called SqueezeNet. SqueezeNet
achieves AlexNet-level accuracy on ImageNet with 50x fewer parameters.
Additionally, with model compression techniques we are able to compress
SqueezeNet to less than 0.5MB (510x smaller than AlexNet). The SqueezeNet architecture is available for download here:
https://github.com/DeepScale/SqueezeNet},
archivePrefix = {arXiv},
arxivId = {1602.07360},
author = {Iandola, Forrest N. and Han, Song and Moskewicz, Matthew W. and Ashraf, Khalid and Dally, William J. and Keutzer, Kurt},
doi = {10.48550/arxiv.1602.07360},
eprint = {1602.07360},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Iandola et al. - 2016 - SqueezeNet AlexNet-level accuracy with 50x fewer parameters and 0.5MB model size.pdf:pdf},
month = {feb},
title = {{SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size}},
url = {https://arxiv.org/abs/1602.07360v4},
year = {2016}
}
@article{He,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8Ã deeper than VGG nets [41] but still having lower complexity. An ensemble of these residual nets achieves 3.57% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC & COCO 2015 competitions 1 , where we also won the 1st places on the tasks of ImageNet detection, ImageNet local-ization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385v1},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
eprint = {1512.03385v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - Unknown - Deep Residual Learning for Image Recognition.pdf:pdf},
title = {{Deep Residual Learning for Image Recognition}},
url = {http://image-net.org/challenges/LSVRC/2015/}
}
@article{Sarvamangala2022,
abstract = {Imaging techniques are used to capture anomalies of the human body. The captured images must be understood for diagnosis, prognosis and treatment planning of the anomalies. Medical image understanding is generally performed by skilled medical professionals. However, the scarce availability of human experts and the fatigue and rough estimate procedures involved with them limit the effectiveness of image understanding performed by skilled medical professionals. Convolutional neural networks (CNNs) are effective tools for image understanding. They have outperformed human experts in many image understanding tasks. This article aims to provide a comprehensive survey of applications of CNNs in medical image understanding. The underlying objective is to motivate medical image understanding researchers to extensively apply CNNs in their research and diagnosis. A brief introduction to CNNs has been presented. A discussion on CNN and its various award-winning frameworks have been presented. The major medical image understanding tasks, namely image classification, segmentation, localization and detection have been introduced. Applications of CNN in medical image understanding of the ailments of brain, breast, lung and other organs have been surveyed critically and comprehensively. A critical discussion on some of the challenges is also presented.},
author = {Sarvamangala, D. R. and Kulkarni, Raghavendra V.},
doi = {10.1007/S12065-020-00540-3/FIGURES/2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sarvamangala, Kulkarni - 2022 - Convolutional neural networks in medical image understanding a survey.pdf:pdf},
issn = {18645917},
journal = {Evolutionary Intelligence},
keywords = {Classification,Convolutional neural networks,Detection,Image understanding,Localization,Segmentation},
month = {mar},
number = {1},
pages = {1--22},
publisher = {Springer Science and Business Media Deutschland GmbH},
title = {{Convolutional neural networks in medical image understanding: a survey}},
url = {https://link.springer.com/article/10.1007/s12065-020-00540-3},
volume = {15},
year = {2022}
}
@article{EWilliams2022,
abstract = {<h2>Summary</h2><h3>Background</h3><p>Symptomatic hand osteoarthritis is more common in women than in men, and its incidence increases around the age of menopause, implicating oestrogen deficiency. No randomised controlled trials of hormone replacement therapy (HRT) have been done in people with hand osteoarthritis. We aimed to determine the feasibility and acceptability of a form of HRT (conjugated oestrogens plus bazedoxifene) in post-menopausal women with painful hand osteoarthritis.</p><h3>Methods</h3><p>The HOPE-e feasibility study was a randomised, double-blind, placebo-controlled trial, for which we recruited women aged 40â65 years, for whom 1â10 years had passed after their final menstrual period, with definite hand osteoarthritis and at least two painful hand joints. Participants were recruited across three primary or secondary care sites and from the community and were randomly assigned (1:1) to receive conjugated oestrogens plus bazedoxifene or placebo, orally once every day for 24 weeks, before weaning for 4 weeks until the end of the study. The primary feasibility outcomes were rates of identification, recruitment, randomisation, retention, and compliance of eligible participants, and the likelihood of unmasking. The secondary objective was to generate proof-of-concept quantitative and qualitative data on the acceptability of proposed clinical outcomes for a full trial and adverse events. We used an intention-to-treat analysis, and criteria for progression to a full trial were pre-defined as recruitment of at least 30 participants across all sites in 18 months; a dropout rate of less than or equal to 30% of randomised individuals; and acceptability to the majority of participants, including acceptable rates of adverse events. Due to the COVID-19 pandemic, the recruitment window was reduced to 12â15 months. A proportionately reduced minimum sample size of 22 was judged to be sufficient to test feasibility. This trial was registered at ISRCTN, ISRCTN12196200.</p><h3>Findings</h3><p>From May 9, 2019 to Dec 31, 2020, 434 enquiries or referrals were received. We did 96 telephone pre-screens; of the 35 eligible participants, seven were excluded as ineligible at the telephone or face-to-face screening and 28 (80% [95% CI 63â92]) were randomly assigned. Of the 406 who were not randomly assigned, 250 (62%) were ineligible (with contraindicated medications accounting for 50 [20%] of these), 101 (25%) did not respond to further enquiries, and 55 (14%) chose not to proceed (with the most common reason being not wanting to take a hormone-based drug). All 28 randomised participants completed all follow-up assessments with high compliance and outcome measure completeness. All three adverse event-related treatment withdrawals were in the placebo group. No serious adverse events were reported. Participants and investigators were successfully masked (participant Bang's blinding index placebo group 0{\textperiodcentered}50 [95% CI 0{\textperiodcentered}25â0{\textperiodcentered}75]). The trial met the prespecified criteria for progression to a full trial.</p><h3>Interpretation</h3><p>This first-ever feasibility study of a randomised controlled trial of HRT for post-menopausal women with painful hand osteoarthritis met its progression criteria, although it was not powered to detect a clinical effect. This outcome indicates that a full trial of an HRT in this population is feasible and acceptable and identifies potential refinements with regard to the design of such a trial.</p><h3>Funding</h3><p>Research for Patient Benefit programme, National Institute for Health Research.</p>},
author = {{E Williams}, J A and Goff, M V and Francis, A and Eldridge, L and Julier, P and Barber, V S and Black, J and Chester-Jones, M and Marian, I and Dutton, S J and {E Williams}, Jennifer A and Chester-Jones, Mae and {Minns Lowe}, Catherine and Goff, Megan V and Francis, Anne and Brewer, Gretchen and Marian, Ioana and Morris, Susan L and Warwick, Debbie and Eldridge, Lucy and Julier, Patrick and Gulati, Malvika and Barker, Karen L and Barber, Vicki S and Black, Joanna and Woollacott, Sue and Mackworth-Young, Charles and Glover, Vicki and Lamb, Sarah E and Vincent, Tonia L and Vincent, Katy and Dutton, Susan J and Watt, Fiona E},
doi = {10.1016/S2665-9913(22)00218-1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/E Williams et al. - 2022 - Hormone replacement therapy (conjugated oestrogens plus bazedoxifene) for post-menopausal women with symptoma.pdf:pdf},
issn = {2665-9913},
journal = {The Lancet Rheumatology},
month = {oct},
number = {10},
pages = {e725--e737},
publisher = {Elsevier},
title = {{Hormone replacement therapy (conjugated oestrogens plus bazedoxifene) for post-menopausal women with symptomatic hand osteoarthritis: primary report from the HOPE-e randomised, placebo-controlled, feasibility study}},
url = {http://www.thelancet.com/article/S2665991322002181/fulltext http://www.thelancet.com/article/S2665991322002181/abstract https://www.thelancet.com/journals/lanrhe/article/PIIS2665-9913(22)00218-1/abstract},
volume = {4},
year = {2022}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual
learning framework to ease the training of networks that are substantially
deeper than those used previously. We explicitly reformulate the layers as
learning residual functions with reference to the layer inputs, instead of
learning unreferenced functions. We provide comprehensive empirical evidence
showing that these residual networks are easier to optimize, and can gain
accuracy from considerably increased depth. On the ImageNet dataset we evaluate
residual nets with a depth of up to 152 layers---8x deeper than VGG nets but
still having lower complexity. An ensemble of these residual nets achieves
3.57% error on the ImageNet test set. This result won the 1st place on the
ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100
and 1000 layers. The depth of representations is of central importance for many visual
recognition tasks. Solely due to our extremely deep representations, we obtain
a 28% relative improvement on the COCO object detection dataset. Deep residual
nets are foundations of our submissions to ILSVRC & COCO 2015 competitions,
where we also won the 1st places on the tasks of ImageNet detection, ImageNet
localization, COCO detection, and COCO segmentation.},
archivePrefix = {arXiv},
arxivId = {1512.03385},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
doi = {10.48550/arxiv.1512.03385},
eprint = {1512.03385},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/He et al. - 2015 - Deep Residual Learning for Image Recognition.pdf:pdf},
isbn = {9781467388504},
issn = {10636919},
journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
month = {dec},
pages = {770--778},
publisher = {IEEE Computer Society},
title = {{Deep Residual Learning for Image Recognition}},
url = {https://arxiv.org/abs/1512.03385v1},
volume = {2016-Decem},
year = {2015}
}
@article{,
abstract = {â¢ You should upload your covering letter at the "Enter Comments" stage of the online submission process â¢ Use the covering letter to explain why your paper should be published in The Lancet Rheumatology rather than elsewhere and state if you wish for it to be considered for fast-track publication â¢ It is helpful to indicate what could shorten your paper-the full paper can be reviewed and a shorter version published; a table or figure, details of a DNA sequence, or further references, for example, can be published on our website or made available from the authors Recommendations for the Conduct, Reporting, Editing, and Publication of Scholarly Work in Medical Journals http://www.icmje.org COPE Core Practices https://publicationethics.org/ core-practices The Lancet Rheumatology considers any original research contribution that illuminates or influences clinical practice, directly informs future clinical trials, or substantively improves our understanding of disease processes. The Lancet Rheumatology also publishes interesting and informative reviews on any topic within the spectrum of rheumatology. Manuscripts must be solely the work of the author(s) stated, must not have been previously published elsewhere, and must not be under consideration by another journal. All papers should be written to be clearly understandable to the journal's readers in a wide range of specialties and countries. For detailed guidance on preparing and submitting your manuscript to The Lancet Rheumatology, please visit TheLancet.com for authors, which provides information, forms, and details to support your experience and assist with the submission process The journal publishes a range of article types that encompass all aspects of rheumatology: Comment, Correspondence, News, Article, Review, Health Policy, and Viewpoint. All original research judged eligible for fast-track publication by the journal's editors will be peer-reviewed within 3-5 days and, if accepted, published within 10 weeks from submission. A majority of accepted fast-track Articles are published online first before appearing in a print journal. The Lancet is a signatory journal to the Recommendations for the Conduct, Reporting, Editing, and Publication of Scholarly Work in Medical Journals, issued by the International Committee of Medical Journal Editors (ICMJE Recommendations), and to the Committee on Publication Ethics (COPE) code of conduct for editors. We follow COPE's guidelines. The Lancet's editorial policies evolve in line with best practice in the sector as well as the changing nature of scientific research and scholarly publishing. When relevant, Lancet editors may publish updates to our policies, which may go beyond the requirements of the ICMJE. We are committed to ensuring that our editorial processes meet our standards of excellence. Publishing your work with The Lancet Rheumatology means partnering with an editorially independent journal committed to improving lives, increasing the social impact of science, and maintaining the highest standards of medical science. Each submission is treated individually, but most research papers follow a similar path of submission, review, revision, editing, production, and publication.},
doi = {10.1016/S2589-7500(20)30218-1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2022 - Information for Authors Covering letter.pdf:pdf},
title = {{Information for Authors Covering letter}},
url = {http://clinicaltrials.gov},
year = {2022}
}
@article{Sim2005,
abstract = {Purpose. This article examines and illustrates the use and interpretation of the kappa statistic in musculoskeletal research. Summary of Key Points. The reliability of clinicians' ratings is an important consideration in areas such as diagnosis and the interpretation of examination findings. Often, these ratings lie on a nominal or an ordinal scale. For such data, the kappa coefficient is an appropriate measure of reliability. Kappa is defined, in both weighted and unweighted forms, and its use is illustrated with examples from musculoskeletal research. Factors that can influence the magnitude of kappa (prevalence, bias, and nonindependent ratings) are discussed, and ways of evaluating the magnitude of an obtained kappa are considered. The issue of statistical testing of kappa is considered, including the use of confidence intervals, and appropriate sample sizes for reliability studies using kappa are tabulated. Conclusions. The article concludes with recommendations for the use and interpretation of kappa.},
author = {Sim, Julius and Wright, Chris C.},
doi = {10.1093/PTJ/85.3.257},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sim, Wright - 2005 - The Kappa Statistic in Reliability Studies Use, Interpretation, and Sample Size Requirements.pdf:pdf},
issn = {0031-9023},
journal = {Physical Therapy},
keywords = {Kappa,Measurement,Reliability,Sample size},
month = {mar},
number = {3},
pages = {257--268},
pmid = {15733050},
publisher = {Oxford Academic},
title = {{The Kappa Statistic in Reliability Studies: Use, Interpretation, and Sample Size Requirements}},
url = {https://academic.oup.com/ptj/article/85/3/257/2805022},
volume = {85},
year = {2005}
}
@article{Herzog2014,
author = {Herzog, Erica L. and Mathur, Aditi and Tager, Andrew M. and Feghali-Bostwick, Carol and Schneider, Frank and Varga, John},
doi = {10.1002/ART.38702},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Herzog et al. - 2014 - Interstitial Lung Disease Associated With Systemic Sclerosis and Idiopathic Pulmonary Fibrosis How Similar and Di.pdf:pdf},
issn = {23265205},
journal = {Arthritis & rheumatology (Hoboken, N.J.)},
number = {8},
pages = {1967},
pmid = {24838199},
publisher = {NIH Public Access},
title = {{Interstitial Lung Disease Associated With Systemic Sclerosis and Idiopathic Pulmonary Fibrosis: How Similar and Distinct?}},
url = {/pmc/articles/PMC4340472/ https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4340472/},
volume = {66},
year = {2014}
}
@inproceedings{Jia2022,
abstract = {Visually scoring lung involvement in systemic sclerosis (SSc) from CT scans plays an important role in monitoring progression, but its labor intensiveness hinders practical application. We proposed, therefore, an automatic scoring framework that consists of two cascaded deep regression neural networks. The first (3D) network aims to predict the craniocaudal position of five anatomically defined scoring levels on the 3D CT scans. The second (2D) network receives the resulting 2D axial slices and predicts the scores, which represent the extent of SSc disease. CT scans from 227 patients were used for both networks. 180 scans were split into four groups with equal number of samples to perform four-fold cross validation and an additional set of 47 scans constitute a separate testing dataset. Two experts scored all CT data in consensus and to obtain inter-observer variabilities they also scored independently 16 patients from the testing dataset. To alleviate the unbalance in training labels in the second network, we introduced a balanced sampling technique and to increase the diversity of the training samples, synthetic data was generated, mimicking ground glass and reticulation patterns. The four-fold cross validation results showed that our proposed score prediction network achieved an average MAE of 5.90, 4.66 and 4.49%, weighted kappa of 0.66, 0.58 and 0.65 for total score (TOT), ground glass (GG) and reticular pattern (RET), respectively. Our network performed slightly worse than the best human observation on TOT and GG prediction but it has competitive performance on RET prediction and has the potential to be an objective alternative for the visual scoring of SSc in CT thorax studies.},
author = {Jia, Jingnan and Staring, Marius and Gir{\'{o}}n, Irene H. and Kroft, Lucia J. and Schouffoer, Anne A. and Stoel, Berend C.},
booktitle = {Medical Imaging 2022: Computer-Aided Diagnosis},
doi = {10.1117/12.2602737},
isbn = {9781510649415},
issn = {16057422},
keywords = {3D scanning,Computed tomography,Glasses,Lung,Neural networks,Opacity,Reliability,Visualization},
pages = {837----843},
publisher = {SPIE},
title = {{Prediction of lung CT scores of systemic sclerosis by cascaded regression neural networks}},
url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12033/1203338/Prediction-of-lung-CT-scores-of-systemic-sclerosis-by-cascaded/10.1117/12.2602737.full https://www.spiedigitallibrary.org/conference-proceedings-of-spie/12033/1203338/Predicti},
volume = {12033},
year = {2022}
}
@article{Hoffmann-Vold2020,
abstract = {Background: Systemic sclerosis-associated interstitial lung disease (ILD) carries a high mortality risk; expert guidance is required to aid early recognition and treatment. We aimed to develop the first expert consensus and define an algorithm for the identification and management of the condition through application of well established methods. Methods: Evidence-based consensus statements for systemic sclerosis-associated ILD management were established for six domains (ie, risk factors, screening, diagnosis and severity assessment, treatment initiation and options, disease progression, and treatment escalation) using a modified Delphi process based on a systematic literature analysis. A panel of 27 Europe-based pulmonologists, rheumatologists, and internists with expertise in systemic sclerosis-associated ILD participated in three rounds of online surveys, a face-to-face discussion, and a WebEx meeting, followed by two supplemental Delphi rounds, to establish consensus and define a management algorithm. Consensus was considered achieved if at least 80% of panellists indicated agreement or disagreement. Findings: Between July 1, 2018, and Aug 27, 2019, consensus agreement was reached for 52 primary statements and six supplemental statements across six domains of management, and an algorithm was defined for clinical practice use. The agreed statements most important for clinical use included: all patients with systemic sclerosis should be screened for systemic sclerosis-associated ILD using high-resolution CT; high-resolution CT is the primary tool for diagnosing ILD in systemic sclerosis; pulmonary function tests support screening and diagnosis; systemic sclerosis-associated ILD severity should be measured with more than one indicator; it is appropriate to treat all severe cases; no pharmacological treatment is an option for some patients; follow-up assessments enable identification of disease progression; progression pace, alongside disease severity, drives decisions to escalate treatment. Interpretation: Through a robust modified Delphi process developed by a diverse panel of experts, the first evidence-based consensus statements were established on guidance for the identification and medical management of systemic sclerosis-associated ILD. Funding: An unrestricted grant from Boehringer Ingelheim International.},
author = {Hoffmann-Vold, Anna Maria and Maher, Toby M. and Philpot, Edward E. and Ashrafzadeh, Ali and Barake, Rafic and Barsotti, Simone and Bruni, Cosimo and Carducci, Paolo and Carreira, Patricia E. and Castellv{\'{i}}, Ivan and {Del Galdo}, Francesco and Distler, J{\"{o}}rg H.W. and Foeldvari, Ivan and Fraticelli, Paolo and George, Peter M. and Griffiths, Bridget and Guill{\'{e}}n-Del-Castillo, Alfredo and Hamid, Abdul Monem and Horv{\'{a}}th, Rudolf and Hughes, Michael and Kreuter, Michael and Moazedi-Fuerst, Florentine and Olas, Jacek and Paul, Suman and Rotondo, Cinzia and Rubio-Rivas, Manuel and Seferian, Andrei and Tom{\v{c}}{\'{i}}k, Michal and Uzunhan, Yurdag{\"{u}}l and Walker, Ulrich A. and Wi{\c{e}}sik-Szewczyk, Ewa and Distler, Oliver},
doi = {10.1016/S2665-9913(19)30144-4},
issn = {26659913},
journal = {The Lancet Rheumatology},
month = {feb},
number = {2},
pages = {e71--e83},
publisher = {Lancet Publishing Group},
title = {{The identification and management of interstitial lung disease in systemic sclerosis: evidence-based European consensus statements}},
volume = {2},
year = {2020}
}
@article{TheLancetRheumatology2019,
author = {{The Lancet Rheumatology}},
doi = {10.1016/S2665-9913(19)30001-3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/The Lancet Rheumatology - 2019 - The Lancet Rheumatologyâtackling heterogeneity and embracing diversity.pdf:pdf},
issn = {26659913},
journal = {The Lancet Rheumatology},
month = {sep},
number = {1},
pages = {e1},
publisher = {Lancet Publishing Group},
title = {{The Lancet Rheumatologyâtackling heterogeneity and embracing diversity}},
url = {http://www.thelancet.com/article/S2665991319300013/fulltext http://www.thelancet.com/article/S2665991319300013/abstract https://www.thelancet.com/journals/lanrhe/article/PIIS2665-9913(19)30001-3/abstract},
volume = {1},
year = {2019}
}
@misc{Kipkogei2021,
abstract = {In this paper, we introduce the âClinical Transformerâ - a recasting of the widely used transformer architecture as a method for precision medicine to model relations between molecular and clinical measurements, and the survival of cancer patients. Although the emergence of immunotherapy offers a new hope for cancer patients with dramatic and durable responses having been reported, only a subset of patients demonstrate benefit. Such treatments do not directly target the tumor but recruit the patient's immune system to fight the disease. Therefore, the response to therapy is more complicated to understand as it is affected by the patient's physical condition, immune system fitness and the tumor. As in text, where the semantics of a word is dependent on the context of the sentence it belongs to, in immunotherapy a biomarker may have limited meaning if measured independent of other clinical or molecular features. Hence, we hypothesize that the transformer-inspired model may potentially enable effective modelling of the semantics of different biomarkers with respect to patients' survival time. Herein, we demonstrate that this approach can offer an attractive alternative to the survival models utilized in current practices as follows: (1) We formulate an embedding strategy applied to molecular and clinical data obtained from the patients. (2) We propose a customized objective function to predict patient survival. (3) We show the applicability of our proposed method to bioinformatics and precision medicine. Applying the clinical transformer to several immuno-oncology clinical studies, we demonstrate how the clinical transformer outperforms other linear and non-linear methods used in current practice for survival prediction. We also show that when initializing the weights of a domain-specific transformer by the weights of a cross-domain transformer, we further improve the predictions. Lastly, we show how the attention mechanism successfully captures some of the known biology behind these therapies.},
author = {Kipkogei, Elly and Argoty, G.A.A. and Kagiampakis, I. and Patra, Arijit and Jacob, Etai},
booktitle = {medRxiv},
doi = {10.1101/2021.10.11.21264761},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kipkogei et al. - Unknown - Explainable Transformer-Based Neural Network for the Prediction of Survival Outcomes in Non-Small Cell Lung.pdf:pdf},
keywords = {Attention-mechanism,Deep learning,Survival outcomes},
title = {{Explainable transformer-based neural network for the prediction of survival outcomes in non-small cell lung cancer (NSCLC)}},
url = {https://doi.org/10.1101/2021.10.11.21264761},
year = {2021}
}

@article{Scott2011,
abstract = {Transnational private regulation (TPR) is a key aspect of contemporary governance. At first glance TPR regimes raise significant problems of legitimacy because of a degree of detachment from traditional government mechanisms. A variety of models have emerged engaging businesses, associations of firms, and NGOs, sometimes in hybrid form and often including governmental actors. Whilst the linkage to electoral politics is a central mechanism of legitimating governance activity, we note there are also other mechanisms including proceduralization and potentially also judicial accountability. But these public law forms do not exhaust the set of such mechanisms, and we consider also the contribution of private law forms and social and competitive structures which may support forms of legitimation. The central challenge identified concerns the possibility of reconceptualizing the global public sphere so as better to embrace TPR regimes in their myriad forms, so that they are recognized as having similar potential for legitimacy as national and international governmental bodies and regulation. {\textcopyright} 2011 The Author. Journal of Law and Society {\textcopyright} 2011 Cardiff University Law School.},
author = {Scott, Colin and Cafaggi, Fabrizio and Senden, Linda},
doi = {10.1111/J.1467-6478.2011.00532.X},
issn = {1467-6478},
journal = {Journal of Law and Society},
month = {mar},
number = {1},
pages = {1--19},
publisher = {John Wiley & Sons, Ltd},
title = {{The Conceptual and Constitutional Challenge of Transnational Private Regulation}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1111/j.1467-6478.2011.00532.x https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1467-6478.2011.00532.x https://onlinelibrary.wiley.com/doi/10.1111/j.1467-6478.2011.00532.x},
volume = {38},
year = {2011}
}
@article{Claassen2016,
author = {Claassen, Rutger},
doi = {10.4324/9781315665320-12},
journal = {Human Rights and Sustainability},
publisher = {Routledge},
title = {{Ecological rights of future generations: A Capability Approach}},
year = {2016}
}

@article{Samuelson1938,
abstract = {By P. A. Page 2. 354 [AUGUST (2). I take this opportunity of enclosing a list of errata which unfortunately appeared in my previous .},
author = {Samuelson, P. A.},
doi = {10.2307/2548836},
issn = {00130427},
journal = {Economica},
month = {feb},
number = {17},
pages = {61},
publisher = {JSTOR},
title = {{A Note on the Pure Theory of Consumer's Behaviour}},
volume = {5},
year = {1938}
}
@article{Sagoff1998,
abstract = {Starting from a distinction between Kantian (principle-based) and utilitarian (preference-based) approaches in political theory, this essay argues that we may understand normative judgments individuals make about policy to express principled views of the public interest or purpose not private preferences about their own consumption opportunities. These judgments, in other words, state opinions about what we ought to do as a society rather than report preferences about what I want as a utility-maximizer. This essay then argues that contingent valuation can take into account these kinds of judgments--which dominate public discourse about the environment--only if it moves toward a deliberative, discursive, jury-like research method emphasizing informed discussion leading toward a consensus based on an argument about the public interest.},
author = {Sagoff, M.},
doi = {10.1016/S0921-8009(97)00144-4},
issn = {0921-8009},
journal = {Ecological Economics},
keywords = {Aggregation,Contingent pricing,Deliberation,Environmental goods,Environmental services},
month = {feb},
number = {2-3},
pages = {213--230},
publisher = {Elsevier},
title = {{Aggregation and deliberation in valuing environmental public goods:: A look beyond contingent pricing}},
volume = {24},
year = {1998}
}

@article{Mulder2017,
abstract = {This article analyzes Dutch consumers' willingness to pay (WTP) for the welfare of broiler chickens and the consequences for nonhuman animal welfare policies. Using data from a discrete-choice expe...},
author = {Mulder, Machiel and Zomer, Sigourney},
doi = {10.1080/10888705.2017.1281134},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mulder, Zomer - 2017 - Dutch Consumers' Willingness to Pay for Broiler Welfare.pdf:pdf},
issn = {15327604},
journal = {http://dx.doi.org/10.1080/10888705.2017.1281134},
keywords = {Broiler welfare,The Netherlands,choice experiment,willingness to pay},
month = {apr},
number = {2},
pages = {137--154},
pmid = {28166413},
publisher = {Routledge},
title = {{Dutch Consumers' Willingness to Pay for Broiler Welfare}},
url = {https://www.tandfonline.com/doi/abs/10.1080/10888705.2017.1281134},
volume = {20},
year = {2017}
}

@article{Jebelli2012,
abstract = {By its terms, Article 101(1) of the Treaty on the Functioning of the European Union (TFEU) prohibits all agreements that restrict competition. Yet, over 40 years ago, the Court recognised that not every restriction of the parties' economic freedom is necessarily a ârestriction of competition' within the meaning of the Treaty. Following this proclamation, a line of cases developed that have frustrated scholars and practitioners unable to find consistency in the law. But what constitutes a ârestriction of competition' is a fundamental question that demands a consistent interpretation. This article analyses the doctrine of âancillary restraints', as it was first applied outside the EU, and how it has since been incorporated into EU law, in order to understand its implications for the meaning of ârestriction' within Article 101(1). By showing that the doctrine has been consistently applied under EU jurisprudence, and that it has a unique and important function within Article 101, this article supports the continued use of a reasoned approach to restraints, embodied in both US and EU law.},
author = {Jebelli, Kayvan Hazemi},
doi = {10.2139/ssrn.2166318},
journal = {SSRN Electronic Journal},
keywords = {EU Ancillary Restraints: A Reasoned Approach to Ar,Kayvan Hazemi Jebelli,SSRN,ancillary,antitrust,competition,doctrine,object,per se,restraint,restrict,restriction,rule of reason,wouters},
month = {jun},
publisher = {Elsevier BV},
title = {{EU Ancillary Restraints: A Reasoned Approach to Article 101(1)}},
url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2166318},
year = {2012}
}
@article{Wouters2021,
author = {Wouters, David},
doi = {10.1093/JECLAP/LPAB013},
issn = {2041-7764},
journal = {Journal of European Competition Law & Practice},
month = {apr},
number = {3},
pages = {257--270},
publisher = {Oxford Academic},
title = {{Which Sustainability Agreements Are Not Caught by Article 101 (1) TFEU?}},
volume = {12},
year = {2021}
}


@article{Lianos2018,
abstract = {In a world marked by financial instability, limited growth, rising inequality, deteriorating environment, growing corporate consolidation, and political turmoil, calls are made to shift the dominant competition law paradigm towards new directions. These may bring competition law beyond its usual comfort zone of assessing business, or government, practices from the point of view of their effect on prices, output and, more broadly, on consumer welfare. Competition law is seen as a tool to be used in various circumstances in order to 'correct' market as well as non-market (e.g. government) failures, that result from restrictions of competition, to the extent that these affect social welfare. These failures may relate to the protection of personal data and privacy, the protection of the environment, the promotion of social mobility, the harnessing of disruptive innovation, or the mitigation of technology risks. Some go even further and argue that competition law may well be employed in order to preserve a number of other 'values' of social justice, thought to be intrinsic in democratic capitalism and the liberal order, and to which competition law should be sensitive. By putting forward the model of 'polycentric competition law' and by explaining how this compares with the mainstream 'monocentric' vision that has prevailed so far, the study aims to unveil and portray the rites of passage in this transition, and to explore the liminal condition of modern competition law.},
author = {Lianos, Ioannis},
doi = {10.1093/clp/cuy008},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lianos - 2018 - Polycentric Competition Law.pdf:pdf},
isbn = {9781910801185},
issn = {20448422},
journal = {CLES Research Paper Series},
keywords = {Citizens,Competition law,Complex economy,Consumers,Environment,Governance,Innovation,Monocentricity,Polycentricity,Privacy},
number = {1},
pages = {161--213},
title = {{Polycentric competition law}},
url = {www.ucl.ac.uk/cles/research-papers},
volume = {71},
year = {2018}
}
@techreport{EuropeanCommission2013,
author = {{European Commission}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/European Commission - 2013 - Competition Antitrust procedures in anticompetitive agreements.pdf:pdf},
institution = {European Commission},
title = {{Competition: Antitrust procedures in anticompetitive agreements}},
url = {http://ec.europa.eu/competition/publications},
year = {2013}
}
@article{Gerbrandy2017,
abstract = {It is undeniable that there is a tension between European competition law and sustainability focused agreements between undertakings. Whether it should, and how it could, be resolved is less clear. The necessity of providing âmore room' for sustainability-focused agreements is contested. Set within the wider discussion on the (proper) goals for European competition law, these public interests are often seen as alien to an economic approach of competition law. By taking developments in the Netherlands, where the tension seems to play out most visibly, as starting point, this article first sets out the argument that there is a sustainability-deficit within current competition law, and delineates where this deficit is âlocated'. The article then provides an overview of possible solutions. These are not (all) immediately applicable but would need tweaking existing competition law's instruments. Thus both to the interpretation of the Article 101 (3) TFEU exception clause and to the doctrines relating to placing entities or activities outside the scope of Article 101 (1) TFEU are discussed, as is the underlying rationale relating to the dichotomy between market and government.},
author = {Gerbrandy, Anna},
doi = {10.54648/WOCO2017035},
issn = {18758436},
journal = {World Competition},
number = {4},
pages = {539--562},
publisher = {Kluwer Law International},
title = {{Solving a sustainability-deficit in european competition law}},
volume = {40},
year = {2017}
}
@article{Holmes2020,
abstract = {Climate Change is an existential threat. Competition law must be part of the solution and not part of the problem. This article draws on the constitutional provisions of the EU treaties and remarks by leaders such as Commissioner Vestager to show how competition law need not stand in the way of urgent action and co-operation by the private sector to fight climate change. It also shows how sustainability is relevant to both the analysis of mergers and dominance cases. It is a call to update our thinking, our guidelines and, if necessary, our law. Based on EU law it contains ideas that could inspire changes in other jurisdictions.},
author = {Holmes, Simon},
doi = {10.1093/JAENFO/JNAA006},
issn = {20500696},
journal = {Journal of Antitrust Enforcement},
keywords = {Agreements,Climate change,Competition,Consumer welfare,Mergers,Sustainability},
month = {jul},
number = {2},
pages = {354--405},
publisher = {Oxford Academic},
title = {{Climate change, sustainability, and competition law}},
url = {https://academic.oup.com/antitrust/article/8/2/354/5819564},
volume = {8},
year = {2020}
}
@techreport{Margrethe2019,
address = {Brussels},
author = {Margrethe, Vestager},
institution = {GCLC Conference on Sustainability and Competition Policy},
title = {{Competition and sustainability}},
url = {https://ec.europa.eu/newsroom/comp/items/661165},
year = {2019}
}
@article{Inderst2022,
author = {Inderst, Roman and Thomas, Stefan},
doi = {10.2139/ssrn.4069374},
file = {:C\:/Users/jjia/Downloads/neww.pdf:pdf},
journal = {SSRN Electronic Journal},
pages = {1--7},
title = {{Sustainability Agreements in the European Commission's Draft Horizontal Guidelines}},
year = {2022}
}
@article{Malinauskaite2022,
author = {Malinauskaite, Jurgita},
doi = {10.1093/jeclap/lpac003},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Malinauskaite - 2022 - Competition Law and Sustainability EU and National Perspectives.pdf:pdf},
issn = {2041-7764},
journal = {Journal of European Competition Law & Practice},
month = {feb},
publisher = {Oxford University Press (OUP)},
title = {{Competition Law and Sustainability: EU and National Perspectives}},
url = {https://academic.oup.com/jeclap/advance-article/doi/10.1093/jeclap/lpac003/6533512},
year = {2022}
}
@article{Claassen2016a,
author = {Claassen, Rutger and Gerbrandy, Anna},
doi = {10.18352/ulr.321},
file = {:C\:/Users/jjia/Downloads/321-894-1-PB.pdf:pdf},
issn = {1871515X},
journal = {Utrecht Law Review},
number = {1},
pages = {1--15},
title = {{Rethinking european competition law: From a consumer welfare to a capability approach}},
volume = {12},
year = {2016}
}
@techreport{UnitedNations2012,
author = {{United Nations}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Assembly - 2012 - ARES66288 The future we want.pdf:pdf},
keywords = {Rio+20,The future we want,sustainable development},
title = {{A/RES/66/288: The future we want}},
url = {https://www.un.org/en/development/desa/population/migration/generalassembly/docs/globalcompact/A_RES_66_288.pdf},
year = {2012}
}
@article{Portney,
abstract = {A concise and accessible examination of sustainability in a range of contemporary contexts, from economic development to government policy. The Concepts of Sustainability -- Sustainability and the Roots of Controversy -- Sustainability and Consumption -- Sustainability in the Private Sector : The Role of Business and Industry -- Sustainability and Governments : The Importance of Public Policies -- The Special Case of Sustainable Cities -- Sustainability and the Future.},
author = {Portney, Kent E.},
isbn = {9780262528504},
pages = {235},
title = {{Sustainability}}
}
@article{Sverzellati2011,
abstract = {Objectives: This study aimed to describe a method of reducing interobserver variation associated with the visual quantitation of high-resolution computed tomographic (HRCT) signs of airways and interstitial lung disease (ILD). Methods: The HRCT scans of 2 cohorts of patients with airways disease (n = 144) and ILD (n = 109) were evaluated by 2 observers. Selected signs of airways disease were evaluated: (1) bronchial wall thickness and (2) the extent of the decreased attenuation. In the ILD group, the total extent of disease was scored. These 3 HRCT signs were scored by 2 observers independently using a standard method. The observers rescored the CT scans with a new scoring system (continuous learning method, CLM). Results: Observer agreement for CT signs was superior for CLM: bronchial wall thickness $\kappa$w increased from 0.51 to 0.76; for decreased attenuation, $\kappa$w increased from 0.34 to 0.81; and for ILD extent, $\kappa$w increased from 0.53 to 0.87. Conclusions: The CLM reduces noise from observer variation in studies that require visual quantitation of HRCT signs of lung disease. Copyright {\textcopyright} 2011 by Lippincott Williams & Wilkins.},
author = {Sverzellati, Nicola and Devaraj, Anand and Desai, Sujal R. and Quigley, Maureen and Wells, Athol U. and Hansell, David M.},
doi = {10.1097/RCT.0B013E3182277D05},
issn = {1532-3145},
journal = {Journal of computer assisted tomography},
keywords = {Adolescent,Adult,Aged,Anand Devaraj,Child,Cohort Studies,Computer-Assisted,David M Hansell,Female,Humans,Interstitial / diagnostic imaging*,Interstitial / pathology,Lung Diseases,MEDLINE,Male,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Nicola Sverzellati,Observer Variation,PubMed Abstract,Radiographic Image Interpretation,Reproducibility of Results,Respiratory Function Tests,Tomography,X-Ray Computed / methods*,doi:10.1097/RCT.0b013e3182277d05,pmid:21926855},
month = {sep},
number = {5},
pages = {596--601},
pmid = {21926855},
publisher = {J Comput Assist Tomogr},
title = {{Method for minimizing observer variation for the quantitation of high-resolution computed tomographic signs of lung disease}},
url = {https://pubmed.ncbi.nlm.nih.gov/21926855/},
volume = {35},
year = {2011}
}
@article{Collins1994,
abstract = {In fibrosing alveolitis the pattern type on thin section computed tomography (CT) predicts histological appearances at open lung biopsy and the likelihood of response to treatment. To test the level of inter- and intra-observer variability on CT and chest radiography (CXR), the pattern type and extent of disease were assessed by four observers (two experienced, two inexperienced). A total of 126 CT examinations and 108 concurrent postero-anterior chest radiographs were scored on two occasions, at least 8 weeks apart. A confidence rating was assigned to each observation. Three out of four observers agreed on pattern type in 81% of cases on CT compared with 54% on CXR (kappa coefficient 0.48 and 0.16 for CT and CXR, respectively). Inter-observer variability in categorizing pattern type on CT was lowest in patients with the highest confidence scores (kappa=0.63). Confident observations were associated with extensive or moderately extensive disease (P<0.001), and with a predominantly reticular pattern (P<0.0001). Intra-observer variability for pattern type on CT was less for the experienced observers (kappa=0.78 and 0.70) than for the inexperienced group (kappa=0.50 and 0.37). Inter-observer variability for extent of disease was significantly less on CT than on CXR (standard deviations 7.8% and 9.2% respectively, P<0.001). This study shows that observer variability using a clinical grading system is lower with CT than with chest radiography in fibrosing alveolitis. {\textcopyright} 1994, All rights reserved.},
author = {Collins, C. D. and Wells, A. U. and Hansell, D. M. and Morgan, R. A. and MacSweeney, J. E. and {Du Bois}, R. M. and Rubens, M. B.},
doi = {10.1016/S0009-9260(05)81847-1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Collins et al. - 1994 - Observer variation in pattern type and extent of disease in fibrosing alveolitis on thin section computed tomogr.pdf:pdf},
issn = {00099260},
journal = {Clinical Radiology},
keywords = {A U Wells,Attitude of Health Personnel,C D Collins,Clinical Competence,Humans,Lung / diagnostic imaging*,Lung / pathology,M B Rubens,MEDLINE,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Observer Variation,PubMed Abstract,Pulmonary Fibrosis / diagnostic imaging*,Pulmonary Fibrosis / pathology,Tomography,X-Ray Computed*,doi:10.1016/s0009-9260(05)81847-1,pmid:8162678},
number = {4},
pages = {236--240},
pmid = {8162678},
publisher = {Clin Radiol},
title = {{Observer variation in pattern type and extent of disease in fibrosing alveolitis on thin section computed tomography and chest radiography}},
url = {https://pubmed.ncbi.nlm.nih.gov/8162678/},
volume = {49},
year = {1994}
}
@book{Portney2015,
abstract = {A concise and accessible examination of sustainability in a range of contemporary contexts, from economic development to government policy. The Concepts of Sustainability -- Sustainability and the Roots of Controversy -- Sustainability and Consumption -- Sustainability in the Private Sector : The Role of Business and Industry -- Sustainability and Governments : The Importance of Public Policies -- The Special Case of Sustainable Cities -- Sustainability and the Future.},
author = {Portney, Kent E.},
isbn = {9780262528504},
publisher = {The MIT Press},
title = {{Sustainability}},
year = {2015}
}
@article{Odudu2010,
abstract = {In his recent book, Article 81 EC and Public Policy, Dr Christopher Townley promotes a vision of competition law that can be used to promote the general well-being of European Union citizens by requiring economic entities to promote general well-being and so participate in society as moral actors. This review article argues that the legitimate task of European Union competition law is much more modest than Townley envisions so that his version of competition law exceeds the limited competences conferred on the Union and the limits of justiciability.},
author = {Odudu, Okeoghene},
doi = {10.1093/ojls/gqq020},
journal = {Oxford Journal of Legal Studies},
number = {3},
pages = {599--613},
title = {{The Wider Concerns of Competition Law â }},
volume = {30},
year = {2010}
}

@book{Townley2009,
author = {Townley, Christopher},
booktitle = {Bloomsbury Publishing},
doi = {10.5040/9781472560582},
publisher = {Bloomsbury Publishing},
title = {{Article 81 EC and Public Policy}},
year = {2009}
}
@techreport{Commision2010,
author = {Commision},
title = {{Guidelines on the applicability of Article 101 of the Treaty on the Functioning of the European Union to horizontal co-operation agreements}},
year = {2010}
}

@techreport{OECD2010,
author = {OECD},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2010 - Regulatory Policy and the Road to Sustainable Growth Regulatory Policy and the Road to Sustainable Growth Â«.pdf:pdf},
title = {{Regulatory Policy and the Road to Sustainable Growth}},
url = {https://www.oecd.org/regreform/policyconference/46270065.pdf},
year = {2010}
}
@techreport{EuropeanCommission,
author = {{European Commission}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Commission on Environment - Unknown - Report of the World Commission on Environment and Development Our Common Future Towards Sustainabl.pdf:pdf},
keywords = {common future,development,environment,sustainable development},
title = {{Report of the World Commission on Environment and Development: Our Common Future Towards Sustainable Development 2. Part II. Common Challenges Population and Human Resources 4}}
}
@article{Fritsche2010,
abstract = {Biofuel production from energy crops is land-use intensive. Land-use change (LUC) associated with bioenergy cropping impacts on the greenhouse gas (GHG) balance, both directly and indirectly. Land-use conversion can also impact on biodiversity.The current state of quantifying GHG emissions relating to direct and indirect land-use change (iLUC) from biomass produced for liquid biofuels or bioenergy is reviewed. Several options for reducing iLUC are discussed, and recommendations made for considering LUC in bioenergy and biofuel policies.Land used for energy cropping is subject to competing demands for conventional agriculture and forest production, as well as for nature protection and conservation. Biomass to be used for bioenergy and biofuels should therefore be produced primarily from excess farm and forest residues or from land not required for food and fiber production. The overall efficiency of biomass production, conversion, and use should be increased where possible in order to further reduce land competition and the related direct and iLUC risks.This review of several varying approaches to iLUC substantiates that, in principle, GHG emissions can be quantified and reductions implemented by appropriate policies. Such approaches can (and should) be refined and substantiated using better data on direct LUC trends from global monitoring, and be further improved by adding more accurate estimates of future trade patterns where appropriate.This brief discussion of current policies and options to reduce iLUC has identified a variety of approaches and options so that a quantified iLUC factor could be translated into practical regulations - both mandatory and voluntary - with few restrictions.Depending on the future development of energy cropping systems and yield improvements, sustainable bioenergy production could make a significant contribution to the future global energy demand. {\textcopyright} 2010 Society of Chemical Industry and John Wiley & Sons, Ltd.},
author = {Fritsche, Uwe R. and Sims, Ralph E.H. and Monti, Andrea},
doi = {10.1002/BBB.258},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Fritsche, Sims, Monti - 2010 - Direct and indirect land-use competition issues for energy crops and their sustainable production â an ov.pdf:pdf},
issn = {1932-1031},
journal = {Biofuels, Bioproducts and Biorefining},
keywords = {GHG emissions,bioenergy,land,sustainable potential,use change},
month = {nov},
number = {6},
pages = {692--704},
publisher = {John Wiley & Sons, Ltd},
title = {{Direct and indirect land-use competition issues for energy crops and their sustainable production â an overview}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/bbb.258 https://onlinelibrary.wiley.com/doi/abs/10.1002/bbb.258 https://onlinelibrary.wiley.com/doi/10.1002/bbb.258},
volume = {4},
year = {2010}
}
@article{Nowag2017,
author = {Nowag, Julian},
doi = {10.1093/ACPROF:OSO/9780198753803.001.0001},
journal = {Environmental Integration in Competition and Free-Movement Laws},
month = {jan},
publisher = {Oxford University Press},
title = {{Environmental Integration in Competition and Free-Movement Laws}},
year = {2017}
}
@article{Hartley2020,
abstract = {The circular economy is a much discussed pathway towards sustainability. While some scholarly work has been carried out on barriers towards a circular economy, there are relatively few academic studies on policies that may accelerate a transition towards a circular economy. Those that focus on policies mostly scrutinize existing policies. The study at hand utilizes data from semi-structured interviews with 47 public and private sector circular economy experts from the European Union to explore expectations regarding circular economy policies, with expectations possibly going beyond existing policies. Expectations identified via this work include more robust standards and norms in production, expansion of circular procurement, tax relief for circular products, liberalization of waste trading and its facilitation through virtual platforms, support for eco-industrial parks, and awareness campaigns. The set of policy recommendations is presented from a life-cycle perspective that is necessary for a transition towards a circular economy. The study aims to contribute to the nascent body of circular economy literature concerning policies and may be of particular interest to practitioners.},
author = {Hartley, Kris and van Santen, Ralf and Kirchherr, Julian},
doi = {10.1016/J.RESCONREC.2019.104634},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hartley, van Santen, Kirchherr - 2020 - Policies for transitioning towards a circular economy Expectations from the European Union (EU).pdf:pdf},
issn = {0921-3449},
journal = {Resources, Conservation and Recycling},
keywords = {Circular economy,Public policy,Sustainability},
month = {apr},
pages = {104634},
publisher = {Elsevier},
title = {{Policies for transitioning towards a circular economy: Expectations from the European Union (EU)}},
volume = {155},
year = {2020}
}
@article{Ossewaarde2020,
abstract = {In December 2019, the European Union introduced its Green Deal in which the ecological crisis is prioritized. In doing so, the EU seems to be breaking with its traditional green growth discourse. Does it? In this article, we seek to find out whether and to what extent the EC indeed has such a revolutionary cultural, economic and political agenda in mind with its Green Deal. While the green growth discourse presumes a growth-based economy that must become greener, the degrowth discourse questions the growth model and perceives it as ecologically irresponsible. If the European Green Deal represents a third alternative, then it will somehow succeed in prioritizing ecology without welfare loss. To ascertain to what extent the European Green Deal is that third alternative, three preliminary steps need to be undertaken. The first step consists in a brief exposition of the key features of the traditional green growth discourse, as propounded by the EC and its various allies. Thereafter, the overlaps between the green growth discourse and the European Green Deal are noted. In the third section, the latter&rsquo;s divergences from that previous model are highlighted. In the final section, the main question of the article is answered. It is also suggested that specific interpretations and implementations of the European Green Deal could possibly turn the original communication into an alternative to both green growth and degrowth.},
author = {Ossewaarde, Marinus and Ossewaarde-Lowtoo, Roshnee},
doi = {10.3390/SU12239825},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ossewaarde, Ossewaarde-Lowtoo - 2020 - The EU's Green Deal A Third Alternative to Green Growth and Degrowth.pdf:pdf},
issn = {2071-1050},
journal = {Sustainability 2020, Vol. 12, Page 9825},
keywords = {European Union,Green Deal,degrowth,green growth,green technologies,power structures},
month = {nov},
number = {23},
pages = {9825},
publisher = {Multidisciplinary Digital Publishing Institute},
title = {{The EU's Green Deal: A Third Alternative to Green Growth and Degrowth?}},
url = {https://www.mdpi.com/2071-1050/12/23/9825/htm https://www.mdpi.com/2071-1050/12/23/9825},
volume = {12},
year = {2020}
}
@techreport{Deichmann2013,
author = {Deichmann, Uwe},
title = {{From Brown Growth to Green: the Economic Benefits of Climate Action}},
url = {https://www.worldbank.org/en/news/feature/2013/06/25/growing-green-europe-and-central-asia},
year = {2013}
}
@techreport{ACM2014,
author = {ACM},
number = {May},
title = {{Vision Document Competition and Sustainability}},
year = {2014}
}
@techreport{Bundeskartellamt2019,
author = {Bundeskartellamt},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Press release.pdf:pdf},
title = {{Bundeskartellamt prohibits Facebook from combining user data from different sources}},
url = {www.bundeskartellamt.de},
year = {2019}
}

@techreport{Cefic2022,
author = {Cefic},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Sustainability Agreements(2).pdf:pdf},
title = {{Cefic Response to the European Commission call for comments on the draft revised rules on horizontal cooperation agreements between companies (âDraft Horizontal Guidelinesâ)}},
url = {https://www.autoritedelaconcurrence.fr/fr/communiques-de-presse/lautorite-de-la-concurrence-publie-une-},
year = {2022}
}
@article{Nowag2021,
author = {Nowag, Julian},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Nowag - 2021 - DAFCOMP(2020)3 Sustainability & Competition Law and Policy-Background Note.pdf:pdf},
title = {{Sustainability & Competition Law and Policy-Background Note}},
url = {http://www.oecd.org/daf/competition/sustainability-and-competition.htm},
year = {2021}
}
@techreport{TheNetherlandsAuthorityforConsumersandMarkets2021,
author = {{The Netherlands Authority for Consumers and Markets}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Authority for Consumers - Unknown - TFEU in a sustainability context.pdf:pdf},
title = {{What is meant by a fair share for consumers in article 101(3) TFEU in a sustainability context?}},
year = {2021}
}
@article{CLARK1992,
abstract = {Born in 1903, in north central Mississippi, Clark received his B.A. from the University of Mississippi, his M.A. from the University of Kentucky, and his Ph.D. from Duke. Clark has collected thousands of documents, edited a dozen volumes, and written over 30 books and 60 articles, many of them about the South since the Civil War. Clark has served as president of Phi Alpha Theta, the Southern Historical Association, and the Organization of American Historians. He and his wife, Martha Elizabeth Turner, were married in 1933 and have a son and a daughter. Retiring in the 1970s after four decades at the University of Kentucky and Indiana University, Clark remains active in such historical circles as the Filson Club, where this interview was conducted in April 1991 by Roger Adelson. Copyright {\textcopyright} 1992, Wiley Blackwell. All rights reserved},
author = {CLARK, THOMAS D.},
doi = {10.1111/j.1540-6563.1992.tb00859.x},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guersent - Unknown - Interview with(2).pdf:pdf},
issn = {15406563},
journal = {Historian},
number = {3},
pages = {411--424},
title = {{Interview with Olivier Guersent, Director General, Directorate General for Competition, European Commissi}},
volume = {54},
year = {1992}
}
@article{Guersent,
abstract = {theantitrustsource w w w. a n t i t r u s t s o u r c e. c o m J u n e 2 0 2 0},
author = {Guersent, Olivier},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Guersent - Unknown - Interview with.pdf:pdf},
title = {{Interview with}}
}
@techreport{EuropeanCommission2019,
author = {{European Commission}},
title = {{President von der Leyen on the European Green Deal}},
url = {https://ec.europa.eu/commission/presscorner/detail/fr/speech_19_6749},
year = {2019}
}
@techreport{EuropeanCommission2022,
author = {{European Commission}},
title = {{Pioneering proposals to restore Europe's nature by 2050}},
url = {https://ec.europa.eu/commission/presscorner/detail/en/ip_22_3746},
year = {2022}
}
@article{Brook2019,
abstract = {The decentralized enforcement regime of EU competition law is based on the assumption that the obligation to apply the same Treaty provisions is sufficient to ensure a uniform administration of the law. This paper questions this assumption. Based on a systematic analysis of a large database of cases, it presents empirical evidence indicating that the Commission, EU courts and five national competition authorities have followed very different interpretations of the law when applying Article 101(3)TFEU. The paper uses the debate over the types of benefit that can be examined under Article 101(3) TFEU as an illustrative example of the struggle between the different competition authorities in shaping the future of EU competition policy.},
author = {Brook, Or},
doi = {10.54648/cola2019006},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brook - Unknown - STRUGGLING WITH ARTICLE 101(3) TFEU DIVERGING APPROACHES OF THE COMMISSION, EU COURTS, AND FIVE COMPETITION AUTHORITIE.pdf:pdf},
issn = {18758320},
journal = {Common Market Law Review},
number = {1},
pages = {121--156},
title = {{Struggling with Article 101(3) TFEU: Diverging approaches of the commission, EU courts, and five competition authorities}},
url = {http://ec.europa.eu/competition/speeches/text/sp1998_027_en.pdf},
volume = {56},
year = {2019}
}
@techreport{UnitedNations,
author = {{United Nations}},
title = {{The Sustainable Development Agenda - United Nations Sustainable Development}},
url = {https://www.un.org/sustainabledevelopment/development-agenda/}
}
@book{Whish2021,
author = {Whish, Richard and David, Bailey},
pages = {134},
publisher = {Oxford University Press},
title = {{Competition law}},
year = {2021}
}
@article{Inderst2022a,
author = {Inderst, Roman and Thomas, Stefan},
doi = {10.2139/SSRN.4069374},
file = {:C\:/Users/jjia/Downloads/neww.pdf:pdf},
journal = {SSRN Electronic Journal},
keywords = {Collective Benefits,Roman Inderst,SSRN,Stefan Thomas,Sustainability,Sustainability Agreements in the European Commissi,Sustainability Benefits},
month = {mar},
publisher = {Elsevier BV},
title = {{Sustainability Agreements in the European Commission's Draft Horizontal Guidelines}},
url = {https://papers.ssrn.com/abstract=4069374},
year = {2022}
}

@techreport{EuropeanUnion2020,
abstract = {The Farm to Fork Strategy is at the heart of the European Green Deal aiming to make food systems fair, healthy and environmentally-friendly. Food systems cannot be resilient to crises such as the Covid-19 pandemic if they are not sustainable. We need to redesign our food systems which today account for nearly one-third of global GHG emissions, consume large amounts of natural resources, result in biodiversity loss and negative health impacts (due to both under- and over-nutrition) and do not allow fair economic returns and livelihoods for all actors, in particular for primary producers. Putting our food systems on a sustainable path also brings new opportunities for operators in the food value chain. New technologies and scientific discoveries, combined with increasing public awareness and demand for sustainable food, will benefit all stakeholders.},
author = {{European Union}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - Farm to Fork Strategy 2 CONTENTS.pdf:pdf},
pages = {1--23},
title = {{Farm to Fork Strategy}},
year = {2020}
}

@article{Hardin1968,
author = {Hardin, Garrett},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hardin - 1968 - The Tragedy of the Commons.pdf:pdf},
journal = {Source: Science, New Series},
number = {3859},
pages = {1243--1248},
title = {{The Tragedy of the Commons}},
volume = {162},
year = {1968}
}

@misc{CommunicationfromtheCommission,
author = {{Communication from the Commission}},
title = {{Communication from the CommissionâGuidelines on the applicability of Article 101 of the Treaty on the Functioning of the European Union to horizontal co-operation agreements, [2011] OJ C11/1.}}
}
@article{EuropeanCommission2021,
abstract = {DIRECTIVE 2003/30/EC OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 8 May 2003 on the promotion of the use of biofuels or other renewable fuels for transport},
author = {{European Commission}},
file = {:C\:/Users/jjia/Downloads/CELEX_32021R1119_EN_TXT.pdf:pdf},
journal = {Official Journal of the European Union},
number = {June},
pages = {17},
title = {{European Climate Law}},
url = {https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32021R1119},
volume = {2021},
year = {2021}
}
@article{EuropeanUnion2020a,
author = {{European Union}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - REGULATION (EU) 2020852 OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL of 18 June 2020 on the establishment of a fram.pdf:pdf},
issn = {2019/2088},
journal = {Official Journal of the European Union},
title = {{Regulation (EU) 2020/852 of the European Parliament and of the Council of 18 June 2020 on the Establishment of a Framework to Facilitate Sustainable Investment, and amending Regulation}},
volume = {L 198/13},
year = {2020}
}
@techreport{Paola2019,
author = {Paola, Tamma and Eline, Schaart and Anca, Gurzu},
institution = {POLITICO},
title = {{Europe's Green Deal plan unveiled}},
url = {https://www.politico.eu/article/the-commissions-green-deal-plan-unveiled/},
year = {2019}
}

@techreport{EuropeanCommission2022b,
author = {{European Commission}},
title = {{Antitrust: Commission invites comments on draft revised rules on horizontal cooperation agreements between companies}},
url = {https://ec.europa.eu/commission/presscorner/detail/en/ip_22_1371},
year = {2022}
}
@misc{CommissionofGuidelines2001,
author = {{Commission of Guidelines 2001}},
title = {{Communication from the Commission NoticeâGuidelines on the applicability of Article 81 of the EC Treaty to horizontal cooperation agreements [2001] OJ C3/2.}}
}
@techreport{Simon2019,
author = {Simon, Fr{\'{e}}d{\'{e}}ric},
institution = {EURACTIV.com},
title = {{EU Commission unveils âEuropean Green Deal': The key points}},
url = {https://www.euractiv.com/section/energy-environment/news/eu-commission-unveils-european-green-deal-the-key-points/},
year = {2019}
}

@article{Brook2019a,
abstract = {The decentralized enforcement regime of EU competition law is based on the assumption that the obligation to apply the same Treaties provisions is sufficient to ensure a uniform administration of the law. This paper questions this assumption. Based on a systematic analysis of a large database of cases, it presents empirical evidence indicating that the Commission, EU courts and five national competition authorities have followed very different interpretations of the law when applying Article 101(3) TFEU. The paper uses the debate over the types of benefits that can be examined under Article 101(3) TFEU as an illustrative example of the struggle between the competition authorities for shaping the future of EU competition policy.},
author = {Brook, O R},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brook - 2019 - Tfeu Diverging Approaches Of The Commission, Eu Courts, And Five Competition Authorities. Brook, O (2019) Struggling With.pdf:pdf},
issn = {0165-0750},
journal = {Company Market Law},
keywords = {Article 101 TFEU,Competition law,EU law,Empirical legal research},
number = {3},
pages = {121--156},
title = {{Struggling with article 101(3) TFEU: diverging approaches of the commission, eu courts, and five competition authorities}},
url = {http://eprints.whiterose.ac.uk/141418/},
volume = {101},
year = {2019}
}

@techreport{TheNetherlandsAuthorityforConsumersandMarkets2022,
author = {{The Netherlands Authority for Consumers and Markets}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/for Consumers - 2022 - Public consultation on the draft revised Horizontal Block Exemption Regulations and Horizontal Guidelines Resp(2).pdf:pdf},
title = {{Public consultation on the draft revised Horizontal Block Exemption Regulations and Horizontal Guidelines Response from the Netherlands Authority for Consumers & Markets}},
url = {www.acm.nl},
year = {2022}
}

@techreport{TheNetherlandsAuthorityforConsumersandMarkets,
author = {{The Netherlands Authority for Consumers and Markets}},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - The Netherlands Authority for Consumers and Markets(2).pdf:pdf},
title = {{Guidelines Sustainability claims}}
}
@article{AuthorityforConsumers,
author = {{Authority for Consumers}, Netherlands},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Authority for Consumers - Unknown - Public(2).pdf:pdf},
title = {sector-letter-regarding-sustainability-claims-in-clothing-sector},
url = {www.acm.nl}
}
@misc{AuthorityforConsumersa,
author = {{Authority for Consumers}, Netherlands},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Authority for Consumers - Unknown - Public.pdf:pdf},
title = {sector-letter-regarding-sustainability-claims-in-dairy-sector},
url = {www.acm.nl},
urldate = {2022-07-03}
}

@techreport{Wouters2021a,
author = {Wouters, David},
booktitle = {Kluwer Competition Law Blog},
title = {{Sustainability Agreements vs Greenwashing under Article 101 TFEU}},
url = {http://competitionlawblog.kluwercompetitionlaw.com/2021/06/03/sustainability-agreements-vs-greenwashing-under-article-101-tfeu/},
year = {2021}
}

@techreport{CommisionDraftHorizontalGuidelines2022,
abstract = {The purpose of these guidelines is to provide an analytical framework for the most common types of horizontal co-operation agreements; they deal with research and development agreements, production agreements including subcontracting and specialisation agreements, purchasing agreements, commer? cialisation agreements, standardisation agreements including standard contracts, and information exchange. This framework is primarily based on legal and economic criteria that help to analyse a horizontal co-operation agreement and the context in which it occurs. Economic criteria such as the market power of the parties and other factors relating to the market structure form a key element of the assessment of the market impact likely to be caused by a horizontal co-operation agreement and, therefore, for the assessment under Article 101.},
author = {{Commision Draft Horizontal Guidelines}},
booktitle = {European Competition Journal},
doi = {10.5235/174410510792283790},
file = {:C\:/Users/jjia/Downloads/COMMUNICATION FROM THE COMMISSION - Guidelines on the applicability of Article 101 of the Treaty on the Functioning of the European Union to horizontal co- operation agreements DRAFT.pdf:pdf},
issn = {1744-1056},
title = {{Draft Guidelines on the applicability of Article 101 of the Treaty on the Functioning of the European Union to horizontal cooperation agreements}},
year = {2022}
}

@article{Cortenbergh2022,
abstract = {Horizontal cooperation between companies is becoming increasingly important to generate efficiencies and benefits to society and provide customers with complete solutions and product portfolio offerings, in particular, in changing industries such as those impacted by digitalisation. However, there is a real risk that companies will refrain from cooperating if they have undue fear that they could be infringing competition rules considering that normally it will be for the parties themselves to assess whether collaboration is compatible with competition laws. A self-assessment on the question of whether a particular form of cooperation between competitors is admissible is always associated with a high degree of legal uncertainty. To avoid such legal uncertainty-and a potential underinvestment-the Commission should give clear and detailed guidance, including examples, when, and under what conditions, cooperation is acceptable. The existing HBER and the Guidelines have been providing a valuable guidance for undertakings on the application of Article 101 TFEU, and, at large, the proposed changes to the current regime enhance legal certainty, making the guidance even more valuable. Small and large businesses have made, and are expected to make, frequent use of this regime. As the Commission sets out, society has undergone significant changes since the previous rules were adopted, which have impacted commercial relations and will continue to have a substantial impact in the coming years. Joint research and development projects or collaborations through industry platforms play an important role. Platforms offer new opportunities and business models for companies on both the provider and customer side. Businesses are adapting to technological innovations and to changing consumer trends. This requires flexibility in the organisation of both horizontal and vertical relationships, and we appreciate that the newly proposed rules reflect these developments even though there could be more guidance on how cooperation agreements could foster the resilience of the EU economy. First and foremost, competition policy should ensure that effective competition between companies exists and is maintained. It should ensure that companies that are investing, for example in sustainable technologies and innovation, can expect to reap the benefits thereof without fear of being unfairly crowded out by cartels or dominant companies abusing their position. Competition is the driving force of achieving results considering that it incentivises companies to be competitive and to achieve results in the most efficient manner. As such, competition policy complements specific legislative actions to reach other policy objectives and we are pleased that the Commission plays an important role in this debate. It is important to engage with other national and international authorities to ensure a consistent approach across the EU, and globally.},
author = {Cortenbergh, Av DE and Aisbl, Businesseurope},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortenbergh, aisbl - 2022 - Draft Revised Horizontal Block Exemption Regulations (HBER) and Draft Guidelines on Horizontal Cooperatio(2).pdf:pdf},
title = {{Draft Revised Horizontal Block Exemption Regulations (HBER) and Draft Guidelines on Horizontal Cooperation Agreements Commission Consultation}},
year = {2022}
}
@techreport{EuropeanCommission2019a,
abstract = {Predicting the binding mode of flexible polypeptides to proteins is an important task that falls outside the domain of applicability of most small molecule and proteinâprotein docking tools. Here, we test the small molecule flexible ligand docking program Glide on a set of 19 non-$\alpha$-helical peptides and systematically improve pose prediction accuracy by enhancing Glide sampling for flexible polypeptides. In addition, scoring of the poses was improved by post-processing with physics-based implicit solvent MM- GBSA calculations. Using the best RMSD among the top 10 scoring poses as a metric, the success rate (RMSD â¤ 2.0 {\AA} for the interface backbone atoms) increased from 21% with default Glide SP settings to 58% with the enhanced peptide sampling and scoring protocol in the case of redocking to the native protein structure. This approaches the accuracy of the recently developed Rosetta FlexPepDock method (63% success for these 19 peptides) while being over 100 times faster. Cross-docking was performed for a subset of cases where an unbound receptor structure was available, and in that case, 40% of peptides were docked successfully. We analyze the results and find that the optimized polypeptide protocol is most accurate for extended peptides of limited size and number of formal charges, defining a domain of applicability for this approach.},
address = {Brussels},
author = {{European Commission}},
file = {:C\:/Users/jjia/Downloads/cellar_b828d165-1c22-11ea-8c1f-01aa75ed71a1.0002.02_DOC_1.pdf:pdf},
title = {{The European Green Deal}},
url = {http://eur-lex.europa.eu/resource.html?uri=cellar:208111e4-414e-4da5-94c1-852f1c74f351.0004.02/DOC_1&format=PDF},
year = {2019}
}

@techreport{SamMacMahonBaldwin2022,
author = {{Sam MacMahon Baldwin}},
institution = {Kluwer Competition Law Blog},
title = {{DG COMP's 2022 draft horizontal guidelines - comments & suggestions}},
url = {http://competitionlawblog.kluwercompetitionlaw.com/2022/04/11/dg-comps-2022-draft-horizontal-guidelines-comments-suggestions/},
year = {2022}
}
@techreport{Modrall2022,
author = {Modrall, Jay},
title = {{The EU's Draft Horizontal Guidelines: Chilling Innovation on Sustainability?}},
url = {https://www.competitionpolicyinternational.com/the-eus-draft-horizontal-guidelines-chilling-innovation-on-sustainability/},
year = {2022}
}
@article{Gassler2021a,
author = {Gassler, Martin},
doi = {10.1093/JECLAP/LPAB001},
issn = {2041-7764},
journal = {Journal of European Competition Law & Practice},
month = {jun},
number = {6},
pages = {430--442},
publisher = {Oxford Academic},
title = {{Sustainability, the Green Deal and Art 101 TFEU: Where We Are and Where We Could Go}},
url = {https://academic.oup.com/jeclap/article/12/6/430/6142276},
volume = {12},
year = {2021}
}
@article{Loozen2019,
abstract = {This article investigates the purpose and workings of EU competition law and policy: how does the protection of competition promote welfare? It scrutinizes the claim that sustainable consumption and production (SCP) requires flexible rather than strict enforcement of Article 101 TFEU. Flexible antitrust proponents argue that SCP requires sector-wide private coordination, as manufacturers of sustainable products suffer if consumers can opt for cheaper, less sustainable products. Four main arguments build on compliance with, respectively, the constitutional context of EU competition law, the more economic approach, the legitimate objective doctrine, and the useful effect doctrine. This article questions all four arguments. Integrating principle and practice, the article shows that strict competition enforcement is the way forward to promote welfare, in this case SCP. Problems of under-regulation should be addressed by the regulatory State.},
author = {Loozen, Edith},
doi = {10.54648/cola2019102},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Loozen - 2019 - STRICT COMPETITION ENFORCEMENT AND WELFARE A CONSTITUTIONAL PERSPECTIVE BASED ON ARTICLE 101 TFEU AND SUSTAINABILITY.pdf:pdf},
issn = {18758320},
journal = {Common Market Law Review},
number = {5},
pages = {1265--1302},
title = {{Strict Competition Enforcement And Welfare: A Constitutional Perspective Based On Article 101 Tfeu And Sustainability}},
volume = {56},
year = {2019}
}

@article{Cortenbergh2022a,
abstract = {Horizontal cooperation between companies is becoming increasingly important to generate efficiencies and benefits to society and provide customers with complete solutions and product portfolio offerings, in particular, in changing industries such as those impacted by digitalisation. However, there is a real risk that companies will refrain from cooperating if they have undue fear that they could be infringing competition rules considering that normally it will be for the parties themselves to assess whether collaboration is compatible with competition laws. A self-assessment on the question of whether a particular form of cooperation between competitors is admissible is always associated with a high degree of legal uncertainty. To avoid such legal uncertainty-and a potential underinvestment-the Commission should give clear and detailed guidance, including examples, when, and under what conditions, cooperation is acceptable. The existing HBER and the Guidelines have been providing a valuable guidance for undertakings on the application of Article 101 TFEU, and, at large, the proposed changes to the current regime enhance legal certainty, making the guidance even more valuable. Small and large businesses have made, and are expected to make, frequent use of this regime. As the Commission sets out, society has undergone significant changes since the previous rules were adopted, which have impacted commercial relations and will continue to have a substantial impact in the coming years. Joint research and development projects or collaborations through industry platforms play an important role. Platforms offer new opportunities and business models for companies on both the provider and customer side. Businesses are adapting to technological innovations and to changing consumer trends. This requires flexibility in the organisation of both horizontal and vertical relationships, and we appreciate that the newly proposed rules reflect these developments even though there could be more guidance on how cooperation agreements could foster the resilience of the EU economy. First and foremost, competition policy should ensure that effective competition between companies exists and is maintained. It should ensure that companies that are investing, for example in sustainable technologies and innovation, can expect to reap the benefits thereof without fear of being unfairly crowded out by cartels or dominant companies abusing their position. Competition is the driving force of achieving results considering that it incentivises companies to be competitive and to achieve results in the most efficient manner. As such, competition policy complements specific legislative actions to reach other policy objectives and we are pleased that the Commission plays an important role in this debate. It is important to engage with other national and international authorities to ensure a consistent approach across the EU, and globally.},
author = {Cortenbergh, Av DE and Aisbl, Businesseurope},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cortenbergh, aisbl - 2022 - Draft Revised Horizontal Block Exemption Regulations (HBER) and Draft Guidelines on Horizontal Cooperation A.pdf:pdf},
title = {{Draft Revised Horizontal Block Exemption Regulations (HBER) and Draft Guidelines on Horizontal Cooperation Agreements Commission Consultation}},
year = {2022}
}

@article{Shrader1952,
abstract = {A CHANGE of gigantic proportions has taken place in the Poultry Industry of the United States. Meat-type poultry has taken its place alongside âProduction Bredââand Standard Bred Fancy Chickens. Changing economic conditions and a well-organized âChicken-of-Tomorrowâ Program has speeded up this evolution. The practice of raising Commercial Meat Chickens on mass production methods has proved profitable, and the volume has more than doubled in five years' time. The number raised in the United States increased from 275 million in 1946 to 616 million in 1950, and the expansion has continued during 1951. This added interest created enormous pressure for an improved meat-type chicken, a more efficient ration, larger hatching and processing facilities, and better marketing and merchandising procedure. In 1945 Howard C. Pierce, Poultry Research Director, A & P Food Stores, in an address before a Canadian Poultry meeting remarked that someone would confer a boon upon the poultry . . .},
author = {Shrader, H.L.},
doi = {10.3382/PS.0310003},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Shrader - 1952 - The Chicken-of-Tomorrow Program Its Influence on âMeat-Typeâ Poultry Production.pdf:pdf},
issn = {0032-5791},
journal = {Poultry Science},
month = {jan},
number = {1},
pages = {3--10},
publisher = {Elsevier},
title = {{The Chicken-of-Tomorrow Program; Its Influence on âMeat-Typeâ Poultry Production}},
volume = {31},
year = {1952}
}
@article{Wong2019,
abstract = {The tremendous potential exhibited by deep learning is often offset by architectural and computational complexity, making widespread deployment a challenge for edge scenarios such as mobile and other consumer devices. To tackle this challenge, we explore the following idea: Can we learn generative machines to automatically generate deep neural networks with efficient network architectures? In this study, we introduce the idea of generative synthesis, which is premised on the intricate interplay between a generator-inquisitor pair that work in tandem to garner insights and learn to generate highly efficient deep neural networks that best satisfies operational requirements. Experimental results for image classification, semantic segmentation, and object detection tasks illustrate the efficacy of generative synthesis (GenSynth) in producing generators that automatically generate highly efficient deep neural networks (which we nickname FermiNets with higher model efficiency and lower computational costs (reaching . 10Ã more efficient and fewer multiply-accumulate operations than several tested state-of-the-art networks), as well as higher energy efficiency (reaching . 4Ã improvements in image inferences per joule consumed on a Nvidia Tegra X2 mobile processor). As such, GenSynth can be a powerful, generalised approach for accelerating and improving the building of deep neural networks for on-device edge scenarios..},
author = {Wong, Alexander and Shafiee, Mohammad Javad and Chwyl, Brendan and Li, Francis},
doi = {10.1049/EL.2019.1719},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wong et al. - 2019 - Gensynth A generative synthesis approach to learning generative machines for generate efficient neural networks.pdf:pdf},
issn = {00135194},
journal = {Electronics Letters},
month = {sep},
number = {18},
pages = {986--989},
publisher = {Institution of Engineering and Technology},
title = {{Gensynth: A generative synthesis approach to learning generative machines for generate efficient neural networks}},
volume = {55},
year = {2019}
}
@article{QiuLin,
abstract = {There has been a significant surge of interest recently in the research community around the concept of explainable artificial intelligence (XAI), where the goal is to produce an interpretation for a decision made by a machine learning algorithm. Of particular interest is the interpretation of how deep neural networks make decisions, given the complexity and 'black box' nature of such networks. Given the infancy of the field, there has been very limited exploration into the assessment of the performance of explainability methods, with most evaluations centered around subjective visual interpretation of the produced interpretations. In this study, we explore a more machine-centric strategy for quantifying the performance of explainability methods on deep neural networks via the notion of decision-making impact analysis. More specifically, we quantify the importance of identified critical factors for a given decision made by a network based on the impact over network decisions and confidences in the absence of these critical factors. For scenarios where we wish to study impact in directed erroneous decisions (e.g., under adversarial distractions), we additionally quantify importance of identified critical factors based on coverage of the adversarially impacted factors. We introduce two quantitative performance metrics: i) Impact Score, which assesses the percentage of critical factors with either strong confidence reduction impact or decision changing impact, and ii) Impact Coverage, which assesses the percentage coverage of adversarially impacted factors in the input. A comprehensive analysis using this approach was conducted on several state-of-the-art explainability methods (LIME, SHAP, Expected Gradients , GSInquire) on a ResNet-50 deep convolutional neural network using a subset of ImageNet for the task of image classification. Experimental results show that, for both general and adversarial distraction scenarios, the critical regions identified by LIME within the tested images had the lowest impact on the decision-making process of the network (â¼38%), with progressive increase in decision-making impact for SHAP (â¼44%), Expected Gradients (â¼51%), and GSInquire (â¼76%). A similar trend is observed in terms of impact coverage under adversarial distractions, with impact coverage being lowest for LIME and highest for GSInquire. While by no means perfect, the hope is that the proposed machine-centric strategy helps push the conversation forward towards better metrics for evaluating explainability methods and improve trust in deep neural networks.},
archivePrefix = {arXiv},
arxivId = {1910.07387v2},
author = {{Qiu Lin}, Zhong and {Javad Shafiee}, Mohammad and Bochkarev, Stanislav and {St Jules}, Michael and {Yu Wang}, Xiao and Wong, Alexander},
eprint = {1910.07387v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Qiu Lin et al. - Unknown - Do Explanations Reflect Decisions A Machine-centric Strategy to Quantify the Performance of Explainability Al.pdf:pdf},
title = {{Do Explanations Reflect Decisions? A Machine-centric Strategy to Quantify the Performance of Explainability Algorithms}}
}
@article{Christodoulidis2017,
abstract = {Early diagnosis of interstitial lung diseases is crucial for their treatment, but even experienced physicians find it difficult, as their clinical manifestations are similar. In order to assist with the diagnosis, computer-aided diagnosis systems have been developed. These commonly rely on a fixed scale classifier that scans CT images, recognizes textural lung patterns, and generates a map of pathologies. In a previous study, we proposed a method for classifying lung tissue patterns using a deep convolutional neural network (CNN), with an architecture designed for the specific problem. In this study, we present an improved method for training the proposed network by transferring knowledge from the similar domain of general texture classification. Six publicly available texture databases are used to pretrain networks with the proposed architecture, which are then fine-tuned on the lung tissue data. The resulting CNNs are combined in an ensemble and their fused knowledge is compressed back to a network with the original architecture. The proposed approach resulted in an absolute increase of about 2% in the performance of the proposed CNN. The results demonstrate the potential of transfer learning in the field of medical image analysis, indicate the textural nature of the problem and show that the method used for training a network can be as important as designing its architecture.},
archivePrefix = {arXiv},
arxivId = {1612.02589},
author = {Christodoulidis, Stergios and Anthimopoulos, Marios and Ebner, Lukas and Christe, Andreas and Mougiakakou, Stavroula},
doi = {10.1109/JBHI.2016.2636929},
eprint = {1612.02589},
issn = {21682208},
journal = {IEEE Journal of Biomedical and Health Informatics},
keywords = {Convolutional neural networks (CNNs),Transfer learning,interstitial lung diseases (ILDs),knowledge distillation,model compression,model ensemble,texture classification},
month = {jan},
number = {1},
pages = {76--84},
pmid = {28114048},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Multisource Transfer Learning with Convolutional Neural Networks for Lung Pattern Analysis}},
volume = {21},
year = {2017}
}
@article{Bakker,
abstract = {Shareable abstract (@ERSpublications) CT may be used as a proxy for lung function in COPD diagnosis and evaluation, particularly for the hyperinflation markers https://bit.ly/2RrGAZf Cite this article as: Bakker JT, Klooster K, Vliegenthart R, et al. Measuring pulmonary function in COPD using quantitative chest computed tomography analysis. Eur Respir Rev 2021; 30: 210031 [ Abstract COPD is diagnosed and evaluated by pulmonary function testing (PFT). Chest computed tomography (CT) primarily serves a descriptive role for diagnosis and severity evaluation. CT densitometry-based emphysema quantification and lobar fissure integrity assessment are most commonly used, mainly for lung volume reduction purposes and scientific efforts. A shift towards a more quantitative role for CT to assess pulmonary function is a logical next step, since more, currently underutilised, information is present in CT images. For instance, lung volumes such as residual volume and total lung capacity can be extracted from CT; these are strongly correlated to lung volumes measured by PFT. This review assesses the current evidence for use of quantitative CT as a proxy for PFT in COPD and discusses challenges in the movement towards CT as a more quantitative modality in COPD diagnosis and evaluation. To better understand the relevance of the traditional PFT measurements and the role CT might play in the replacement of these parameters, COPD pathology and traditional PFT measurements are discussed.},
author = {Bakker, Jens T and Klooster, Karin and Vliegenthart, Rozemarijn and Slebos, Dirk-Jan},
doi = {10.1183/16000617.0031-2021},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bakker et al. - Unknown - Measuring pulmonary function in COPD using quantitative chest computed tomography analysis.pdf:pdf},
title = {{Measuring pulmonary function in COPD using quantitative chest computed tomography analysis}},
url = {https://doi.org/10.1183/16000617.0031-2021}
}
@article{Regan2011,
abstract = {Background: COPDGene is a multicenter observational study designed to identify genetic factors associated with COPD. It will also characterize chest CT phenotypes in COPD subjects, including assessment of emphysema, gas trapping, and airway wall thickening. Finally, sub-types of COPD based on these phenotypes will be used in a comprehensive genome-wide study to identify COPD susceptibility genes. Methods/Results: COPDGene will enroll 10,000 smokers with and without COPD across the GOLD stages. Both Non-Hispanic white and African-American subjects are included in the cohort. Inspiratory and expiratory chest CT scans will be obtained on all participants. In addition to the cross-sectional enrollment process, these subjects will be followed regularly for longitudinal studies. A genome-wide association study (GWAS) will be done on an initial group of 4000 subjects to identify genetic variants associated with case-control status and several quantitative phenotypes related to COPD. The initial findings will be verified in an additional 2000 COPD cases and 2000 smoking control subjects, and further validation association studies will be carried out. Conclusions: COPDGene will provide important new information about genetic factors in COPD, and will characterize the disease process using high resolution CT scans. Understanding genetic factors and CT phenotypes that define COPD will potentially permit earlier diagnosis of this disease and may lead to the development of treatments to modify progression.},
author = {Regan, Elizabeth A and Hokanson, John E and Murphy, James R and Make, Barry and Lynch, David A and Beaty, Terri H and Curran-Everett, Douglas and Silverman, Edwin K and Crapo, James D},
doi = {10.3109/15412550903499522},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Regan et al. - 2011 - Genetic Epidemiology of COPD (COPDGene) Study Design.pdf:pdf},
issn = {1541-2563},
journal = {COPD: Journal of Chronic Obstructive Pulmonary Disease},
number = {1},
pages = {32--43},
title = {{Genetic Epidemiology of COPD (COPDGene) Study Design}},
url = {https://www.tandfonline.com/action/journalInformation?journalCode=icop20},
volume = {7},
year = {2011}
}
@article{Iwano2009a,
abstract = {Rationale and Objectives: The aim of this study was to evaluate the accuracy of measurements of lung volumes reconstructed using three-dimensional computed tomographic (CT) imaging from thin-section multidetector-row CT images compared to standard pulmonary function testing. Materials and Methods: Preoperative three-dimensional CT images and pulmonary function test results of 64 patients with solitary pulmonary nodules who were considered candidates for lung resection were reviewed. On the three-dimensional CT images, total lung capacity (TLCCTV), emphysematous lung capacity (ELCCTV), and normal lung capacity (NLCCTV) were calculated. Total lung capacity (TLC), vital capacity, and forced expiratory volume in 1 second were measured using spirometry. Results: There was a strong positive correlation between estimated TLCCTV and measured TLC values (r = 0.87, P < .001). Estimated ELCCTV at the threshold value of -900 Hounsfield units was negatively correlated with forced expiratory volume in 1 second (r = -0.56, P < .001). NLCCTV values were more strongly correlated with vital capacity values than TLCCTV values (r = 0.74, P < .001). Conclusions: Lung volume calculated using three-dimensional CT volumetry was well correlated with lung volume measured using spirometry. Three-dimensional CT volumetry can be used to evaluate pulmonary function. {\textcopyright} 2009 AUR.},
author = {Iwano, Shingo and Okada, Tohru and Satake, Hiroko and Naganawa, Shinji},
doi = {10.1016/J.ACRA.2008.09.019},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Iwano et al. - 2009 - 3D-CT Volumetry of the Lung Using Multidetector Row CT. Comparison with Pulmonary Function Tests.pdf:pdf},
issn = {10766332},
journal = {Academic Radiology},
keywords = {3D image,Computed tomography,lung density,lung neoplasms,pulmonary function},
month = {mar},
number = {3},
pages = {250--256},
pmid = {19201353},
title = {{3D-CT Volumetry of the Lung Using Multidetector Row CT. Comparison with Pulmonary Function Tests}},
volume = {16},
year = {2009}
}
@article{Coxson,
abstract = {The aim of the present study was to correlate clinical outcome measures following treatment with bronchial valves with regional lung volume. Computed tomography (CT) scan data from 57 subjects with severe emphysema were obtained from nine North American clinical trial sites. IBV1 Valves (Spiration, Inc., Redmond, WA, USA) were placed to occlude segmental and subsegmental bronchi in right and left upper lobes using a flexible bronchoscope. Subjects completed a St George's Respiratory Questionnaire (SGRQ), pulmonary function test (PFT) and exercise capacity test. CT scans were analysed at baseline and at 1, 3 or 6 months after treatment to measure total and lobar lung density, volume and mass. Total lung volumes measured using CT were strongly correlated with PFT and did not change with treatment. However, the treated upper lobes significantly decreased in volume in 88% of the observations, by meanÂ¡SD 335Â¡444 mL, or a decrease of 10.2% in the 6 month data. The untreated lobes had an 11.6% increase in volume. Changes in regional lung volume were associated with clinically meaningful improvements in SGRQ (-8.95Â¡16.22), but not clinically meaningful PFT changes. The significant health status improvements reported by subjects following bilateral bronchial valve treatment are associated with regional lung volume changes and interlobar shift measured using computed tomography.},
author = {Coxson, H O and Fauerbach, P V Nasute and Storness-Bliss, C and M{\"{u}}ller, N L and Cogswell, S and Dillard, D H and Finger, C L and Springmeyer, S C},
doi = {10.1183/09031936.00056008},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Coxson et al. - Unknown - Computed tomography assessment of lung volume changes after bronchial valve treatment.pdf:pdf},
keywords = {Computed tomography,emphysema,intrabronchial valve,lung volume reduction surgery},
title = {{Computed tomography assessment of lung volume changes after bronchial valve treatment}},
url = {www.erj.ersjournals.com/misc/}
}
@article{Kazarooni1997,
abstract = {OBJECTIVE. The purpose of our study was to determine if three-level thin-section CT depicts idiopathic pulmonary fibrosis (IPF) pathology as accurately as CT obtained at 10-mm increments throughout the entire lungs. SUBJECTS AND METHODS. Thin-section (1.0- to 1.5-mm) images at 10-mm increments were obtained and scored prospectively in 25 consecutive patients with newly diagnosed IPF who were participating in a Special Center of Research grant for interstitial lung disease. Each patient's lobe was scored by four thoracic radiologists on a scale of 0-5 for both ground-glass attenuation and fibrosis. The radiologists used three images (limited CT) and also used the entire data set (complete CT). CT scores were compared with pathology scores from 67 open and thoracoscopic biopsies. Limited and complete scores were compared with each other (Pearson correlation coefficient). Interobserver variation in the CT scoring system was assessed using kappa values. RESULTS. CT fibrosis scores strongly correlated with pathology fibrosis scores for complete (r = .53, p = .0001) and limited (r = .50, p = .0001) CT. CT ground-glass scores correlated with the histologic inflammatory scores for each lobe on complete (r = .27, p = .03) and limited (r = .26, p = .03) CT. The desquamative subcomponent of the pathology inflammatory score had the highest correlation with the CT ground-glass scores (complete: r = .29, p = .01; limited: r = .33, p = .007). Good interobserver agreement existed for both the alveolar and fibrosis components of the CT scoring system (kappa values ranging from .51 to .83) for each lobe of the lung on limited and complete CT. CONCLUSION. Limited thin-section CT reveals the pathologic changes associated with IPF as well as CT obtained at 10-mm increments. An added advantage of limited thin-section CT is that it exposes patients to less radiation.},
author = {Kazarooni, Ella A. and Martinez, Fernando J. and Flint, Andrew and Jamadar, David A. and Gross, Barry H. and Spizarny, David L. and Cascade, Philip N. and Whyte, Richard I. and Lynch, Joseph P. and Toews, Galen},
doi = {10.2214/AJR.169.4.9308447},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazarooni et al. - 1997 - Thin-section CT obtained at 10-mm increments versus limited three-level thin-section CT for idiopathic pulmona.pdf:pdf},
issn = {0361803X},
journal = {American Journal of Roentgenology},
number = {4},
pages = {977--983},
pmid = {9308447},
publisher = {American Roentgen Ray Society},
title = {{Thin-section CT obtained at 10-mm increments versus limited three-level thin-section CT for idiopathic pulmonary fibrosis: Correlation with pathologic scoring}},
volume = {169},
year = {1997}
}
@article{Tantucci2016,
abstract = {Background: Accurate measurement of lung volumes is of paramount importance to establish the presence of ventilatory defects and give insights for diagnostic and/or therapeutic purposes. Objectives: It was the aim of this study to measure lung volumes in subjects with respiratory disorders and in normal controls by 3 different techniques (plethysmographic, dilutional and radiographic methods), in an attempt to clarify the role of each of them in performing such a task, without any presumptive 'a priori' superiority of one method above others. Patients andMethods: In different groups of subjects with obstructive and restrictive ventilatory defects and in a normal control group, total lung capacity, functional residual capacity (FRC) and residual volume were measured by body plethysmography, multi-breath helium (He) dilution and radiographic CT scan method with spirometric gating. Results: The 3 methods gave comparable results in normal subjects and in patients with a restrictive defect. In patients with an obstructive defect, CT scan and plethysmography showed similar lung volumes, while on average significantly lower lung volumes were obtained with the He dilution technique. Taking into account that the He dilution technique does primarily measure FRC during tidal breathing, our data suggest that in some patients with an obstructive defect, a number of small airways can be functionally closed at end-expiratory lung volume, preventing He to reach the lung regions subserved by these airways. Conclusion: In all circumstances, both CT scan with spirometric gating and plethysmographic methods provide similar values of lung volumes. In contrast, the He dilution method can measure lower lung volumes in some patients with chronic airflow obstruction.},
author = {Tantucci, Claudio and Bottone, Damiano and Borghesi, Andrea and Guerini, Michele and Quadri, Federico and Pini, Laura},
doi = {10.1159/000444418},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Tantucci et al. - 2016 - Methods for Measuring Lung Volumes Is There a Better One.pdf:pdf},
issn = {14230356},
journal = {Respiration},
keywords = {Lung volume management,Ventilatory defects},
month = {may},
number = {4},
pages = {273--280},
pmid = {26982496},
publisher = {S. Karger AG},
title = {{Methods for Measuring Lung Volumes: Is There a Better One?}},
volume = {91},
year = {2016}
}
@article{Kazarooni2013,
abstract = {The purpose of our study was to determine if three-level thin-section CT depicts idiopathic pulmonary fibrosis (IPF) pathology as accurately as CT obtained at 10-mm increments throughout the entire...},
author = {Kazarooni, Ella A. and Martinez, Fernando J. and Flint, Andrew and Jamadar, David A. and Gross, Barry H. and Spizarny, David L. and Cascade, Philip N. and Whyte, Richard I. and Lynch, Joseph P. and Toews, Galen},
doi = {10.2214/AJR.169.4.9308447},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kazarooni et al. - 2013 - Thin-section CT obtained at 10-mm increments versus limited three-level thin-section CT for idiopathic pulmona.pdf:pdf},
issn = {0361803X},
journal = {http://dx.doi.org/10.2214/ajr.169.4.9308447},
month = {jan},
number = {4},
pages = {977--983},
pmid = {9308447},
publisher = {American Public Health Association},
title = {{Thin-section CT obtained at 10-mm increments versus limited three-level thin-section CT for idiopathic pulmonary fibrosis: correlation with pathologic scoring.}},
url = {www.ajronline.org},
volume = {169},
year = {2013}
}
@inproceedings{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
booktitle = {Advances in Neural Information Processing Systems},
doi = {10.3156/jsoft.29.5_177_2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - Unknown - Generative Adversarial Nets(2).pdf:pdf},
issn = {10495258},
number = {January},
pages = {2672--2680},
title = {{Generative adversarial nets}},
url = {http://www.github.com/goodfeli/adversarial},
volume = {3},
year = {2014}
}
@article{Dong2022,
abstract = {The data-driven nature of deep learning (DL) models for semantic segmentation requires a large number of pixel-level annotations. However, large-scale and fully labeled medical datasets are often unavailable for practical tasks. Recently, partially supervised methods have been proposed to utilize images with incomplete labels in the medical domain. To bridge the methodological gaps in partially supervised learning (PSL) under data scarcity, we propose Vicinal Labels Under Uncertainty (VLUU), a simple yet efficient framework utilizing the human structure similarity for partially supervised medical image segmentation. Motivated by multi-task learning and vicinal risk minimization, VLUU transforms the partially supervised problem into a fully supervised problem by generating vicinal labels. We systematically evaluate VLUU under the challenges of small-scale data, dataset shift, and class imbalance on two commonly used segmentation datasets for the tasks of chest organ segmentation and optic disc-and-cup segmentation. The experimental results show that VLUU can consistently outperform previous partially supervised models in these settings. Our research suggests a new research direction in label-efficient deep learning with partial supervision.},
archivePrefix = {arXiv},
arxivId = {2011.14164},
author = {Dong, Nanqing and Kampffmeyer, Michael and Liang, Xiaodan and Xu, Min and Voiculescu, Irina and Xing, Eric},
doi = {10.1016/J.ASOC.2021.108074},
eprint = {2011.14164},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dong et al. - 2022 - Towards robust partially supervised multi-structure medical image segmentation on small-scale data.pdf:pdf},
isbn = {2021.108074},
issn = {15684946},
journal = {Applied Soft Computing},
keywords = {Data scarcity,Deep learning,Medical image segmentation,Partially supervised learning},
month = {jan},
pages = {108074},
publisher = {Elsevier Ltd},
title = {{Towards robust partially supervised multi-structure medical image segmentation on small-scale data}},
url = {http://creativecommons.org/licenses/by/4.0/},
volume = {114},
year = {2022}
}
@article{Acharya2013,
abstract = {Systemic sclerosis (SSc) is a multisystem autoimmune connective tissue disease of unknown etiology. Pulmonary involvement is known to occur in SSc in form of progressive fibrosis and alveolitis. Pulmonary hypertension is another spectrum of involvement. We present a case of limited cutaneous scleroderma who presented with progressive dysnea and was diagnosed to have Interstitial lung disease (ILD).},
author = {Acharya, Sourya and Shukla, Samarth and Mahajan, S. N. and Banode, Pankaj and Mahure, Chetan and Mathew, Leny},
doi = {10.1164/rccm.200706-877oc},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh et al. - 2012 - Interstitial Lung Disease in Systemic Sclerosis.pdf:pdf},
issn = {09743901},
journal = {Journal of Datta Meghe Institute of Medical Sciences University},
keywords = {Alveolitis,Fibrosis,ILD,Systemic sclerosis},
month = {dec},
number = {1},
pages = {57--59},
publisher = {American Thoracic Society},
title = {{Interstitial lung disease in systemic sclerosis}},
url = {www.atsjournals.org},
volume = {8},
year = {2013}
}

@article{Meijs2016,
abstract = {Objectives: To determine the outcomes, including number of medical interventions and initiation of immunosuppressive treatment of a standardised, comprehensive, diagnostic care pathway for patients with systemic sclerosis (SSc). Patient characteristics associated with need for medical interventions and with need for immunosuppressive treatment were determined. Methods: Data were routinely gathered in connection with a 2-day care pathway combining multidisciplinary care and complete diagnostic work-up of organ involvement in SSc. The number of patients in whom the pathway resulted in medical interventions, and/or initiation of immunosuppressives was recorded. Patient characteristics and diagnostic tests results were compared between patients with and without medical interventions, and patients with and without initiation of immunosuppressives by means of multivariable logistic regression analyses. Results: During a period of 44 months, 226 patients with SSc were referred to the care pathway. They included 186 (82%) women with mean age of 54 (SD 14.5) years, and median disease duration of 4 years (range 1-11); 73 (32%) of them had diffuse cutaneous SSc. Medical interventions were initiated in 191 (85%) patients, including initiation of immunosuppressive treatment in n=49 (22%). Presence of telangiectasias and higher erythrocyte sedimentation rate were associated with any medical intervention. Of commonly available variables, lower age, higher skin score and absence of anticentromere antibody were associated with initiation of immunosuppressives. Conclusions: A standardised comprehensive 2-day care pathway for patients with SSc resulted in additional diagnostic or therapeutic interventions in 85% of the patients, regardless of SSc subtype and disease duration. In 22% of the patients, immunosuppressive treatment was initiated.},
author = {Meijs, Jessica and Schouffoer, Anne A. and Marsan, Nina Ajmone and Kroft, Lucia J.M. and Stijnen, Theo and Ninaber, Maarten K. and Huizinga, Tom W.J. and {Vliet Vlieland}, Theodora P.M. and {De Vries-Bouwstra}, Jeska K.},
doi = {10.1136/RMDOPEN-2015-000159},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meijs et al. - 2016 - Original article Therapeutic and diagnostic outcomes of a standardised, comprehensive care pathway for patients wi.pdf:pdf},
issn = {20565933},
journal = {RMD Open},
number = {1},
pmid = {27042333},
publisher = {BMJ Publishing Group},
title = {{Original article: Therapeutic and diagnostic outcomes of a standardised, comprehensive care pathway for patients with systemic sclerosis}},
url = {/pmc/articles/PMC4800807/ /pmc/articles/PMC4800807/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4800807/},
volume = {2},
year = {2016}
}
@inproceedings{GonzalezSerrano2018,
abstract = {Mitochondria are cellular organelles that harvest energy in the form of ATP through a process termed oxidative phosphorylation (OXPHOS), which occurs via the protein complexes of the electron transport chain (ETC). In recent years it has become unequivocally clear that mitochondrial complexes of the ETC are not static entities in the inner mitochondrial membrane. These complexes are dynamic and in mammals they aggregate in different stoichiometric combinations to form supercomplexes (SCs) or respirasomes. It has been proposed that the net respiration is more efficient via SCs than via isolated complexes. However, it still needs to be determined whether the activity of a particular SC is associated with a disease etiology. Here we describe a simplified method to visualize and assess in-gel activity of SCs and the individual complexes with good resolution using blue native polyacrylamide gel electrophoresis (BN-PAGE).},
author = {{Gonzalez Serrano}, German and Washko, George R. and {San Jos{\'{e}} Est{\'{e}}par}, Ra{\'{u}}l},
booktitle = {Proceedings of SPIE--the International Society for Optical Engineering},
doi = {10.1117/12.2293455},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonzalez Serrano, Washko, San Jos{\'{e}} Est{\'{e}}par - 2018 - Deep learning for biomarker regression application to osteoporosis and emphysema on.pdf:pdf},
isbn = {9781510616370},
issn = {0277-786X},
keywords = {bone mineral density,computed tomography,deep learning,emphysema,regression},
month = {mar},
pages = {52},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Deep learning for biomarker regression: application to osteoporosis and emphysema on chest CT scans}},
url = {https://pubmed.ncbi.nlm.nih.gov/30122802/ /pmc/articles/PMC6097534/ /pmc/articles/PMC6097534/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6097534/},
volume = {10574},
year = {2018}
}
@book{Martel2020,
abstract = {part1;},
author = {Martel, Anne L and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A and Zhou, S Kevin and Racoceanu, Daniel and Joskowicz, Leo and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/part II.pdf:pdf;:E\:/jjia/papers/miccai/2021/part VI.pdf:pdf},
isbn = {9783030597153},
title = {{and Computer Assisted Intervention â MICCAI 2020 Lecture Notes in Computer Science}},
year = {2020}
}
@article{Williamson2021,
author = {Williamson, Lucy},
doi = {10.1016/S2213-2600(20)30565-8},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Williamson - 2021 - New reference atlas for pulmonary fibrosis severity score in systemic sclerosis.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Williamson - 2021 - New reference atlas for pulmonary fibrosis severity score in systemic sclerosis(2).pdf:pdf},
issn = {22132619},
journal = {The Lancet Respiratory Medicine},
month = {feb},
number = {2},
pages = {130--131},
pmid = {33278914},
publisher = {Lancet Publishing Group},
title = {{New reference atlas for pulmonary fibrosis severity score in systemic sclerosis}},
url = {https://easy.dans.knaw.},
volume = {9},
year = {2021}
}
@book{Frangi2018,
author = {Frangi, Alejandro F and Schnabel, Julia A and Alberola-l{\'{o}}pez, Christos Davatzikos Carlos and Eds, Gabor Fichtinger and Hutchison, David},
file = {:E\:/jjia/papers/miccai/2021/part IV.pdf:pdf;:E\:/jjia/papers/miccai/2021/part III.pdf:pdf;:E\:/jjia/papers/miccai/2021/part V.pdf:pdf;:E\:/jjia/papers/miccai/2021/part VII.pdf:pdf},
isbn = {9783030009335},
title = {{and Computer Assisted Intervention â MICCAI 2018}},
year = {2018}
}

@article{Goh2008,
abstract = {Systemic sclerosis (SSc) is a multisystem autoimmune connective tissue disease of unknown etiology. Pulmonary involvement is known to occur in SSc in form of progressive fibrosis and alveolitis. Pulmonary hypertension is another spectrum of involvement. We present a case of limited cutaneous scleroderma who presented with progressive dysnea and was diagnosed to have Interstitial lung disease (ILD).},
author = {Goh, Nicole S.L. and Desai, Sujal R and Veeraraghavan, Srihari and Hansell, David M and Copley, Susan J and Maher, Toby M and Corte, Tamera J and Sander, Clare R and Ratoff, Jonathan and Devaraj, Anand and Bozovic, Gracijela and Denton, Christopher P and Black, Carol M and {Du Bois}, Roland M and Wells, Athol U},
doi = {10.1164/RCCM.200706-877OC},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh et al. - Unknown - Interstitial Lung Disease in Systemic Sclerosis a Simple Staging System Online Data Supplement.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/NS et al. - 2008 - Interstitial lung disease in systemic sclerosis a simple staging system.pdf:pdf},
issn = {1535-4970},
journal = {American journal of respiratory and critical care medicine},
keywords = {Adult,Algorithms*,Athol U Wells,Cohort Studies,Controlled Clinical Trial,Extensive,Female,High-resolution computed tomography,Humans,Interstitial / diagnosis*,Interstitial / etiology,Interstitial / mortality,Limited,Lung Diseases,MEDLINE,Male,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Nicole S L Goh,Non-U.S. Gov't,Predictive Value of Tests,Prognosis,PubMed Abstract,Pulmonary function test,Research Support,Scleroderma,Severity of Illness Index*,Sujal R Desai,Survival Analysis,Systemic / complications*,Systemic / diagnostic imaging,Systemic / physiopathology,Tomography,Vital Capacity / physiology,X-Ray Computed,doi:10.1164/rccm.200706-877OC,pmid:18369202},
number = {11},
pages = {57--59},
pmid = {18369202},
publisher = {Am J Respir Crit Care Med},
title = {{Interstitial lung disease in systemic sclerosis: a simple staging system}},
url = {https://pubmed.ncbi.nlm.nih.gov/18369202/},
volume = {177},
year = {2008}
}
@inproceedings{Simonyan2015,
abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3 Ã 3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16â19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
archivePrefix = {arXiv},
arxivId = {1409.1556},
author = {Simonyan, Karen and Zisserman, Andrew},
booktitle = {3rd International Conference on Learning Representations, ICLR 2015 - Conference Track Proceedings},
eprint = {1409.1556},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - Very deep convolutional networks for large-scale image recognition(2).pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Simonyan, Zisserman - 2015 - VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION(3).pdf:pdf},
keywords = {()},
month = {sep},
publisher = {International Conference on Learning Representations, ICLR},
title = {{Very deep convolutional networks for large-scale image recognition}},
url = {http://www.robots.ox.ac.uk/},
year = {2015}
}
@article{Cohen1968,
abstract = {A previously described coefficient of agreement for nominal scales, kappa, treats all disagreements equally. A generalization to weighted kappa (Kw) is presented. The Kw provides for the incorpation of ratio-scaled degrees of disagreement (or agreement) to each of the cells of the k * k table of joint nominal scale assignments such that disagreements of varying gravity (or agreements of varying degree) are weighted accordingly. Although providing for partial credit, Kw is fully chance corrected. Its sampling characteristics and procedures for hypothesis testing and setting confidence limits are given. Under certain conditions, Kw equals product-moment r. The use of unequal weights for symmetrical cells makes Kw suitable as a measure of validity. (PsycINFO Database Record (c) 2006 APA, all rights reserved). {\textcopyright} 1968 American Psychological Association.},
author = {Cohen, Jacob},
doi = {10.1037/h0026256},
issn = {00332909},
journal = {Psychological Bulletin},
keywords = {pro,weighted kappa coefficient for nominal scales},
month = {oct},
number = {4},
pages = {213--220},
pmid = {19673146},
title = {{Weighted kappa: Nominal scale agreement provision for scaled disagreement or partial credit}},
url = {https://scihubtw.tw/10.1037/h0026256},
volume = {70},
year = {1968}
}
@article{AK2010,
abstract = {Purpose: To evaluate the imaging features on high-resolution computed tomography (HRCT) of the chest and the clinical parameters that are associated with pulmonary hypertension in systemic sclerosis. We specifically investigated whether main pulmonary artery (MPA) diameter and burden of lung fibrosis are predictors of pulmonary hypertension in these patients. Methods: We retrospectively retrieved the database information of patients with systemic sclerosis seen at our hospital between January 2007 and December 2008. A total of 75 patients had HRCT of the chest, pulmonary function testing (PFT), and echocardiography within 6 months of each other. The echocardiography images were reviewed by a level-3 echocardiographer, and 29 cases were excluded because of suboptimal evaluation of pulmonary artery (PA) pressure. Peak PA pressures and PFT of the remaining 46 cases (43 women and 3 men) were charted. The PFT included total lung capacity (TLC), diffusion capacity of lung for carbon monooxide (DLCO) and the ratio of forced expiratory volume in one second and forced vital capacity (FEV1/FVC). The HRCT of the chest of each patient was read by a chest radiologist. The extent of ground glass, reticulation, and honeycombing was objectively scored. The maximum diameter of the main pulmonary artery (MPAD) and ascending aorta were measured. The ratio of main pulmonary artery diameter and ascending aortic diameter (MPAD/AD) and ratio of main pulmonary artery diameter and body surface area (MPAD/BSA) were also calculated. Results: Statistical analysis done by using a multivariate model showed that the calculated fibrotic score strongly correlated with peak PA pressures (P < .001). MPAD (P = .0175), and the ratio MPAD/AD (P = .0102) also showed a statistically significant correlation with peak PA pressures. By using stepwise regression analysis, the fibrotic score was found to be the most reliable independent predictor of pulmonary hypertension. Conclusion: HRCT-determined severity and extent of pulmonary fibrosis may be helpful in screening for pulmonary hypertension in patients with systemic sclerosis. {\textcopyright} 2010 Canadian Association of Radiologists. All rights reserved.},
author = {AK, Pandey and P, Wilcox and JR, Mayo and D, Sin and R, Moss and J, Ellis and J, Brown and J, Leipsic and Pandey, Anoop Kumar and Wilcox, Pearce and Mayo, John R. and Sin, Donald and Moss, Robert and Ellis, Jennifer and Brown, Jacquie and Leipsic, Jonathon},
doi = {10.1016/J.CARJ.2010.02.006},
issn = {0846-5371},
keywords = {80 and over,Adult,Aged,Anoop Kumar Pandey,Cross-Sectional Studies,Echocardiography,Female,Fibrotic score,High-resolution computed tomography,Humans,Hypertension,Jonathon Leipsic,Linear Models,MEDLINE,Male,Middle Aged,NCBI,NIH,NLM,National Center for Biotechnology Information,National Institutes of Health,National Library of Medicine,Pearce Wilcox,PubMed Abstract,Pulmonary / diagnostic imaging*,Pulmonary / etiology*,Pulmonary Fibrosis / diagnostic imaging*,Pulmonary Fibrosis / etiology*,Pulmonary hypertension,Radiography,Respiratory Function Tests,Retrospective Studies,Scleroderma,Systemic / complications*,Systemic / diagnostic imaging*,Thoracic,Tomography,X-Ray Computed / methods*,doi:10.1016/j.carj.2010.02.006,pmid:20382500},
month = {dec},
number = {5},
pages = {291--296},
pmid = {20382500},
title = {{No Title}},
url = {https://pubmed.ncbi.nlm.nih.gov/20382500/},
volume = {61},
year = {2010}
}
@article{LiangThian2019,
abstract = {Purpose To demonstrate the feasibility and performance of an object detection convolutional neural network (CNN) for fracture detection and localization on wrist radiographs. Materials and Methods Institutional review board approval was obtained with waiver of consent for this retrospective study. A total of 7356 wrist radiographic studies were extracted from a hospital picture archiving and communication system. Radiologists annotated all radius and ulna fractures with bounding boxes. The dataset was split into training (90%) and validation (10%) sets and used to train fracture localization models for frontal and lateral images. Inception-ResNet Faster R-CNN architecture was implemented as a deep learning model. The models were tested on an unseen test set of 524 consecutive emergency department wrist radiographic studies with two radiologists in consensus as the reference standard. Per-fracture, per-image (ie, per-view), and per-study sensitivity and specificity were determined. Area under the receiver ...},
author = {{Liang Thian}, Yee and Li, Yiting and Jagmohan, Pooja and Sia, David and {Ern Yao Chan}, Vincent and Tan, Robby T and Thian, Yee Liang and Li, Yiting and Jagmohan, Pooja and Sia, David and Chan, Vincent Ern Yao and Tan, Robby T},
doi = {10.1148/ryai.2019180001},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang Thian et al. - Unknown - Convolutional Neural Networks for Automated Fracture Detection and Localization on Wrist Radiographs.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liang Thian et al. - Unknown - Convolutional Neural Networks for Automated Fracture Detection and Localization on Wrist Radiographs(2).pdf:pdf},
issn = {2638-6100},
journal = {Radiology: Artificial Intelligence},
number = {1},
pages = {e180001},
title = {{Convolutional Neural Networks for Automated Fracture Detection and Localization on Wrist Radiographs}},
url = {https://doi.org/10.1148/ryai.2019180001},
volume = {1},
year = {2019}
}
@article{Frid-Adar2018,
abstract = {Deep learning methods, and in particular convolutional neural networks (CNNs), have led to an enormous breakthrough in a wide range of computer vision tasks, primarily by using large-scale annotated datasets. However, obtaining such datasets in the medical domain remains a challenge. In this paper, we present methods for generating synthetic medical images using recently presented deep learning Generative Adversarial Networks (GANs). Furthermore, we show that generated medical images can be used for synthetic data augmentation, and improve the performance of CNN for medical image classification. Our novel method is demonstrated on a limited dataset of computed tomography (CT) images of 182 liver lesions (53 cysts, 64 metastases and 65 hemangiomas). We first exploit GAN architectures for synthesizing high quality liver lesion ROIs. Then we present a novel scheme for liver lesion classification using CNN. Finally, we train the CNN using classic data augmentation and our synthetic data augmentation and compare performance. In addition, we explore the quality of our synthesized examples using visualization and expert assessment. The classification performance using only classic data augmentation yielded 78.6% sensitivity and 88.4% specificity. By adding the synthetic data augmentation the results increased to 85.7% sensitivity and 92.4% specificity. We believe that this approach to synthetic data augmentation can generalize to other medical classification applications and thus support radiologists' efforts to improve diagnosis.},
archivePrefix = {arXiv},
arxivId = {1803.01229},
author = {Frid-Adar, Maayan and Diamant, Idit and Klang, Eyal and Amitai, Michal and Goldberger, Jacob and Greenspan, Hayit},
doi = {10.1016/j.neucom.2018.09.013},
eprint = {1803.01229},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frid-Adar et al. - 2018 - GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Frid-Adar et al. - Unknown - GAN-based Synthetic Medical Image Augmentation for increased CNN Performance in Liver Lesion Classification.pdf:pdf},
issn = {18728286},
journal = {Neurocomputing},
keywords = {Convolutional neural networks,Data augmentation,Deep learning,Generative adversarial network,Image synthesis,Index Terms-Image synthesis,Lesion classification,Liver lesions,convolu-tional neural networks,data augmentation,deep learning,generative adversarial network,lesion classification,liver lesions},
month = {dec},
pages = {321--331},
publisher = {Elsevier},
title = {{GAN-based synthetic medical image augmentation for increased CNN performance in liver lesion classification}},
volume = {321},
year = {2018}
}
@article{Koo2016a,
abstract = {Objective Intraclass correlation coefficient (ICC) is a widely used reliability index in test-retest, intrarater, and interrater reliability analyses. This article introduces the basic concept of ICC in the content of reliability analysis. Discussion for Researchers There are 10 forms of ICCs. Because each form involves distinct assumptions in their calculation and will lead to different interpretations, researchers should explicitly specify the ICC form they used in their calculation. A thorough review of the research design is needed in selecting the appropriate form of ICC to evaluate reliability. The best practice of reporting ICC should include software information, âmodel,â âtype,â and âdefinitionâ selections. Discussion for Readers When coming across an article that includes ICC, readers should first check whether information about the ICC form has been reported and if an appropriate ICC form was used. Based on the 95% confident interval of the ICC estimate, values less than 0.5, between 0.5 and 0.75, between 0.75 and 0.9, and greater than 0.90 are indicative of poor, moderate, good, and excellent reliability, respectively. Conclusion This article provides a practical guideline for clinical researchers to choose the correct form of ICC and suggests the best practice of reporting ICC parameters in scientific publications. This article also gives readers an appreciation for what to look for when coming across ICC while reading an article.},
author = {Koo, Terry K. and Li, Mae Y.},
doi = {10.1016/J.JCM.2016.02.012},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Koo, Li - 2016 - A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Koo, Li - 2016 - A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research(2).pdf:pdf},
issn = {15563707},
journal = {Journal of Chiropractic Medicine},
keywords = {Reliability and validity,Research,Statistics},
month = {jun},
number = {2},
pages = {155--163},
pmid = {27330520},
publisher = {Elsevier},
title = {{A Guideline of Selecting and Reporting Intraclass Correlation Coefficients for Reliability Research}},
url = {/pmc/articles/PMC4913118/ /pmc/articles/PMC4913118/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4913118/},
volume = {15},
year = {2016}
}
@article{Desai2004,
abstract = {PURPOSE: To evaluate computed tomographic (CT) patterns of lung disease in patients with systemic sclerosis (SSc) and compare them with CT appearance in patients with biopsy-proved idiopathic pulmonary fibrosis (IPF) and idiopathic non-specific interstitial pneumonia (NSIP). MATERIALS AND METHODS: The CT features of consecutive patients with SSc (n = 225; male patients, 44; female patients, 181; median age, 47 years; age range, 16-78 years), IPF (n = 40; men, 26; women, 14; median age, 54.5 years; age range, 36-77 years) and NSIP (n = 27; men, 18; women, nine; median age, 53 years; age range, 32-68 years) were quantified separately by two observers. The extent of interstitial lung disease, ground-glass opacification, emphysema, and the coarseness of a reticular pattern were quantified. Group comparisons were made nonparametrically with the Wilcoxon rank sum test. Differences in CT features were identified with multiple logistic regression analysis. RESULTS: The coarseness of fibrosis was similar in patients with SSc and idiopathic NSIP but strikingly different between patients with SSc (median coarseness score, 5.5; range, 0.0-13.3) and IPF (median coarseness score, 8.8; range, 2.5-15.0) (P < .001). The proportion of ground-glass opacification at CT was similar in patients with SSc and idiopathic NSIP but differed significantly between patients with SSc (median proportion, 49.9%, range, 0.0%-100.0%) and IPF (median proportion, 23.5%; range, 0.0%-97.2%) (P < .001). At logistic regression analysis, there were no differences in the CT features between patients with SSc and those with NSIP after controlling for age, disease extent, and the percentage predicted forced vital capacity and carbon monoxide diffusing capacity. CONCLUSION: Interstitial lung disease in patients with SSc is less extensive, less coarse, and characterized by a greater proportion of ground-glass opacification than that in patients with IPF. The CT features of lung disease in patients with SSc closely resemble those in patients with idiopathic NSIP. {\textcopyright} RSNA, 2004.},
author = {Desai, Sujal R. and Veeraraghavan, Srihari and Hansell, David M. and Nikolakopolou, Ageliki and Goh, Nicole S.L. and Nicholson, Andrew G. and Colby, Thomas V. and Denton, Christopher P. and Black, Carol M. and {Du Bois}, Roland M. and Wells, Athol U.},
doi = {10.1148/radiol.2322031223},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Desai et al. - 2004 - CT features of lung disease in patients with systemic scerosis Comparison with idiopathic pulmonary fibrosis and n.pdf:pdf;:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Desai et al. - 2004 - CT features of lung disease in patients with systemic scerosis Comparison with idiopathic pulmonary fibrosis an(2).pdf:pdf},
issn = {00338419},
journal = {Radiology},
keywords = {CT,Lung,Pneumonia,Scleroderma,diseases,fibrosis,interstitial disease,nonschedule interstitial and fibrosis,usual interstitial},
month = {aug},
number = {2},
pages = {560--567},
pmid = {15286324},
publisher = {Radiological Society of North America Inc.},
title = {{CT features of lung disease in patients with systemic scerosis: Comparison with idiopathic pulmonary fibrosis and nonspecific interstitial pneumonia}},
url = {https://pubs.rsna.org/doi/abs/10.1148/radiol.2322031223 https://pubmed.ncbi.nlm.nih.gov/15286324/},
volume = {232},
year = {2004}
}
@article{Elhai2017,
abstract = {Objectives to determine the causes of death and risk factors in systemic sclerosis (SSc). Methods Between 2000 and 2011, we examined the death certificates of all French patients with SSc to determine causes of death. then we examined causes of death and developed a score associated with all-cause mortality from the international European Scleroderma trials and research (EUStAr) database. Candidate prognostic factors were tested by Cox proportional hazards regression model by single variable analysis, followed by a multiple variable model stratified by centres. the bootstrapping technique was used for internal validation. results We identified 2719 French certificates of deaths related to SSc, mainly from cardiac (31%) and respiratory (18%) causes, and an increase in SSc-specific mortality over time. over a median follow-up of 2.3 years, 1072 (9.6%) of 11 193 patients from the EUStAr sample died, from cardiac disease in 27% and respiratory causes in 17%. By multiple variable analysis, a risk score was developed, which accurately predicted the 3-year mortality, with an area under the curve of 0.82. the 3-year survival of patients in the upper quartile was 53%, in contrast with 98% in the first quartile. Conclusion Combining two complementary and detailed databases enabled the collection of an unprecedented 3700 deaths, revealing the major contribution of the cardiopulmonary system to SSc mortality. We also developed a robust score to risk-stratify these patients and estimate their 3-year survival. With the emergence of new therapies, these important observations should help caregivers plan and refine the monitoring and management to prolong these patients' survival.},
author = {Elhai, Muriel and Meune, Christophe and Boubaya, Marouane and Avouac, J{\'{e}}r{\^{o}}me and Hachulla, Eric and Balbir-Gurman, Alexandra and Riemekasten, Gabriela and paolo Air{\`{o}} and Joven, Beatriz and Vettori, Serena and Cozzi, Franco and Ullman, Susanne and Czirj{\'{a}}k, L{\'{a}}szl{\'{o}} and Heitmann, Stefan and W distler, J{\"{o}}rg H and thierry Zenone and Seidel, Matthias and Vacca, Alessandra and de Langhe, Ellen and Novak, Srdan and Cutolo, Maurizio and Mouthon, Luc and Henes, J{\"{o}}rg and Chizzolini, Carlo and {Alberto von M{\"{u}}hlen}, Carlos and Solanki, Kamal and Rednic, Simona and Stamp, Lisa and Anic, Branimir and ortiz Santamaria, Vera and de Santis, Maria and Yavuz, Sule and {Alberto Sifuentes-Giraldo}, Walter and Chatelus, Emmanuel and Stork, Jiri and van Laar, Jacob and Loyo, Esthela and paloma {Garc{\'{i}}a de la pe{\~{n}}a Lefebvre} and Eyerich, Kilian and Cosentino, Vanesa and {Jose Alegre-Sancho}, Juan and otylia Kowal-Bielecka and Rey, Gr{\'{e}}goire and Matucci-Cerinic, Marco and Allanore, Yannick},
doi = {10.1136/annrheumdis-2017-211448},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Elhai et al. - 2017 - Mohammed tikly, 13 Ulf M{\"{u}}ller-Ladner, 14 paola Caramaschi, 15 oliver distler, 16 Florenzo Iannone, 17 Lidia p Anan.pdf:pdf},
journal = {Ann Rheum Dis},
pages = {37},
title = {{Mohammed tikly, 13 Ulf M{\"{u}}ller-Ladner, 14 paola Caramaschi, 15 oliver distler, 16 Florenzo Iannone, 17 Lidia p Ananieva, 18 roger Hesselstrand, 19 radim Becvar, 20 Armando Gabrielli, 21 nemanja damjanov, 22 Maria J Salvador, 23 Valeria riccieri, 24 Carina }},
url = {http://ard.bmj.com/},
volume = {76},
year = {2017}
}
@article{Elhai2017a,
abstract = {Objectives To determine the causes of death and risk factors in systemic sclerosis (SSc).

Methods Between 2000 and 2011, we examined the death certificates of all French patients with SSc to determine causes of death. Then we examined causes of death and developed a score associated with all-cause mortality from the international European Scleroderma Trials and Research (EUSTAR) database. Candidate prognostic factors were tested by Cox proportional hazards regression model by single variable analysis, followed by a multiple variable model stratified by centres. The bootstrapping technique was used for internal validation.

Results We identified 2719 French certificates of deaths related to SSc, mainly from cardiac (31%) and respiratory (18%) causes, and an increase in SSc-specific mortality over time. Over a median follow-up of 2.3 years, 1072 (9.6%) of 11â193 patients from the EUSTAR sample died, from cardiac disease in 27% and respiratory causes in 17%. By multiple variable analysis, a risk score was developed, which accurately predicted the 3-year mortality, with an area under the curve of 0.82. The 3-year survival of patients in the upper quartile was 53%, in contrast with 98% in the first quartile.

Conclusion Combining two complementary and detailed databases enabled the collection of an unprecedented 3700 deaths, revealing the major contribution of the cardiopulmonary system to SSc mortality. We also developed a robust score to risk-stratify these patients and estimate their 3-year survival. With the emergence of new therapies, these important observations should help caregivers plan and refine the monitoring and management to prolong these patients' survival.},
author = {Elhai, Muriel and Meune, Christophe and Boubaya, Marouane and Avouac, J{\'{e}}r{\^{o}}me and Hachulla, Eric and Balbir-Gurman, Alexandra and Riemekasten, Gabriela and Air{\`{o}}, Paolo and Joven, Beatriz and Vettori, Serena and Cozzi, Franco and Ullman, Susanne and Czirj{\'{a}}k, L{\'{a}}szl{\'{o}} and Tikly, Mohammed and M{\"{u}}ller-Ladner, Ulf and Caramaschi, Paola and Distler, Oliver and Iannone, Florenzo and Ananieva, Lidia P. and Hesselstrand, Roger and Becvar, Radim and Gabrielli, Armando and Damjanov, Nemanja and Salvador, Maria J. and Riccieri, Valeria and Mihai, Carina and Sz{\"{u}}cs, Gabriella and Walker, Ulrich A. and Hunzelmann, Nicolas and Martinovic, Duska and Smith, Vanessa and M{\"{u}}ller, Carolina De Souza and Montecucco, Carlo Maurizio and Opris, Daniela and Ingegnoli, Francesca and Vlachoyiannopoulos, Panayiotis G. and Stamenkovic, Bojana and Rosato, Edoardo and Heitmann, Stefan and Distler, J{\"{o}}rg H.W. and Zenone, Thierry and Seidel, Matthias and Vacca, Alessandra and Langhe, Ellen De and Novak, Srdan and Cutolo, Maurizio and Mouthon, Luc and Henes, J{\"{o}}rg and Chizzolini, Carlo and M{\"{u}}hlen, Carlos Alberto Von and Solanki, Kamal and Rednic, Simona and Stamp, Lisa and Anic, Branimir and Santamaria, Vera Ortiz and Santis, Maria De and Yavuz, Sule and Sifuentes-Giraldo, Walter Alberto and Chatelus, Emmanuel and Stork, Jiri and Laar, Jacob Van and Loyo, Esthela and {De La Pe{\~{n}}a Lefebvre}, Paloma Garcia and Eyerich, Kilian and Cosentino, Vanesa and Alegre-Sancho, Juan Jose and Kowal-Bielecka, Otylia and Rey, Gr{\'{e}}goire and Matucci-Cerinic, Marco and Allanore, Yannick},
doi = {10.1136/ANNRHEUMDIS-2017-211448},
issn = {0003-4967},
journal = {Annals of the Rheumatic Diseases},
keywords = {cardiovascular disease,epidemiology,pulmonary fibrosis,systemic sclerosis},
month = {nov},
number = {11},
pages = {1897--1905},
pmid = {28835464},
publisher = {BMJ Publishing Group Ltd},
title = {{Mapping and predicting mortality from systemic sclerosis}},
url = {https://ard.bmj.com/content/76/11/1897 https://ard.bmj.com/content/76/11/1897.abstract},
volume = {76},
year = {2017}
}
@article{Zhou,
abstract = {In this work, we revisit the global average pooling layer proposed in [13], and shed light on how it explicitly enables the convolutional neural network (CNN) to have remarkable localization ability despite being trained on image-level labels. While this technique was previously proposed as a means for regularizing training, we find that it actually builds a generic localizable deep representation that exposes the implicit attention of CNNs on an image. Despite the apparent simplicity of global average pooling, we are able to achieve 37.1% top-5 error for object localization on ILSVRC 2014 without training on any bounding box annotation .We demonstrate in a variety of experiments that our network is able to localize the discriminative image regions despite just being trained for solving classification task 1 .},
author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - Unknown - Learning Deep Features for Discriminative Localization.pdf:pdf},
title = {{Learning Deep Features for Discriminative Localization}},
url = {http://cnnlocalization.csail.mit.edu}
}
@article{Brock,
abstract = {Despite recent progress in generative image modeling, successfully generating high-resolution, diverse samples from complex datasets such as ImageNet remains an elusive goal. To this end, we train Generative Adversarial Networks at the largest scale yet attempted, and study the instabilities specific to such scale. We find that applying orthogonal regularization to the generator renders it amenable to a simple "truncation trick," allowing fine control over the trade-off between sample fidelity and variety by reducing the variance of the Generator's input. Our modifications lead to models which set the new state of the art in class-conditional image synthesis. When trained on ImageNet at 128Ã128 resolution, our models (BigGANs) achieve an Inception Score (IS) of 166.5 and Fr{\'{e}}chet Inception Distance (FID) of 7.4, improving over the previous best IS of 52.52 and FID of 18.65.},
archivePrefix = {arXiv},
arxivId = {1809.11096v2},
author = {Brock, Andrew and Donahue, Jeff and Simonyan, Karen},
eprint = {1809.11096v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Brock, Donahue, Simonyan - Unknown - LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS.pdf:pdf},
title = {{LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS}},
url = {https://tfhub.dev/s?q=biggan}
}
@inproceedings{Perez2018,
abstract = {We introduce a general-purpose conditioning method for neural networks called FiLM: Feature-wise Linear Modulation. FiLM layers influence neural network computation via a simple, feature-wise affine transformation based on conditioning information. We show that FiLM layers are highly effective for visual reasoning - answering image-related questions which require a multi-step, high-level process - a task which has proven difficult for standard deep learning methods that do not explicitly model reasoning. Specifically, we show on visual reasoning tasks that FiLM layers 1) halve state-of-the-art error for the CLEVR benchmark, 2) modulate features in a coherent manner, 3) are robust to ablations and architectural modifications, and 4) generalize well to challenging, new data from few examples or even zero-shot.},
archivePrefix = {arXiv},
arxivId = {1709.07871},
author = {Perez, Ethan and Strub, Florian and {De Vries}, Harm and Dumoulin, Vincent and Courville, Aaron},
booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
eprint = {1709.07871},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Perez et al. - Unknown - FiLM Visual Reasoning with a General Conditioning Layer.pdf:pdf},
isbn = {9781577358008},
pages = {3942--3951},
title = {{FiLM: Visual reasoning with a general conditioning layer}},
url = {www.aaai.org},
year = {2018}
}
@inproceedings{Zhang2021,
abstract = {Due to the intensive cost of labor and expertise in annotating 3D medical images at a voxel level, most benchmark datasets are equipped with the annotations of only one type of organs and/or tumors, resulting in the so-called partially labeling issue. To address this issue, we propose a dynamic on-demand network (DoDNet) that learns to segment multiple organs and tumors on partially labeled datasets. DoDNet consists of a shared encoder-decoder architecture, a task encoding module, a controller for dynamic filter generation, and a single but dynamic segmentation head. The information of current segmentation task is encoded as a task-aware prior to tell the model what the task is expected to achieve. Different from existing approaches which fix kernels after training, the kernels in dynamic head are generated adaptively by the controller, conditioned on both input image and assigned task. Thus, DoDNet is able to segment multiple organs and tumors, as done by multiple networks or a multi-head network, in a much efficient and flexible manner. We created a large-scale partially labeled dataset called MOTS and demonstrated the superior performance of our DoDNet over other competitors on seven organ and tumor segmentation tasks. We also transferred the weights pre-trained on MOTS to a downstream multi-organ segmentation task and achieved state-of-the-art performance. This study provides a general 3D medical image segmentation model that has been pre-trained on a large-scale partially labeled dataset and can be extended (after fine-tuning) to downstream volumetric medical data segmentation tasks. Code and models are available at: https://git.io/DoDNet.},
archivePrefix = {arXiv},
arxivId = {2011.10217},
author = {Zhang, Jianpeng and Xie, Yutong and Xia, Yong and Shen, Chunhua},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR46437.2021.00125},
eprint = {2011.10217},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - Unknown - DoDNet Learning to Segment Multi-Organ and Tumors from Multiple Partially Labeled Datasets(2).pdf:pdf},
isbn = {9781665445092},
issn = {10636919},
pages = {1195--1204},
title = {{DoDNet: Learning to Segment Multi-Organ and Tumors from Multiple Partially Labeled Datasets}},
url = {https://git.io/DoDNet},
year = {2021}
}
@inproceedings{Dmitriev2019,
abstract = {Multi-class segmentation has recently achieved significant performance in natural images and videos. This achievement is due primarily to the public availability of large multi-class datasets. However, there are certain domains, such as biomedical images, where obtaining sufficient multi-class annotations is a laborious and often impossible task and only single-class datasets are available. While existing segmentation research in such domains use private multi-class datasets or focus on single-class segmentations, we propose a unified highly efficient framework for robust simultaneous learning of multi-class segmentations by combining single-class datasets and utilizing a novel way of conditioning a convolutional network for the purpose of segmentation. We demonstrate various ways of incorporating the conditional information, perform an extensive evaluation, and show compelling multi-class segmentation performance on biomedical images, which outperforms current state-of-the-art solutions (up to 2.7%). Unlike current solutions, which are meticulously tailored for particular single-class datasets, we utilize datasets from a variety of sources. Furthermore, we show the applicability of our method also to natural images and evaluate it on the Cityscapes dataset. We further discuss other possible applications of our proposed framework.},
author = {Dmitriev, Konstantin and Kaufman, Arie E},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2019.00973},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dmitriev, Kaufman - Unknown - Learning Multi-Class Segmentations From Single-Class Datasets.pdf:pdf},
isbn = {9781728132938},
issn = {10636919},
keywords = {Biological and Cell Microscopy,Grouping and Shape,Medical,Scene Analysis and Understanding,Segmentation},
pages = {9493--9503},
title = {{Learning multi-class segmentations from single-class datasets}},
volume = {2019-June},
year = {2019}
}

@article{Miyato,
abstract = {We propose a novel, projection based way to incorporate the conditional information into the discriminator of GANs that respects the role of the conditional information in the underlining probabilistic model. This approach is in contrast with most frameworks of conditional GANs used in application today, which use the conditional information by concatenating the (embedded) conditional vector to the feature vectors. With this modification, we were able to significantly improve the quality of the class conditional image generation on ILSVRC2012 (Im-ageNet) 1000-class image dataset from the current state-of-the-art result, and we achieved this with a single pair of a discriminator and a generator. We were also able to extend the application to super-resolution and succeeded in producing highly discriminative super-resolution images. This new structure also enabled high quality category transformation based on parametric functional transformation of conditional batch normalization layers in the generator. The code with Chainer (Tokui et al., 2015), generated images and pretrained models are available at https://github.com/pfnet-research/sngan_projection.},
archivePrefix = {arXiv},
arxivId = {1802.05637v2},
author = {Miyato, Takeru and Koyama, Masanori},
eprint = {1802.05637v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Miyato, Koyama - Unknown - CGANS WITH PROJECTION DISCRIMINATOR.pdf:pdf},
title = {{CGANS WITH PROJECTION DISCRIMINATOR}},
url = {https://github.com/pfnet-research/sngan_projection.}
}
@article{Odena2017,
abstract = {In this paper we introduce new methods for the improved training of generative adversarial networks (GANs) for image synthesis. We construct a variant of GANs employing label conditioning that results in 128 Ã 128 resolution image samples exhibiting global coherence. We expand on previous work for image quality assessment to provide two new analyses for assessing the discriminability and diversity of samples from class-conditional image synthesis models. These analyses demonstrate that high resolution samples provide class information not present in low resolution samples. Across 1000 ImageNet classes, 128 Ã 128 samples are more than twice as discriminable as artificially resized 32 Ã 32 samples. In addition, 84.7% of the classes have samples exhibiting diversity comparable to real ImageNet data.},
archivePrefix = {arXiv},
arxivId = {1610.09585v4},
author = {Odena, Augustus and Olah, Christopher and Shlens, Jonathon},
eprint = {1610.09585v4},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Odena, Olah, Shlens - 2017 - Conditional Image Synthesis with Auxiliary Classifier GANs.pdf:pdf},
title = {{Conditional Image Synthesis with Auxiliary Classifier GANs}},
url = {https://github.com/openai/improved-gan/.},
year = {2017}
}
@article{Ding2020,
abstract = {This work proposes the continuous conditional generative adversarial network (CcGAN), the first generative model for image generation conditional on continuous , scalar conditions (termed regression labels). Existing conditional GANs (cGANs) are mainly designed for categorical conditions (e.g., class labels); conditioning on regression labels is mathematically distinct and raises two fundamental problems: (P1) Since there may be very few (even zero) real images for some regression labels, minimizing existing empirical versions of cGAN losses (a.k.a. empirical cGAN losses) often fails in practice; (P2) Since regression labels are scalar and infinitely many, conventional label input methods (e.g., combining a hidden map of the generator/discriminator with a one-hot encoded label) are not applicable. The proposed CcGAN solves the above problems, respectively, by (S1) reformulating existing empirical cGAN losses to be appropriate for the continuous scenario; and (S2) proposing a novel method to incorporate regression labels into the generator and the discriminator. The reformulation in (S1) leads to two novel empirical discriminator losses, termed the hard vicinal discriminator loss (HVDL) and the soft vicinal discriminator loss (SVDL) respectively, and a novel empirical generator loss. The error bounds of a discriminator trained with HVDL and SVDL are derived under mild assumptions in this work. A new benchmark dataset, RC-49, is also proposed for generative image modeling conditional on regression labels. Our experiments on the Circular 2-D Gaussians, RC-49, and UTKFace datasets show that CcGAN is able to generate diverse, high-quality samples from the image distribution conditional on a given regression label. Moreover, in these experiments, CcGAN substantially outperforms cGAN both visually and quantitatively.},
author = {Ding, Xin and Wang, Yongwei and Xu, Zuheng and Welch, William J and {Jane Wang}, Z.},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ding et al. - Unknown - CCGAN CONTINUOUS CONDITIONAL GENERATIVE ADVERSARIAL NETWORKS FOR IMAGE GENERATION.pdf:pdf},
issn = {23318422},
journal = {arXiv},
keywords = {CcGAN,Conditional generative adversarial networks,Continuous and scalar conditions,Image generation},
title = {{CcGAN: Continuous conditional generative adversarial networks for image generation}},
year = {2020}
}
@article{Yi2019,
abstract = {Generative adversarial networks have gained a lot of attention in the computer vision community due to their capability of data generation without explicitly modelling the probability density function. The adversarial loss brought by the discriminator provides a clever way of incorporating unlabeled samples into training and imposing higher order consistency. This has proven to be useful in many cases, such as domain adaptation, data augmentation, and image-to-image translation. These properties have attracted researchers in the medical imaging community, and we have seen rapid adoption in many traditional and novel applications, such as image reconstruction, segmentation, detection, classification, and cross-modality synthesis. Based on our observations, this trend will continue and we therefore conducted a review of recent advances in medical imaging using the adversarial training scheme with the hope of benefiting researchers interested in this technique.},
archivePrefix = {arXiv},
arxivId = {1809.07294},
author = {Yi, Xin and Walia, Ekta and Babyn, Paul},
doi = {10.1016/j.media.2019.101552},
eprint = {1809.07294},
file = {:C\:/Users/jjia/Downloads/full-text.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Deep learning,Generative adversarial network,Generative model,Medical imaging,Review},
month = {dec},
pages = {101552},
pmid = {31521965},
publisher = {Elsevier},
title = {{Generative adversarial network in medical imaging: A review}},
volume = {58},
year = {2019}
}
@article{Mahajan2018,
abstract = {State-of-the-art visual perception models for a wide range of tasks rely on supervised pretraining. ImageNet classification is the de facto pretraining task for these models. Yet, ImageNet is now nearly ten years old and is by modern standards "small". Even so, relatively little is known about the behavior of pretraining with datasets that are multiple orders of magnitude larger. The reasons are obvious: such datasets are difficult to collect and annotate. In this paper, we present a unique study of transfer learning with large convolutional networks trained to predict hashtags on billions of social media images. Our experiments demonstrate that training for large-scale hashtag prediction leads to excellent results. We show improvements on several image classification and object detection tasks, and report the highest ImageNet-1k single-crop, top-1 accuracy to date: 85.4% (97.6% top-5). We also perform extensive experiments that provide novel empirical data on the relationship between large-scale pretraining and transfer learning performance.},
archivePrefix = {arXiv},
arxivId = {1805.00932v1},
author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and {Van Der}, Laurens and Facebook, Maaten},
eprint = {1805.00932v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mahajan et al. - 2018 - Exploring the Limits of Weakly Supervised Pretraining.pdf:pdf},
title = {{Exploring the Limits of Weakly Supervised Pretraining}},
year = {2018}
}
@article{Zhou2019,
abstract = {Transfer learning from natural image to medical image has established as one of the most practical paradigms in deep learning for medical image analysis. However, to fit this paradigm, 3D imaging tasks in the most prominent imaging modalities (e.g., CT and MRI) have to be reformulated and solved in 2D, losing rich 3D anatomical information and inevitably compromising the performance. To overcome this limitation, we have built a set of models, called Generic Autodidactic Models, nicknamed Models Genesis, because they are created ex nihilo (with no manual labeling), self-taught (learned by self-supervision), and generic (served as source models for generating application-specific target models). Our extensive experiments demonstrate that our Models Genesis significantly outperform learning from scratch in all five target 3D applications covering both segmentation and classification. More importantly, learning a model from scratch simply in 3D may not necessarily yield performance better than transfer learning from ImageNet in 2D, but our Models Genesis consistently top any 2D approaches including fine-tuning the models pre-trained from ImageNet as well as fine-tuning the 2D versions of our Models Genesis, confirming the importance of 3D anatomical information and significance of our Models Genesis for 3D medical imaging. This performance is attributed to our unified self-supervised learning framework, built on a simple yet powerful observation: the sophisticated yet recurrent anatomy in medical images can serve as strong supervision signals for deep models to learn common anatomical representation automatically via self-supervision. As open science, all pre-trained Models Genesis are available at https://github.com/MrGiovanni/ModelsGenesis.},
archivePrefix = {arXiv},
arxivId = {1908.06912},
author = {Zhou, Zongwei and Sodha, Vatsal and {Rahman Siddiquee}, Md Mahfuzur and Feng, Ruibin and Tajbakhsh, Nima and Gotway, Michael B. and Liang, Jianming},
doi = {10.1007/978-3-030-32251-9_42},
eprint = {1908.06912},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2019 - Models Genesis Generic Autodidactic Models for 3D Medical Image Analysis.pdf:pdf},
isbn = {9783030322502},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
month = {oct},
pages = {384--393},
publisher = {Springer, Cham},
title = {{Models Genesis: Generic Autodidactic Models for 3D Medical Image Analysis}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-32251-9_42},
volume = {11767 LNCS},
year = {2019}
}
@article{Chen2019,
abstract = {The performance on deep learning is significantly affected by volume of training data. Models pre-trained from massive dataset such as ImageNet become a powerful weapon for speeding up training convergence and improving accuracy. Similarly, models based on large dataset are important for the development of deep learning in 3D medical images. However, it is extremely challenging to build a sufficiently large dataset due to difficulty of data acquisition and annotation in 3D medical imaging. We aggregate the dataset from several medical challenges to build 3DSeg-8 dataset with diverse modalities, target organs, and pathologies. To extract general medical three-dimension (3D) features, we design a heterogeneous 3D network called Med3D to co-train multi-domain 3DSeg-8 so as to make a series of pre-trained models. We transfer Med3D pre-trained models to lung segmentation in LIDC dataset, pulmonary nodule classification in LIDC dataset and liver segmentation on LiTS challenge. Experiments show that the Med3D can accelerate the training convergence speed of target 3D medical tasks 2 times compared with model pre-trained on Kinetics dataset, and 10 times compared with training from scratch as well as improve accuracy ranging from 3% to 20%. Transferring our Med3D model on state-the-of-art DenseASPP segmentation network, in case of single model, we achieve 94.6\% Dice coefficient which approaches the result of top-ranged algorithms on the LiTS challenge.},
archivePrefix = {arXiv},
arxivId = {1904.00625},
author = {Chen, Sihong and Ma, Kai and Zheng, Yefeng},
eprint = {1904.00625},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen, Ma, Zheng - Unknown - MED3D TRANSFER LEARNING FOR 3D MEDICAL IMAGE ANALYSIS.pdf:pdf},
issn = {2331-8422},
title = {{Med3D: Transfer Learning for 3D Medical Image Analysis}},
url = {https://github.com/Tencent/MedicalNet. http://arxiv.org/abs/1904.00625},
year = {2019}
}
@article{Wang2018,
abstract = {Cascaded refinement network [5] Our result (c) Application: Edit object appearance (b) Application: Change label types (a) Synthesized result Figure 1: We propose a generative adversarial framework for synthesizing 2048 Ã 1024 images from semantic label maps (lower left corner in (a)). Compared to previous work [5], our results express more natural textures and details. (b) We can change labels in the original label map to create new scenes, like replacing trees with buildings. (c) Our framework also allows a user to edit the appearance of individual objects in the scene, e.g. changing the color of a car or the texture of a road. Please visit our website for more side-by-side comparisons as well as interactive editing demos. Abstract We present a new method for synthesizing high-resolution photo-realistic images from semantic label maps using conditional generative adversarial networks (condi-tional GANs). Conditional GANs have enabled a variety of applications, but the results are often limited to low-resolution and still far from realistic. In this work, we generate 2048 Ã 1024 visually appealing results with a novel adversarial loss, as well as new multi-scale generator and discriminator architectures. Furthermore, we extend our framework to interactive visual manipulation with two additional features. First, we incorporate object instance seg-mentation information, which enables object manipulations such as removing/adding objects and changing the object category. Second, we propose a method to generate diverse results given the same input, allowing users to edit the object appearance interactively. Human opinion studies demonstrate that our method significantly outperforms existing methods, advancing both the quality and the resolution of deep image synthesis and editing.},
archivePrefix = {arXiv},
arxivId = {1711.11585v2},
author = {Wang, Ting-Chun and Liu, Ming-Yu and Zhu, Jun-Yan and Tao, Andrew and Kautz, Jan and Catanzaro, Bryan},
eprint = {1711.11585v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2018 - High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs.pdf:pdf},
title = {{High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs}},
year = {2018}
}
@article{Uzunova2020,
abstract = {Machine learning methods heavily rely on the availability of large annotated datasets of a certain domain for training. However, freely available datasets of patients with pathologies rarely contain annotations of normal structures, thus cannot be used as ground truth for various image processing methods. To overcome this issue, we propose a topology preserving unpaired domain translation method, including an explicit pathology integration to generate annotated ground truth data of pathological domains. Moreover, we integrate a novel inverse probabilistic approach to generate deformations of the surrounding caused by pathological tissue. Our experiments show the necessity for annotated pathological data for algorithm evaluation. Furthermore, when training neural networks on healthy data and testing on real pathological images, the results are strongly impaired. By generating training data with pathologies using the proposed method, the performance of segmentation and registration methods increases significantly. The best results are achieved by also integrating pathology-induced tissue deformations.},
author = {Uzunova, Hristina and Ehrhardt, Jan and Handels, Heinz},
doi = {10.1007/978-3-030-59719-1_49},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Uzunova, Ehrhardt, Handels - 2020 - Generation of Annotated Brain Tumor MRIs with Tumor-induced Tissue Deformations for Training and Ass.pdf:pdf},
isbn = {9783030597184},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
keywords = {Domain translation,Transfer learning,Tumor generation},
month = {oct},
pages = {501--511},
publisher = {Springer, Cham},
title = {{Generation of Annotated Brain Tumor MRIs with Tumor-induced Tissue Deformations for Training and Assessment of Neural Networks}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-59719-1_49},
volume = {12264 LNCS},
year = {2020}
}
@article{Barthelemy2015,
abstract = {Dysferlinopathies are a family of disabling muscular dystrophies with LGMD2B and Miyoshi myopathy as the main phenotypes. They are associated with molecular defects in DYSF, which encodes dysferlin, a key player in sarcolemmal homeostasis. Previous investigations have suggested that exon skipping may be a promising therapy for a subset of patients with dysferlinopathies. Such an approach aims to rescue functional proteins when targeting modular proteins and specific tissues. We sought to evaluate the dysferlin functional recovery following exon 32 skipping in the cells of affected patients. Exon skipping efficacy was characterized at several levels by use of in vitro myotube formation assays and quantitative membrane repair and recovery tests. Data obtained from these assessments confirmed that dysferlin function is rescued by quasi-dysferlin expression in treated patient cells, supporting the case for a therapeutic antisense-based trial in a subset of dysferlin-deficient patients.},
author = {Barth{\'{e}}l{\'{e}}my, Florian and Blouin, C{\'{e}}dric and Wein, Nicolas and Mouly, Vincent and Courrier, S{\'{e}}bastien and Dionnet, Eug{\'{e}}nie and Kergourlay, Virginie and Mathieu, Yves and Garcia, Luis and Butler-Browne, Gillian and Lamaze, Christophe and L{\'{e}}vy, Nicolas and Krahn, Martin and Bartoli, Marc},
doi = {10.3233/JND-150109},
file = {:E\:/jjia/others documents/course/How to review a paper/MS_62842-15-109.pdf:pdf},
issn = {22143602},
journal = {Journal of Neuromuscular Diseases},
keywords = {Dysferlinopathy,Exon-skipping,Membrane,Neuromuscular diseases,Therapy},
number = {3},
pages = {281--290},
pmid = {27858744},
title = {{Exon 32 Skipping of Dysferlin Rescues Membrane Repair in Patients' Cells}},
volume = {2},
year = {2015}
}
@book{Reyes2021,
author = {Reyes, Mauricio and Henriques, Pedro and Cardoso, Jaime and Hajij, Mustafa and Zamzmi, Ghada and Rahul, Paul and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/iMIMIC.pdf:pdf},
isbn = {9783030874438},
title = {{Interpretability of Machine Intelligence in Medical Image Computing , and Topological Data Analysis Founding Editors}},
year = {2021}
}
@book{Haq2021,
author = {Haq, Nandinee and Johnson, Patricia and Maier, Andreas and W{\"{u}}rfl, Tobias and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/MLMIR.pdf:pdf},
isbn = {9783030885519},
title = {{for Medical}},
year = {2021}
}
@book{Wang2019,
author = {Wang, Qian and Shi, Yinghuan and Shen, DInggang},
booktitle = {IEEE Journal of Biomedical and Health Informatics},
doi = {10.1109/JBHI.2019.2920801},
file = {:E\:/jjia/papers/miccai/2021/MLMI.pdf:pdf},
isbn = {9783030875886},
issn = {21682208},
number = {4},
pages = {1361--1362},
title = {{Machine Learning in Medical Imaging}},
volume = {23},
year = {2019}
}
@book{Eds2021,
author = {Eds, Julia Schnabel and Goos, Gerhard},
doi = {10.1007/978-3-030-87602-9},
file = {:E\:/jjia/papers/miccai/2021/PRIME.pdf:pdf},
isbn = {9783030876012},
title = {{Predictive Intelligence in Medicine}},
year = {2021}
}
@book{Martel2021,
abstract = {part1;},
author = {Martel, Anne L and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A and Zhou, S Kevin and Racoceanu, Daniel and Joskowicz, Leo and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/part VIII.pdf:pdf},
isbn = {9783030597092},
title = {{Medical Image Computing and Computer Assisted Intervention - MICCAI 2021 - Part VIII}},
year = {2021}
}
@book{Sudre2021,
author = {Sudre, Carole H and Licandro, Roxane and Baumgartner, Christian and Melbourne, Andrew and Dalca, Adrian and Hutter, Jana and Tanno, Ryutaro and Abaci, Esra and Koen, Turk and Torrents, Jordina and William, Barrena and Goos, Gerhard},
doi = {10.1007/978-3-030-87735-4},
file = {:E\:/jjia/papers/miccai/2021/UNSURE.pdf:pdf},
isbn = {9783030877347},
title = {{Uncertainty for Safe Utilization of Machine Learning in Medical Imaging , and Perinatal Imaging , Placental and Preterm Image Analysis Lecture Notes in Computer Science Founding Editors}},
year = {2021}
}
@book{Gooya2020,
author = {Gooya, Ali and Eds, Ninon Burgos and Hutchison, David},
file = {:E\:/jjia/papers/miccai/2021/SASHIMI.pdf:pdf},
isbn = {9783030005351},
title = {{Simulation and Synthesis 2020}},
year = {2020}
}
@book{Martel2021a,
abstract = {part1;},
author = {Martel, Anne L and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A and Zhou, S Kevin and Racoceanu, Daniel and Joskowicz, Leo and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/part I.pdf:pdf},
isbn = {9783030597092},
title = {{Medical Image Computing and Computer Assisted Intervention â MICCAI 2020 (P1)}},
year = {2021}
}
@book{Chen2017,
author = {Chen, X J and Li, S and Trucco, E and Liu, J J and Shi, Y G and Zou, B J},
booktitle = {Computerized Medical Imaging and Graphics},
file = {:E\:/jjia/papers/miccai/2021/OMIA.pdf:pdf},
isbn = {0895-6111},
pages = {1},
title = {{Ophthalmic Medical Image Analysis Preface}},
volume = {55},
year = {2017}
}
@book{Noble2021,
author = {Noble, J Alison and Aylward, Stephen and Grimwood, Alexander and Min, Zhe and Yipeng, Su-lin Lee and Eds, Hu and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/ASMUS.pdf:pdf},
isbn = {9783030875824},
title = {{Simplifying Medical Ultrasound}},
year = {2021}
}
@book{Rashid2021,
author = {Rashid, Shazia and Kathuria, Neha},
booktitle = {Big Data and Artificial Intelligence for Healthcare Applications},
doi = {10.1201/9781003093770-5},
file = {:E\:/jjia/papers/miccai/2021/MLCN.pdf:pdf},
isbn = {9783030875855},
pages = {69--82},
title = {{Machine Learning in Clinical Trials}},
year = {2021}
}
@book{Albarqouni2021,
author = {Albarqouni, Shadi and Cardoso, M Jorge and Dou, Qi and Kamnitsas, Konstantinos and Khanal, Bishesh and Rekik, Islem and Rieke, Nicola and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/DARTandFAIR.pdf:pdf},
isbn = {9783030877217},
title = {{Domain Adaptation and Representation Transfer , and Affordable Healthcare and AI for Founding Editors}},
year = {2021}
}
@book{Cetin-karayumak2021,
author = {Cetin-karayumak, Suheyla and Christiaens, Daan and Figini, Matteo and Guevara, Pamela and Gyori, Noemi and Nath, Vishwesh and Pieciak, Tomasz and Goos, Gerhard},
doi = {10.1007/978-3-030-87615-9},
file = {:E\:/jjia/papers/miccai/2021/CDMRI.pdf:pdf},
isbn = {9783030876142},
title = {{Computational Diffusion MRI}},
year = {2021}
}
@book{Engelhardt2021,
author = {Engelhardt, Sandy and Oksuz, Ilkay and Zhu, Dajiang and Yuan, Yixuan and Mukhopadhyay, Anirban and Heller, Nicholas and Xiaolei, Sharon and Hien, Huang and Sznitman, Raphael and Xue, Yuan and Goos, Gerhard},
file = {:E\:/jjia/papers/miccai/2021/DGM4MICCAI.pdf:pdf},
isbn = {9783030882099},
title = {{Deep Generative Models , and Data Augmentation , Labelling , and Imperfections}},
year = {2021}
}
@article{Goodfellow,
abstract = {We propose a new framework for estimating generative models via an adversar-ial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1 2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
author = {Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goodfellow et al. - Unknown - Generative Adversarial Nets.pdf:pdf},
title = {{Generative Adversarial Nets}},
url = {http://www.github.com/goodfeli/adversarial}
}
@article{Choi2007,
abstract = {We evaluated the clinical significance of serum N-terminal pro-brain natriuretic peptide (NT-proBNP) level in systemic sclerosis (SSc). We studied 45 SSc patients (30 with limited and 15 with diffuse cutaneous SSc) of mean age Â± SD 47.1âÂ±â12.9Â years, mean duration of disease 10.2âÂ±â6.0Â years, and 45 age- and sex-matched healthy controls. Pulmonary artery pressure was measured by echocardiography. Lung involvement was evaluated by pulmonary function testing and by using high-resolution computed tomography scores. Serum NT-proBNP levels were measured using a sandwich electrochemiluminescent immunoassay. Serum NT-proBNP levels were significantly higher in patients with SSc compared to healthy controls. When the patients were divided into clinical subsets, serum NT-proBNP was higher in diffuse SSc than in limited SSc. Serum NT-proBNP levels were found to be positively correlated with age, skin thickness score, and systolic pulmonary artery pressure and negatively correlated with percentage of carbon monoxide diffusion capacity (DLco). Multivariate analysis showed that serum NT-proBNP levels were positively correlated with age (pâ=â0.010), skin thickness score (pâ=â0.000), and blood pressure (pâ=â0.021) and negatively correlated with %DLco (pâ=â0.016). Fifty-seven percent of the variation in log (proBNP) can be explained by the multivariate model (R
                        2â=â0.57). Serum NT-proBNP levels were higher in SSc patients (particularly the diffuse subset) than in healthy controls and were found to be correlated with skin thickness and %DLco. We conclude that serum NT-proBNP may be a biologic marker of skin fibrosis and pulmonary vascular involvement in SSc.},
author = {Choi, Hyo Jin and Shin, Young Kee and Lee, Hyun Joo and Kee, Joo Young and Shin, Dong Woo and Lee, Eun Young and Lee, Yun Jong and Lee, Eun Bong and Song, Yeong Wook},
doi = {10.1007/S10067-007-0724-9},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Choi et al. - 2007 - The clinical significance of serum N-terminal pro-brain natriuretic peptide in systemic sclerosis patients.pdf:pdf},
issn = {1434-9949},
journal = {Clinical Rheumatology 2007 27:4},
keywords = {Rheumatology},
month = {sep},
number = {4},
pages = {437--442},
publisher = {Springer},
title = {{The clinical significance of serum N-terminal pro-brain natriuretic peptide in systemic sclerosis patients}},
url = {https://link.springer.com/article/10.1007/s10067-007-0724-9},
volume = {27},
year = {2007}
}
@article{Pandey2010,
abstract = {Purpose: To evaluate the imaging features on high-resolution computed tomography (HRCT) of the chest and the clinical parameters that are associated with pulmonary hypertension in systemic sclerosis. We specifically investigated whether main pulmonary artery (MPA) diameter and burden of lung fibrosis are predictors of pulmonary hypertension in these patients. Methods: We retrospectively retrieved the database information of patients with systemic sclerosis seen at our hospital between January 2007 and December 2008. A total of 75 patients had HRCT of the chest, pulmonary function testing (PFT), and echocardiography within 6 months of each other. The echocardiography images were reviewed by a level-3 echocardiographer, and 29 cases were excluded because of suboptimal evaluation of pulmonary artery (PA) pressure. Peak PA pressures and PFT of the remaining 46 cases (43 women and 3 men) were charted. The PFT included total lung capacity (TLC), diffusion capacity of lung for carbon monooxide (DLCO) and the ratio of forced expiratory volume in one second and forced vital capacity (FEV1/FVC). The HRCT of the chest of each patient was read by a chest radiologist. The extent of ground glass, reticulation, and honeycombing was objectively scored. The maximum diameter of the main pulmonary artery (MPAD) and ascending aorta were measured. The ratio of main pulmonary artery diameter and ascending aortic diameter (MPAD/AD) and ratio of main pulmonary artery diameter and body surface area (MPAD/BSA) were also calculated. Results: Statistical analysis done by using a multivariate model showed that the calculated fibrotic score strongly correlated with peak PA pressures (P < .001). MPAD (P = .0175), and the ratio MPAD/AD (P = .0102) also showed a statistically significant correlation with peak PA pressures. By using stepwise regression analysis, the fibrotic score was found to be the most reliable independent predictor of pulmonary hypertension. Conclusion: HRCT-determined severity and extent of pulmonary fibrosis may be helpful in screening for pulmonary hypertension in patients with systemic sclerosis. {\textcopyright} 2010 Canadian Association of Radiologists. All rights reserved.},
author = {Pandey, Anoop Kumar and Wilcox, Pearce and Mayo, John R. and Sin, Donald and Moss, Robert and Ellis, Jennifer and Brown, Jacquie and Leipsic, Jonathon},
doi = {10.1016/j.carj.2010.02.006},
issn = {08465371},
journal = {Canadian Association of Radiologists Journal},
keywords = {Fibrotic score,High-resolution computed tomography,Pulmonary hypertension,Scleroderma},
month = {dec},
number = {5},
pages = {291--296},
pmid = {20382500},
publisher = {Can Assoc Radiol J},
title = {{Predictors of pulmonary hypertension on high-resolution computed tomography of the chest in systemic sclerosis: A retrospective analysis}},
url = {https://pubmed.ncbi.nlm.nih.gov/20382500/},
volume = {61},
year = {2010}
}
@article{Goldin2008,
abstract = {Background: Lung disease has become the leading cause of mortality and morbidity in scleroderma (SSc) patients. The frequency, nature, and progression of interstitial lung disease seen on high-resolution CT (HRCT) scans in patients with diffuse SSc (dcSSc) compared with those with limited SSc (lcSSc) has not been well characterized. Methods: Baseline HRCT scan images of 162 participants randomized into a National Institutes of Health-funded clinical trial were compared to clinical features, pulmonary function test measures, and BAL fluid cellularity. The extent and distribution of interstitial lung disease HRCT findings, including pure ground-glass opacity (pGGO), pulmonary fibrosis (PF), and honeycomb cysts (HCs), were recorded in the upper, middle, and lower lung zones on baseline and follow-up CT scan studies. Results: HRCT scan findings included 92.9% PF, 49.4% pGGO, and 37.2% HCs. There was a significantly higher incidence of HCs in the three zones in lcSSc patients compared to dcSSc patients (p = 0.034, p = 0.048, and p = 0.0007, respectively). The extent of PF seen on HRCT scans was significantly negatively correlated with FVC (r = - 0.22), diffusing capacity of the lung for carbon monoxide (r = - 0.44), and total lung capacity (r = - 0.36). A positive correlation was found between pGGO and the increased number of acute inflammatory cells found in BAL fluid (r = 0.28). In the placebo group, disease progression was assessed as 30% in the upper and middle lung zones, and 45% in the lower lung zones. No difference in the progression rate was seen between lcSSc and dcSSc patients. Conclusions: PF and GGO were the most common HRCT scan findings in symptomatic SSc patients. HCs were seen in more than one third of cases, being more common in lcSSc vs dcSSc. There was no relationship between progression and baseline PF extent or lcSSc vs dcSSc. Trial registration: Clinicaltrials.gov Identifier: NCT00004563. Copyright {\textcopyright} 2008 by American College of Chest Physicians.},
author = {Goldin, Jonathan G. and Lynch, David A. and Strollo, Diane C. and Suh, Robert D. and Schraufnagel, Dean E. and Clements, Philip J. and Elashoff, Robert M. and Furst, Daniel E. and Vasunilashorn, Sarinnapha and McNitt-Gray, Michael F. and Brown, Mathew S. and Roth, Michael D. and Tashkin, Donald P.},
doi = {10.1378/CHEST.07-2444},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goldin et al. - 2008 - High-Resolution CT Scan Findings in Patients With Symptomatic Scleroderma-Related Interstitial Lung Disease.pdf:pdf},
issn = {0012-3692},
journal = {Chest},
keywords = {CT scan,Lung disease,Scleroderma},
month = {aug},
number = {2},
pages = {358--367},
publisher = {Elsevier},
title = {{High-Resolution CT Scan Findings in Patients With Symptomatic Scleroderma-Related Interstitial Lung Disease}},
volume = {134},
year = {2008}
}
@article{Humphries2017,
abstract = {Our findings that data-driven textural analysis fibrosis score is associated with baseline measures of disease severity and with change over time suggest that CT captures anatomic information that ...},
author = {Humphries, Stephen M. and Yagihashi, Kunihiro and Huckleberry, Jason and Rho, Byung-Hak and Schroeder, Joyce D. and Strand, Matthew and Schwarz, Marvin I. and Flaherty, Kevin R. and Kazerooni, Ella A. and van Beek, Edwin J. R. and Lynch, David A.},
doi = {10.1148/RADIOL.2017161177},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Humphries et al. - 2017 - Idiopathic Pulmonary Fibrosis Data-driven Textural Analysis of Extent of Fibrosis at Baseline and 15-Month Fol.pdf:pdf},
journal = {https://doi.org/10.1148/radiol.2017161177},
month = {may},
number = {1},
pages = {270--278},
publisher = { Radiological Society of North America },
title = {{Idiopathic Pulmonary Fibrosis: Data-driven Textural Analysis of                    Extent of Fibrosis at Baseline and 15-Month Follow-up}},
url = {https://pubs.rsna.org/doi/abs/10.1148/radiol.2017161177},
volume = {285},
year = {2017}
}
@article{Ninaber2015a,
abstract = {Introduction Interstitial lung disease occurs frequently in patients with systemic sclerosis (SSc). Quantitative computed tomography (CT) densitometry using the percentile density method may provide a sensitive assessment of lung structure for monitoring parenchymal damage. Therefore, we aimed to evaluate the optimal percentile density score in SSc by quantitative CT densitometry, against pulmonary function. Material and methods We investigated 41 SSc patients by chest CT scan, spirometry and gas transfer tests. Lung volumes and the nth percentile density (between 1 and 99%) of the entire lungs were calculated from CT histograms. The nth percentile density is defined as the threshold value of densities expressed in Hounsfield units. A prerequisite for an optimal percentage was its correlation with baseline DLCO %predicted. Two patients showed distinct changes in lung function 2 years after baseline. We obtained CT scans from these patients and performed progression analysis. Results Regression analysis for the relation between DLCO %predicted and the nth percentile density was optimal at 85% (Perc85). There was significant agreement between Perc85 and DLCO %predicted (R = -0.49, P = 0.001) and FVC %predicted (R = -0.64, P < 0.001). Two patients showed a marked change in Perc85 over a 2 year period, but the localization of change differed clearly. Conclusions We identified Perc85 as optimal lung density parameter, which correlated significantly with DLCO and FVC, confirming a lung parenchymal structure-function relation in SSc. This provides support for future studies to determine whether structural changes do precede lung function decline.},
author = {Ninaber, Maarten K. and Stolk, Jan and Smit, Jasper and {Le Roy}, Ernest J. and Kroft, Lucia J.M. and {Els Bakker}, M. and {De Vries Bouwstra}, Jeska K. and Schouffoer, Anne A. and Staring, Marius and Stoel, Berend C.},
doi = {10.1016/J.EJRAD.2015.01.012},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ninaber et al. - 2015 - Lung structure and function relation in systemic sclerosis Application of lung densitometry.pdf:pdf},
issn = {0720-048X},
journal = {European Journal of Radiology},
keywords = {Chest CT imaging,Interstitial lung disease,Lung densitometry,Systemic sclerosis},
month = {may},
number = {5},
pages = {975--979},
publisher = {Elsevier},
title = {{Lung structure and function relation in systemic sclerosis: Application of lung densitometry}},
volume = {84},
year = {2015}
}

@inproceedings{Zeiler2014,
abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets. {\textcopyright} 2014 Springer International Publishing.},
archivePrefix = {arXiv},
arxivId = {1311.2901},
author = {Zeiler, Matthew D and Fergus, Rob},
booktitle = {European conference on computer vision},
doi = {10.1007/978-3-319-10590-1_53},
eprint = {1311.2901},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zeiler, Fergus - 2014 - LNCS 8689 - Visualizing and Understanding Convolutional Networks.pdf:pdf},
isbn = {9783319105895},
issn = {16113349},
number = {PART 1},
pages = {818--833},
title = {{Visualizing and understanding convolutional networks}},
url = {https://cs.nyu.edu/$\sim$fergus/papers/zeilerECCV2014.pdf%0Ahttp://www.matthewzeiler.com/pubs/arxive2013/eccv2014.pdf},
volume = {8689 LNCS},
year = {2014}
}

@article{McHugh2012,
abstract = {The kappa statistic is frequently used to test interrater reliability. The importance of rater reliability lies in the fact that it represents the extent to which the data collected in the study are correct representations of the variables measured. Measurement of the extent to which data collectors (raters) assign the same score to the same variable is called interrater reliability. While there have been a variety of methods to measure interrater reliability, traditionally it was measured as percent agreement, calculated as the number of agreement scores divided by the total number of scores. In 1960, Jacob Cohen critiqued use of percent agreement due to its inability to account for chance agreement. He introduced the Cohen's kappa, developed to account for the possibility that raters actually guess on at least some variables due to uncertainty. Like most correlation statistics, the kappa can range from -1 to +1. While the kappa is one of the most commonly used statistics to test interrater reliability, it has limitations. Judgments about what level of kappa should be acceptable for health research are questioned. Cohen's suggested interpretation may be too lenient for health related studies because it implies that a score as low as 0.41 might be acceptable. Kappa and percent agreement are compared, and levels for both kappa and percent agreement that should be demanded in healthcare studies are suggested.},
author = {McHugh, Mary L.},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/McHugh - 2012 - Interrater reliability the kappa statistic.pdf:pdf},
journal = {Biochemia Medica},
keywords = {Interrater,Kappa,Rater,Reliability},
number = {3},
pages = {276},
pmid = {23092060},
publisher = {Croatian Society for Medical Biochemistry and Laboratory Medicine},
title = {{Interrater reliability: the kappa statistic}},
url = {/pmc/articles/PMC3900052/ /pmc/articles/PMC3900052/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3900052/},
volume = {22},
year = {2012}
}

@article{Zhang2019,
abstract = {Real-world visual data often exhibits a long-tailed distribution, where some ''head'' classes have a large number of samples, yet only a few samples are available for ''tail'' classes. Such imbalanced distribution causes a great challenge for learning a deep neural network, which can be boiled down into a dilemma: on the one hand, we prefer to increase the exposure of tail class samples to avoid the excessive dominance of head classes in the classifier training. On the other hand, oversampling tail classes makes the network prone to over-fitting, since head class samples are often consequently under-represented. To resolve this dilemma, in this paper, we propose a simple-yet-effective auxiliary learning approach. The key idea is to split a network into a classifier part and a feature extractor part, and then employ different training strategies for each part. Specifically, to promote the awareness of tail-classes, a class-balanced sampling scheme is utilised for training both the classifier and the feature extractor. For the feature extractor, we also introduce an auxiliary training task, which is to train a classifier under the regular random sampling scheme. In this way, the feature extractor is jointly trained from both sampling strategies and thus can take advantage of all training data and avoid the over-fitting issue. Apart from this basic auxiliary task, we further explore the benefit of using self-supervised learning as the auxiliary task. Without using any bells and whistles, our model achieves superior performance over the state-of-the-art solutions.},
archivePrefix = {arXiv},
arxivId = {1912.04486},
author = {Zhang, Junjie and Liu, Lingqiao and Wang, Peng and Shen, Chunhua},
eprint = {1912.04486},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhang et al. - Unknown - To Balance or Not to Balance A Simple-yet-Effective Approach for Learning with Long-Tailed Distributions.pdf:pdf},
isbn = {1912.04486v2},
journal = {ArXiv 1912.04486 [preprint]},
keywords = {Auxiliary Learning,Class Balance Sampling,Long-Tail},
title = {{To Balance or Not to Balance: A Simple-yet-Effective Approach for Learning with Long-Tailed Distributions}},
url = {http://arxiv.org/abs/1912.04486},
year = {2019}
}
@article{Zhai2018,
abstract = {Objectives Balloon pulmonary angioplasty (BPA) in patients with inoperable chronic thromboembolic pulmonary hypertension (CTEPH) can have variable outcomes. To gain more insight into this variation, we designed a method for visualizing and quantifying changes in pulmonary perfusion by automatically comparing computed tomography (CT) pulmonary angiography before and after BPA treatment. We validated these quantifications of perfusion changes against hemodynamic changes measured with right-sided heart catheterization. Materials and Methods We studied 14 consecutive CTEPH patients (12 women; age, 70.5 Â± 24), who underwent CT pulmonary angiography and right-sided heart catheterization, before and after BPA. Posttreatment images were registered to pretreatment CT scans (using the Elastix toolbox) to obtain corresponding locations. Pulmonary vascular trees and their centerlines were detected using a graph cuts method and a distance transform method, respectively. Areas distal from vessels were defined as pulmonary parenchyma. Subsequently, the density changes within the vascular centerlines and parenchymal areas were calculated and corrected for inspiration level differences. For visualization, the densitometric changes were displayed in color-coded overlays. For quantification, the median and interquartile range of the density changes in the vascular and parenchymal areas ($\Delta$VD and $\Delta$PD) were calculated. The recorded changes in hemodynamic parameters, including changes in systolic, diastolic, and mean pulmonary artery pressure ($\Delta$sPAP, $\Delta$dPAP, and $\Delta$mPAP, respectively) and vascular resistance ($\Delta$PVR), were used as reference assessments of the treatment effect. Spearman correlation coefficients were employed to investigate the correlations between changes in perfusion and hemodynamic changes. Results Comparative imaging maps showed distinct patterns in perfusion changes among patients. Within pulmonary vessels, the interquartile range of $\Delta$VD correlated significantly with $\Delta$sPAP (R = -0.58, P = 0.03), $\Delta$dPAP (R = -0.71, P = 0.005), $\Delta$mPAP (R = -0.71, P = 0.005), and $\Delta$PVR (R = -0.77, P = 0.001). In the parenchyma, the median of $\Delta$PD had significant correlations with $\Delta$dPAP (R = -0.58, P = 0.030) and $\Delta$mPAP (R = -0.59, P = 0.025). Conclusions Comparative imaging analysis in CTEPH patients offers insight into differences in BPA treatment effect. Quantification of perfusion changes provides noninvasive measures that reflect hemodynamic changes.},
author = {Zhai, Zhiwei and Ota, Hideki and Staring, Marius and Stolk, Jan and Sugimura, Koichiro and Takase, Kei and Stoel, Berend C.},
doi = {10.1097/RLI.0000000000000441},
issn = {15360210},
journal = {Investigative Radiology},
keywords = {balloon pulmonary angioplasty,chronic thromboembolic pulmonary hypertension,computed tomography,imaging quantifications},
month = {may},
number = {5},
pages = {286--292},
pmid = {29278545},
publisher = {Lippincott Williams and Wilkins},
title = {{Treatment Effect of Balloon Pulmonary Angioplasty in Chronic Thromboembolic Pulmonary Hypertension Quantified by Automatic Comparative Imaging in Computed Tomography Pulmonary Angiography}},
url = {https://journals.lww.com/investigativeradiology/Fulltext/2018/05000/Treatment_Effect_of_Balloon_Pulmonary_Angioplasty.5.aspx},
volume = {53},
year = {2018}
}
@article{Liu2019,
abstract = {A deep learning model showed improved overall sensitivity compared with manual identification of pulmonary nodules and was insensitive to radiation dose, patient age, or CT manufacturer; the model ...},
author = {Liu, Kai and Li, Qiong and Ma, Jiechao and Zhou, Zijian and Sun, Mengmeng and Deng, Yufeng and Tu, Wenting and Wang, Yun and Fan, Li and Xia, Chen and Xiao, Yi and Zhang, Rongguo and Liu, Shiyuan},
doi = {10.1148/RYAI.2019180084},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - 2019 - Evaluating a Fully Automated Pulmonary Nodule Detection Approach and Its Impact on Radiologist Performance.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2019180084},
month = {may},
number = {3},
pages = {e180084},
publisher = { Radiological Society of North America },
title = {{Evaluating a Fully Automated Pulmonary Nodule Detection Approach and                     Its Impact on Radiologist Performance}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2019180084},
volume = {1},
year = {2019}
}
@article{Parakh2019,
abstract = {A cascading convolutional neural network model, enriched with labeled CT images, detected the presence of urinary tract stones on unenhanced abdominopelvic CT scans with high accuracy (area under r...},
author = {Parakh, Anushri and Lee, Hyunkwang and Lee, Jeong Hyun and Eisner, Brian H. and Sahani, Dushyant V. and Do, Synho},
doi = {10.1148/RYAI.2019180066},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Parakh et al. - 2019 - Urinary Stone Detection on CT Images Using Deep Convolutional Neural Networks Evaluation of Model Performance and.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2019180066},
month = {jul},
number = {4},
pages = {e180066},
publisher = { Radiological Society of North America },
title = {{Urinary Stone Detection on CT Images Using Deep Convolutional Neural                     Networks: Evaluation of Model Performance and Generalization}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2019180066},
volume = {1},
year = {2019}
}
@article{Commandeur2019,
abstract = {Deep learning allows for fast, robust, and fully automated quantification of epicardial adipose tissue from nonâcontrast materialâenhanced calcium-scoring CT.},
author = {Commandeur, Frederic and Goeller, Markus and Razipour, Aryabod and Cadet, Sebastien and Hell, Michaela M. and Kwiecinski, Jacek and Chen, Xi and Chang, Hyuk-Jae and Marwan, Mohamed and Achenbach, Stephan and Berman, Daniel S. and Slomka, Piotr J. and Tamarappoo, Balaji K. and Dey, Damini},
doi = {10.1148/RYAI.2019190045},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Commandeur et al. - 2019 - Fully Automated CT Quantification of Epicardial Adipose Tissue by Deep Learning A Multicenter Study.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2019190045},
month = {nov},
number = {6},
pages = {e190045},
publisher = { Radiological Society of North America },
title = {{Fully Automated CT Quantification of Epicardial Adipose Tissue by                     Deep Learning: A Multicenter Study}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2019190045},
volume = {1},
year = {2019}
}
@article{Sabottke2020,
abstract = {Tracking convolutional neural network performance as a function of image resolution allows insight into how the relative subtlety of different radiology findings can affect the success of deep lear...},
author = {Sabottke, Carl F. and Spieler, Bradley M.},
doi = {10.1148/RYAI.2019190015},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sabottke, Spieler - 2020 - The Effect of Image Resolution on Deep Learning in Radiography.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2019190015},
month = {jan},
number = {1},
pages = {e190015},
publisher = { Radiological Society of North America },
title = {{The Effect of Image Resolution on Deep Learning in                     Radiography}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2019190015},
volume = {2},
year = {2020}
}
@article{Mongan2020,
abstract = {The advent of deep neural networks as a new artificial intelligence (AI) technique has engendered a large number of medical applications, particularly in medical imaging. Such applications of AI must remain grounded in the fundamental tenets of science and scientific publication (1). Scientific results must be reproducible, and a scientific publication must describe the authors' work in sufficient detail to enable readers to determine the rigor, quality, and generalizability of the work, and potentially to reproduce the work's results. A number of valuable manuscript checklists have come into widespread use, including the Standards for Reporting of Diagnostic Accuracy Studies (STARD) (2â5), Strengthening the Reporting of Observational studies in Epidemiology (STROBE) (6), and Consolidated Standards of Reporting Trials (CONSORT) (7,8). A radiomics quality score has been proposed to assess the quality of radiomics studies (9).},
author = {Mongan, John and Moy, Linda and {Charles                             E.  Kahn}, Jr},
doi = {10.1148/RYAI.2020200029},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mongan, Moy, Charles E. Kahn - 2020 - Checklist for Artificial Intelligence in Medical Imaging (CLAIM) A Guide for Authors and Reviewers.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2020200029},
month = {mar},
number = {2},
pages = {e200029},
publisher = { Radiological Society of North America },
title = {{Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A                     Guide for Authors and Reviewers}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020200029},
volume = {2},
year = {2020}
}
@article{Thomas2020,
abstract = {An end-to-end interpretable model that takes full knee radiographs as input and assesses osteoarthritis severity with comparable performance to individual musculoskeletal radiologists and does not ...},
author = {Thomas, Kevin A. and Kidzi{\'{n}}ski, {\L}ukasz and Halilaj, Eni and Fleming, Scott L. and Venkataraman, Guhan R. and Oei, Edwin H. G. and Gold, Garry E. and Delp, Scott L.},
doi = {10.1148/RYAI.2020190065},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Thomas et al. - 2020 - Automated Classification of Radiographic Knee Osteoarthritis Severity Using Deep Neural Networks.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2020190065},
month = {mar},
number = {2},
pages = {e190065},
publisher = { Radiological Society of North America },
title = {{Automated Classification of Radiographic Knee Osteoarthritis Severity                     Using Deep Neural Networks}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190065},
volume = {2},
year = {2020}
}
@article{Meijs2020,
abstract = {The automated segmentation of cerebral vasculature into arteries and veins is feasible using deep learning, and quantitative and qualitative evaluations of the deep learning network showed that seg...},
author = {Meijs, Midas and Pegge, Sjoert A. H. and Vos, Maria H. E. and Patel, Ajay and van de Leemput, Sil C. and Koschmieder, Kevin and Prokop, Mathias and Meijer, Frederick J. A. and Manniesing, Rashindra},
doi = {10.1148/RYAI.2020190178},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meijs et al. - 2020 - Cerebral Artery and Vein Segmentation in Four-dimensional CT Angiography Using Convolutional Neural Networks.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2020190178},
month = {jul},
number = {4},
pages = {e190178},
publisher = { Radiological Society of North America },
title = {{Cerebral Artery and Vein Segmentation in Four-dimensional CT                     Angiography Using Convolutional Neural Networks}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190178},
volume = {2},
year = {2020}
}
@article{Humpire-Mamani2020,
abstract = {Automatic spleen segmentation using deep learning is feasible in complex scenarios, such as oncologic follow-up, and may aid radiologists in accurately assessing splenic volume change over time.},
author = {Humpire-Mamani, Gabriel E. and Bukala, Joris and Scholten, Ernst T. and Prokop, Mathias and van Ginneken, Bram and Jacobs, Colin},
doi = {10.1148/RYAI.2020190102},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Humpire-Mamani et al. - 2020 - Fully Automatic Volume Measurement of the Spleen at CT Using Deep Learning.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2020190102},
month = {jul},
number = {4},
pages = {e190102},
publisher = { Radiological Society of North America },
title = {{Fully Automatic Volume Measurement of the Spleen at CT Using Deep                     Learning}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190102},
volume = {2},
year = {2020}
}
@article{Cai2020,
abstract = {Deep learning can accurately segment neuroanatomy on CT scans; optimizations that improved segmentation performance for structures with varying size and slicewise prevalence were assessed, includin...},
author = {Cai, Jason C. and Akkus, Zeynettin and Philbrick, Kenneth A. and Boonrod, Arunnit and Hoodeshenas, Safa and Weston, Alexander D. and Rouzrokh, Pouria and Conte, Gian Marco and Zeinoddini, Atefeh and Vogelsang, David C. and Huang, Qiao and Erickson, Bradley J.},
doi = {10.1148/ryai.2020190183},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Cai et al. - 2020 - Fully Automated Segmentation of Head CT Neuroanatomy Using Deep Learning.pdf:pdf},
issn = {2638-6100},
journal = {Radiology: Artificial Intelligence},
month = {sep},
number = {5},
pages = {e190183},
publisher = {Radiological Society of North America},
title = {{Fully Automated Segmentation of Head CT Neuroanatomy Using Deep Learning}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190183},
volume = {2},
year = {2020}
}
@article{Chaganti2020,
abstract = {Automated quantification of abnormalities associated with COVID-19 from chest CT could help clinicians evaluate the disease and assess its severity and progression. This study proposes measures of ...},
author = {Chaganti, Shikha and Grenier, Philippe and Balachandran, Abishek and Chabin, Guillaume and Cohen, Stuart and Flohr, Thomas and Georgescu, Bogdan and Grbic, Sasa and Liu, Siqi and Mellot, Fran{\c{c}}ois and Murray, Nicolas and Nicolaou, Savvas and Parker, William and Re, Thomas and Sanelli, Pina and Sauter, Alexander W. and Xu, Zhoubing and Yoo, Youngjin and Ziebandt, Valentin and Comaniciu, Dorin},
doi = {10.1148/RYAI.2020200048},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chaganti et al. - 2020 - Automated Quantification of CT Patterns Associated with COVID-19 from Chest CT.pdf:pdf},
journal = {https://doi.org/10.1148/ryai.2020200048},
keywords = {CT,Lung,Quantification/Vision/Application Domain,Reinforcement Learning,Segmentation/Vision/Application Domain,Supervised Learning},
month = {jul},
number = {4},
pages = {e200048},
publisher = { Radiological Society of North America },
title = {{Automated Quantification of CT Patterns Associated with COVID-19 from                     Chest CT}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020200048},
volume = {2},
year = {2020}
}
@article{Meijs2016a,
abstract = {Objectives To determine the outcomes, including number of medical interventions and initiation of immunosuppressive treatment of a standardised, comprehensive, diagnostic care pathway for patients with systemic sclerosis (SSc). Patient characteristics associated with need for medical interventions and with need for immunosuppressive treatment were determined.

Methods Data were routinely gathered in connection with a 2-day care pathway combining multidisciplinary care and complete diagnostic work-up of organ involvement in SSc. The number of patients in whom the pathway resulted in medical interventions, and/or initiation of immunosuppressives was recorded. Patient characteristics and diagnostic tests results were compared between patients with and without medical interventions, and patients with and without initiation of immunosuppressives by means of multivariable logistic regression analyses.

Results During a period of 44âmonths, 226 patients with SSc were referred to the care pathway. They included 186 (82%) women with mean age of 54 (SD 14.5) years, and median disease duration of 4âyears (range 1â11); 73 (32%) of them had diffuse cutaneous SSc. Medical interventions were initiated in 191 (85%) patients, including initiation of immunosuppressive treatment in n=49 (22%). Presence of telangiectasias and higher erythrocyte sedimentation rate were associated with any medical intervention. Of commonly available variables, lower age, higher skin score and absence of anticentromere antibody were associated with initiation of immunosuppressives.

Conclusions A standardised comprehensive 2-day care pathway for patients with SSc resulted in additional diagnostic or therapeutic interventions in 85% of the patients, regardless of SSc subtype and disease duration. In 22% of the patients, immunosuppressive treatment was initiated.},
author = {Meijs, Jessica and Schouffoer, Anne A and Marsan, Nina Ajmone and Kroft, Lucia J M and Stijnen, Theo and Ninaber, Maarten K and Huizinga, Tom W J and Vlieland, Theodora P M Vliet and de Vries-Bouwstra, Jeska K},
doi = {10.1136/RMDOPEN-2015-000159},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Meijs et al. - 2016 - Therapeutic and diagnostic outcomes of a standardised, comprehensive care pathway for patients with systemic scler.pdf:pdf},
issn = {2056-5933},
journal = {RMD Open},
month = {mar},
number = {1},
pages = {e000159},
publisher = {BMJ Specialist Journals},
title = {{Therapeutic and diagnostic outcomes of a standardised, comprehensive care pathway for patients with systemic sclerosis}},
url = {https://rmdopen.bmj.com/content/2/1/e000159 https://rmdopen.bmj.com/content/2/1/e000159.abstract},
volume = {2},
year = {2016}
}
@techreport{Gou2021,
abstract = {In recent years, deep neural networks have been successful in both industry and academia, especially for computer vision tasks. The great success of deep learning is mainly due to its scalability to encode large-scale data and to maneuver billions of model parameters. However, it is a challenge to deploy these cumbersome deep models on devices with limited resources, e.g., mobile phones and embedded devices, not only because of the high computational complexity but also the large storage requirements. To this end, a variety of model compression and acceleration techniques have been developed. As a representative type of model compression and acceleration, knowledge distillation effectively learns a small student model from a large teacher model. It has received rapid increasing attention from the community. This paper provides a comprehensive survey of knowledge distillation from the perspectives of knowledge categories, training schemes, teacher-student architecture, distillation algorithms, performance comparison and applications. Furthermore, challenges in knowledge distillation are briefly reviewed and comments on future research are discussed and forwarded.},
archivePrefix = {arXiv},
arxivId = {2006.05525v7},
author = {Gou, Jianping and Yu, Baosheng and Maybank, Stephen J and Tao, Dacheng},
eprint = {2006.05525v7},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gou et al. - 2021 - Knowledge Distillation A Survey(2).pdf:pdf},
keywords = {Deep neural networks {\textperiodcentered},Knowledge distillation {\textperiodcentered},Knowledge transfer {\textperiodcentered},Model compression {\textperiodcentered},Teacher-student architecture},
title = {{Knowledge Distillation: A Survey}},
year = {2021}
}
@techreport{Hinton2015,
abstract = {A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions [3]. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators [1] have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on MNIST and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.},
archivePrefix = {arXiv},
arxivId = {1503.02531v1},
author = {Hinton, Geoffrey and Dean, Jeff},
eprint = {1503.02531v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Hinton, Dean - 2015 - Distilling the Knowledge in a Neural Network.pdf:pdf},
keywords = {()},
title = {{Distilling the Knowledge in a Neural Network}},
year = {2015}
}
@techreport{Lopes,
abstract = {Recent advances in model compression have provided procedures for compressing large neural networks to a fraction of their original size while retaining most if not all of their accuracy. However, all of these approaches rely on access to the original training set, which might not always be possible if the network to be compressed was trained on a very large dataset, or on a dataset whose release poses privacy or safety concerns as may be the case for biometrics tasks. We present a method for data-free knowledge distillation, which is able to compress deep neural networks trained on large-scale datasets to a fraction of their size leveraging only some extra metadata to be provided with a pretrained model release. We also explore different kinds of metadata that can be used with our method, and discuss tradeoffs involved in using each of them.},
archivePrefix = {arXiv},
arxivId = {1710.07535v2},
author = {Lopes, Raphael Gontijo and Fenu, Stefano and Starner, Thad},
eprint = {1710.07535v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Lopes, Fenu, Starner - Unknown - Data-Free Knowledge Distillation for Deep Neural Networks.pdf:pdf},
title = {{Data-Free Knowledge Distillation for Deep Neural Networks}}
}
@article{Hussain2021,
abstract = {Kidney volume is an essential biomarker for a number of kidney disease diagnoses, for example, chronic kidney disease. Existing total kidney volume estimation methods often rely on an intermediate kidney segmentation step. On the other hand, automatic kidney localization in volumetric medical images is a critical step that often precedes subsequent data processing and analysis. Most current approaches perform kidney localization via an intermediate classification or regression step. This paper proposes an integrated deep learning approach for (i) kidney localization in computed tomography scans and (ii) segmentation-free renal volume estimation. Our localization method uses a selection-convolutional neural network that approximates the kidney inferior-superior span along the axial direction. Cross-sectional (2D) slices from the estimated span are subsequently used in a combined sagittal-axial Mask-RCNN that detects the organ bounding boxes on the axial and sagittal slices, the combination of which produces a final 3D organ bounding box. Furthermore, we use a fully convolutional network to estimate the kidney volume that skips the segmentation procedure. We also present a mathematical expression to approximate the 'volume error' metric from the 'Sorensen-Dice coefficient.' We accessed 100 patients' CT scans from the Vancouver General Hospital records and obtained 210 patients' CT scans from the 2019 Kidney Tumor Segmentation Challenge database to validate our method. Our method produces a kidney boundary wall localization error of 2.4mm and a mean volume estimation error of 5%.},
author = {Hussain, Mohammad Arafat and Hamarneh, Ghassan and Garbi, Rafeef},
doi = {10.1109/TMI.2021.3060465},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {CNN,FCN,Mask-RCNN,Sorensen-Dice,kidney localization,kidney volume},
month = {jun},
number = {6},
pages = {1555--1567},
pmid = {33606626},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Cascaded Regression Neural Nets for Kidney Localization and Segmentation-free Volume Estimation}},
volume = {40},
year = {2021}
}
@techreport{KevinZhou2021,
abstract = {Deep reinforcement learning (DRL) augments the reinforcement learning framework, which learns a sequence of actions that maximizes the expected reward, with the representative power of deep neural networks. Recent works have demonstrated the great potential of DRL in medicine and health-care.This paper presents a literature review of DRL in medical imaging. We start with a comprehensive tutorial of DRL, including the latest model-free and model-based algorithms. We then cover existing DRL applications for medical imaging, which are roughly divided into three main categories: (i) parametric medical image analysis tasks including landmark detection, ob-ject/lesion detection, registration, and view plane localization; (ii) solving optimization tasks including hyperparameter tuning, selecting augmentation strategies, and neural architecture search; and (iii) miscellaneous applications including surgical gesture segmentation, personalized mobile health intervention, and computational model personalization. The paper concludes with discussions of future perspectives.},
archivePrefix = {arXiv},
arxivId = {2103.05115v1},
author = {{Kevin Zhou}, S and {Ngan Le}, Hoang and Luu, Khoa and Nguyen, Hien V and Ayache, Nicholas},
booktitle = {Medical Image Analysis},
eprint = {2103.05115v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kevin Zhou et al. - 2021 - Deep reinforcement learning in medical imaging A literature review A R T I C L E I N F O.pdf:pdf},
keywords = {Deep reinforcement learning,Medical imaging,Survey},
title = {{Deep reinforcement learning in medical imaging: A literature review A R T I C L E I N F O}},
url = {https://www.technologyreview.com/10-breakthrough-},
year = {2021}
}
@inproceedings{Gu2021,
abstract = {Convolutional neural networks (CNNs) have been increasingly applied to computer-aided diagnosis (CADx) for lung nodule malignancy prediction, which usually is a binary classification task. However, CNNs were often difficult to capture optimal features, thereby affect the classification performance. This study developed a CADx system based on a CNN model with auxiliary task learning to predict lung nodule malignancy in chest computed tomography (CT) scans. Our CADx system took raw CT image cubes centering at nodules as input and generated one main output and eight auxiliary outputs. The main output predicted lung nodule malignancy; the auxiliary outputs predicted lesion size and characteristics. The auxiliary tasks offered assistance for predicting the final nodule malignancy. The performance of the developed lung nodule CADx system was verified by use of the LIDC dataset. Results showed that our CADx system achieved improved performance for lung nodule malignancy prediction.},
author = {Gu, Xiaomeng and Chen, Fucai and Xie, Weiyang and Zhao, Jun and Li, Qiang},
booktitle = {Medical Imaging},
doi = {10.1117/12.2581215},
isbn = {9781510640238},
issn = {16057422},
keywords = {auxiliary task learning,computed tomography,computer-aided diagnosis,convolutional neural network,lung nodule},
month = {feb},
number = {15},
pages = {25},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Lung nodule malignancy prediction in chest CT scans based on a CNN model with auxiliary task learning}},
url = {https://www.spiedigitallibrary.org/terms-of-use},
volume = {2021},
year = {2021}
}
@inproceedings{Xie2021,
abstract = {Lung opacities on CT scans, such as ground-glass opacities (GGOs) and consolidation, can manifest with various conditions, including lung cancers, pulmonary edema and COVID-19. Presentation of these non-specific findings can vary from isolated focal to diffuse opacities in all lobes. Moreover, disease distributions and progressions vary across disease types and patients. This unpredictability can challenge one's ability to accurately quantify and compare the percentage of infected lung within and across patients. Despite the promise of AI models for image segmentation, the inconsistency of lung opacities, and limited access to large annotated datasets affect generalization performance of models to the cohort of lung diseases. In this paper, we developed a single-stage system to jointly localize the lung and opacifications in CT scans using a diverse real-world dataset with sparse annotations. A multi-class Dense U-Net model was designed to segment the lungs and two classes of opacity regions (GGOs and consolidations) in CT images. The model was trained on 4075 slices from 495 sparsely annotated CT studies and evaluated on 18625 slices from 103 densely annotated studies (37 positive). A comparative analysis of different training data subsets and loss functions was performed to determine optimal model design. Performance was evaluated by comparing manual and automated lung opacity percentages via Pearson Correlation Coefficient. The optimal model achieved a Pearson Correlation Coefficient of 0.99. These findings suggest the potential of developing an accurate method to localize lung opacification, unspecific to a particular disease.},
author = {Xie, Yiting and Rajan, Deepta and Schudlo, Larissa and Takeuchi, Yusuke and Graf, Benedikt and Coy, Adam and Negahdar, Mohammadreza and Mukherjee, Vandana and Beymer, David and Krishnan, Arun},
booktitle = {Computer-Aided Diagnosis},
doi = {10.1117/12.2582197},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Xie et al. - 2021 - Automatic localization of lung opacity in chest CT images - a real-world study.pdf:pdf},
isbn = {9781510640238},
issn = {16057422},
keywords = {Ground-glass opacity,chest CT,consolidation,deep learning,opacity segmentation},
month = {feb},
number = {15},
pages = {4},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Automatic localization of lung opacity in chest CT images - a real-world study}},
url = {https://www.spiedigitallibrary.org/terms-of-use},
volume = {2021},
year = {2021}
}
@inproceedings{Singh2021,
abstract = {Total intracranial volume (TIV) is the volume enclosed inside the cranium, inclusive of the meninges and the brain. TIV is extensively used to correct variations in inter-subject head size for the evaluation of neurodegen- erative diseases. In this work, we present an automatic method to generate a TIV mask from MR images while synthesizing a CT image to be used in subsequent analysis. In addition, we propose an alternative way to obtain ground truth TIV masks using a semi-manual approach, which results in significant time savings. We train a conditional generative adversarial network (cGAN) using 2D MR slices to realize our tasks. The quantitative evaluation showed that the model was able to synthesize CT and generate TIV masks that closely approximate the reference images. This study also provides a comparison of the described method against skull stripping tools that output a mask enclosing the cranial volume, using MRI scan. In particular, highlighting the deficiencies in using such tools to approximate the volume using MRI scan.},
author = {Singh, Mallika and Pahl, Eleanor and Wang, Shangxian L. and Carass, Aaron and Lee, Junghoon and Prince, Jerry L.},
doi = {10.1117/12.2582264},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Singh et al. - 2021 - Accurate estimation of total intracranial volume in MRI using a multi-tasked image-to-image translation network.pdf:pdf},
isbn = {9781510640214},
issn = {16057422},
keywords = {Human brain,Intracranial volume,MRI,Synthetic CT},
month = {feb},
number = {15},
pages = {11},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Accurate estimation of total intracranial volume in MRI using a multi-tasked image-to-image translation network}},
url = {https://www.spiedigitallibrary.org/terms-of-use},
volume = {11596},
year = {2021}
}
@inproceedings{Song2021,
abstract = {The recent work has achieved great success in utilizing multi-scale feature ensembling for medical image seg-mentation. In this paper, we propose a new module called cascaded multi-scale feature interaction (CMSI) for choroidal atrophy segmentation in fundus images. The proposed CMSI module makes full use of multi-scale features , including using cascaded pooling and convolution to implement feature interactions at different scales and using strip pooling to capture long-distance features, which makes it more flexible than traditional convolution on the choroidal atrophy region with various scales in fundus image. Based on the U-shape network, we use the ResNet as the backbone to extract hierarchical feature representations. The proposed CMSI module is added at the top of the encoder path. In summary, our main contributions are summarized in two aspects as follows: (1) The CMSI module is proposed for multi-scale feature ensembling by cascading multi-scale pooling and strip pooling. (2) The Dice coefficients of our proposed network on choroidal atrophy segmentation increased by 4.15% compared to U-Net.},
author = {Song, Jiahuan and Chen, Xinjian and Zhu, Weifang},
booktitle = {115960J},
doi = {10.1117/12.2580652},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Song, Chen, Zhu - 2021 - Cascaded multi-scale feature interaction for choroidal atrophy segmentation(2).pdf:pdf},
isbn = {9781510640214},
issn = {16057422},
keywords = {Cascaded Multi-Scale Feature Interaction,Choroidal Atrophy Segmentation,Deep Learning,Med-ical Image Processing},
month = {feb},
number = {15},
pages = {12},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Cascaded multi-scale feature interaction for choroidal atrophy segmentation}},
url = {https://www.spiedigitallibrary.org/terms-of-use},
volume = {11596},
year = {2021}
}
@article{Zhou2021,
abstract = {Transfer learning from natural image to medical image has been established as one of the most practical paradigms in deep learning for medical image analysis. To fit this paradigm, however, 3D imaging tasks in the most prominent imaging modalities (e.g., CT and MRI) have to be reformulated and solved in 2D, losing rich 3D anatomical information, thereby inevitably compromising its performance. To overcome this limitation, we have built a set of models, called Generic Autodidactic Models, nicknamed Models Genesis, because they are created ex nihilo (with no manual labeling), self-taught (learnt by self-supervision), and generic (served as source models for generating application-specific target models). Our extensive experiments demonstrate that our Models Genesis significantly outperform learning from scratch and existing pre-trained 3D models in all five target 3D applications covering both segmentation and classification. More importantly, learning a model from scratch simply in 3D may not necessarily yield performance better than transfer learning from ImageNet in 2D, but our Models Genesis consistently top any 2D/2.5D approaches including fine-tuning the models pre-trained from ImageNet as well as fine-tuning the 2D versions of our Models Genesis, confirming the importance of 3D anatomical information and significance of Models Genesis for 3D medical imaging. This performance is attributed to our unified self-supervised learning framework, built on a simple yet powerful observation: the sophisticated and recurrent anatomy in medical images can serve as strong yet free supervision signals for deep models to learn common anatomical representation automatically via self-supervision. As open science, all codes and pre-trained Models Genesis are available at https://github.com/MrGiovanni/ModelsGenesis.},
archivePrefix = {arXiv},
arxivId = {2004.07882},
author = {Zhou, Zongwei and Sodha, Vatsal and Pang, Jiaxuan and Gotway, Michael B. and Liang, Jianming},
doi = {10.1016/j.media.2020.101840},
eprint = {2004.07882},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhou et al. - 2021 - Models Genesis(2).pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {3D Deep learning,Representation learning,Self-supervised learning,Transfer learning},
month = {jan},
pages = {101840},
pmid = {33188996},
publisher = {Elsevier B.V.},
title = {{Models Genesis}},
volume = {67},
year = {2021}
}
@article{Qin2021,
abstract = {Training convolutional neural networks (CNNs) for segmentation of pulmonary airway, artery, and vein is challenging due to sparse supervisory signals caused by the severe class imbalance between tubular targets and background. We present a CNNs-based method for accurate airway and artery-vein segmentation in non-contrast computed tomography. It enjoys superior sensitivity to tenuous peripheral bronchioles, arterioles, and venules. The method first uses a feature recalibration module to make the best use of features learned from the neural networks. Spatial information of features is properly integrated to retain relative priority of activated regions, which benefits the subsequent channel-wise recalibration. Then, attention distillation module is introduced to reinforce representation learning of tubular objects. Fine-grained details in high-resolution attention maps are passing down from one layer to its previous layer recursively to enrich context. Anatomy prior of lung context map and distance transform map is designed and incorporated for better artery-vein differentiation capacity. Extensive experiments demonstrated considerable performance gains brought by these components. Compared with state-of-the-art methods, our method extracted much more branches while maintaining competitive overall segmentation performance. Codes and models are available at http://www.pami.sjtu.edu.cn/News/56.},
archivePrefix = {arXiv},
arxivId = {2012.05767},
author = {Qin, Yulei and Zheng, Hao and Gu, Yun and Huang, Xiaolin and Yang, Jie and Wang, Lihui and Yao, Feng and Zhu, Yue Min and Yang, Guang Zhong},
doi = {10.1109/TMI.2021.3062280},
eprint = {2012.05767},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Arteries,Atmospheric modeling,Computed tomography,Convolution,Image segmentation,Task analysis,Veins,convolutional neural networks,image segmentation,lung},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Learning Tubule-Sensitive CNNs for Pulmonary Airway and Artery-Vein Segmentation in CT}},
year = {2021}
}
@article{Rayan2019,
abstract = {Deep learning using a multiview approach combining a recurrent neural network and a convolutional neural network can distinguish elbow abnormality from normal growth centers of the pediatric elbow ...},
author = {Rayan, Jesse C. and Reddy, Nakul and Kan, J. Herman and Zhang, Wei and Annapragada, Ananth},
doi = {10.1148/ryai.2019180015},
issn = {2638-6100},
journal = {Radiology: Artificial Intelligence},
month = {jan},
number = {1},
pages = {e180015},
publisher = {Radiological Society of North America (RSNA)},
title = {{Binomial Classification of Pediatric Elbow Fractures Using a Deep Learning Multiview Approach Emulating Radiologist Decision Making}},
url = {https://doi.org/10.1148/ryai.2019180015},
volume = {1},
year = {2019}
}
@article{Rava2021,
abstract = {Purpose: Computed tomography perfusion (CTP) is used to diagnose ischemic strokes through contralateral hemisphere comparisons of various perfusion parameters. Various perfusion parameter thresholds have been utilized to segment infarct tissue due to differences in CTP software and patient baseline hemodynamics. This study utilized a convolutional neural network (CNN) to eliminate the need for non-universal parameter thresholds to segment infarct tissue. Methods: CTP data from 63 ischemic stroke patients was retrospectively collected and perfusion parameter maps were generated using Vitrea CTP software. Infarct ground truth labels were segmented from diffusion-weighted imaging (DWI) and CTP and DWI volumes were registered. A U-net based CNN was trained and tested five separate times using each CTP parameter (cerebral blood flow (CBF), cerebral blood volume (CBV), time-to-peak (TTP), mean-transit-time (MTT), delay time). 8,352 infarct slices were utilized with a 60:30:10 training:testing:validation split and Monte Carlo cross-validation was conducted using 20 iterations. Infarct volumes were reconstructed following segmentation from each CTP slice. Infarct spatial and volumetric agreement was compared between each CTP parameter and DWI. Results: Spatial agreement metrics (Dice coefficient, positive predictive value) for each CTP parameter in predicting infarct volumes are: CBF=(0.67, 0.76), CBV=(0.44, 0.62), TTP=(0.60, 0.67), MTT=(0.58, 0.62), delay time=(0.57, 0.60). 95% confidence intervals for volume differences with DWI infarct are: CBF=14.3Â±11.5 mL, CBV=29.6Â±21.2 mL, TTP=7.7Â±15.2 mL, MTT=â10.7Â±18.6 mL, delay time=â5.7Â±23.6 mL. Conclusions: CBF is the most accurate CTP parameter in segmenting infarct tissue. Segmentation of infarct using a CNN has the potential to eliminate non-universal CTP contralateral hemisphere comparison thresholds.},
author = {Rava, Ryan A and Podgorsak, Alexander R and Waqas, Muhammad and Snyder, Kenneth V and Levy, Elad I and Davies, Jason M and Siddiqui, Adnan H and Ionita, Ciprian N},
doi = {10.1117/12.2579753},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Rava et al. - 2021 - Use of a convolutional neural network to identify infarct core using computed tomography perfusion parameters HHS P.pdf:pdf},
journal = {Proc SPIE Int Soc Opt Eng},
keywords = {Computed tomography perfusion,cerebral infarct tissue,convolutional neural network,semantic segmentation},
title = {{Use of a convolutional neural network to identify infarct core using computed tomography perfusion parameters HHS Public Access}},
volume = {11596},
year = {2021}
}
@article{Chen,
abstract = {Purpose: Vessel segmentation from volumetric medical images is becoming an essential pre-step in aiding the diagnosis, guiding the therapy and patient management for vascular-related diseases. Deep learning-based methods have drawn many attentions, but most of them did not fully utilize the multi-scale spatial information of vessels. To address this shortcoming, we propose a multi-scale network similar to the well-known multi-scale DeepMedic. It also includes a double-pathway architecture and a class-balanced Accepted Article This article is protected by copyright. All rights reserved loss at the voxel level (MDNet-Vb) to achieve both the computation efficiency and segmentation accuracy. Methods: The proposed network consists two parallel pathways to learn the multi-scale vessel morphology. Specifically, the pathway with a normal resolution uses three-dimensional (3D) U-Net fed with small inputs to learn the local details with relatively small storage and time consumption. The pathway with a low resolution employs 3D fully convolutional network (FCN) fed with down-sampled large inputs to learn the overall spatial relationships between vessels and adjacent tissues, and the morphological information of large vessels. To cope with the class-imbalanced issue in vessel segmentation, we propose a class-balanced loss at the voxel level with uniform sampling strategy. The class-balanced loss at the voxel level re-balances the loss function with a coefficient that is inversely proportional to the normalized effective number at the voxel level of each class. The uniform sampling strategy extracts training data by sampling uniformly from two classes in every epoch. Results: Our MDNet-Vb outperforms several state-of-the-art methods including ResNet, DenseNet, 3D U-Net, V-Net and DeepMedic with the highest dice coefficients of 72.91% and 69.32% on cardiac computed tomography angiography (CTA) dataset and cerebral magnetic resonance angiography (MRA) dataset, respectively. Amongst four different double-pathway networks, our network (3D U-Net+3D FCN) not only has the fewest training parameters and shortest training time, but also gets competitive dice coefficients on both the CTA and MRA datasets. Compared with classical losses, our class-balanced focal loss (FL-Vb) and dice coefficient loss at the voxel level (Dsc-Vb) alleviates class imbalanced issue by improving both the sensitivity and dice coefficient on the CTA and MRA datasets. Moreover, simultaneously training on two datasets shows that our method has the highest dice coefficient of 73.06% and 65.40% on CTA and MRA datasets respectively, outperforming the commonly used methods, such as U-Net and DeepMedic, which demonstrates the generalization potential of our network for segmenting different blood vessels. Accepted Article This article is protected by copyright. All rights reserved Conclusions: Our MDNet-Vb method demonstrates its superiority over other state-of-the-art methods, on both cardiac CTA and cerebral MRA datasets. For the network architecture, the MDNet-Vb combined the 3D U-Net and 3D FCN, which dramatically reduces the network parameters yet maintains the segmentation accuracy. The class-balanced loss at the voxel level further improves accuracy by properly alleviating the class-imbalanced issue between different classes. In summary, MDNet-Vb is promising for vessel segmentation from various volumetric medical images.},
author = {Chen, Yibing and Fan, Siqi and Chen, Yongfeng and Che, Chang and Cao, Xin and He, Xiaowei and Song, Xiaolei and Zhao, Fengjun},
doi = {10.1002/MP.14934},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - Unknown - Vessel Segmentation from Volumetric Images A Multi-scale Double-pathway Network with Class-balanced Loss at the.pdf:pdf},
keywords = {Vessel segmentation,computed tomography angiography,deep leaning,fully convolutional network,magnetic resonance angiography},
title = {{Vessel Segmentation from Volumetric Images: A Multi-scale Double-pathway Network with Class-balanced Loss at the Voxel Level Running Title: Vessel segmentation in 3D medical images}}
}

@article{Hoyles2006,
abstract = {Objective. The lack of randomized controlled trials (RCTs) in pulmonary fibrosis in systemic sclerosis (SSc) has hampered an evidence-based approach to treatment. This RCT was undertaken to investigate the effects of intravenous (IV) cyclophosphamide (CYC) followed by azathioprine (AZA) treatment in pulmonary fibrosis in SSc. Methods. Forty-five patients were randomised to receive low-dose prednisolone and 6 infusions (monthly) of CYC followed by oral AZA, or placebo. Primary outcome measures were change in percent predicted forced vital capacity (FVC) and change in single-breath diffusing capacity for carbon monoxide (DLCO). Secondary outcome measures included changes in appearance on high-resolution computed tomography and dyspnea scores. An intent-to-treat statistical analysis was performed. Results. At baseline, there were no significant group differences in factors linked to outcome, including severity of pulmonary fibrosis and autoantibody status. Sixty-two percent of the patients completed the first year of treatment. Withdrawals included 9 patients (6 from the placebo group) with significant decline in lung function, 2 with treatment side effects (both from the active treatment group), and 6 with non-trial-related comorbidity. No hemorrhagic cystitis or bone marrow suppression was observed. Estimation of the relative treatment effect (active treatment versus placebo) adjusted for baseline FVC and treatment center revealed a favorable outcome for FVC of 4.19%; this between-group difference showed a trend toward statistical significance (P = 0.08). No improvements in DLCO or secondary outcome measures were identified. Conclusion. This trial did not demonstrate significant improvement in the primary or secondary end points in the active treatment group versus the group receiving placebo. However, for FVC there was a trend toward statistical significance between the 2 groups. This suggests that treatment of pulmonary fibrosis in SSc with low-dose prednisolone and IV CYC followed by AZA stabilizes long function in a subset of patients with the disease. Therapy was well tolerated with no increase in serious adverse events. {\textcopyright} 2006, American College of Rheumatology.},
author = {Hoyles, Rachel K. and Ellis, Ross W. and Wellsbury, Jessica and Lees, Belinda and Newlands, Pauline and Goh, Nicole S.L. and Roberts, Christopher and Desai, Sujal and Herrick, Ariane L. and McHugh, Neil J. and Foley, Noeleen M. and Pearson, Stanley B. and Emery, Paul and Veale, Douglas J. and Denton, Christopher P. and Wells, Athol U. and Black, Carol M. and {Du Bois}, Roland M.},
doi = {10.1002/art.22204},
issn = {00043591},
journal = {Arthritis and Rheumatism},
month = {dec},
number = {12},
pages = {3962--3970},
pmid = {17133610},
publisher = {John Wiley & Sons, Ltd},
title = {{A multicenter, prospective, randomized, double-blind, placebo-controlled trial of corticosteroids and intravenous cyclophosphamide followed by oral azathioprine for the treatment of pulmonary fibrosis in scleroderma}},
url = {https://onlinelibrary.wiley.com/doi/full/10.1002/art.22204 https://onlinelibrary.wiley.com/doi/abs/10.1002/art.22204 https://onlinelibrary.wiley.com/doi/10.1002/art.22204},
volume = {54},
year = {2006}
}
@article{Assayag2012,
abstract = {Interstitial lung disease commonly develops in patients with Systemic sclerosis (SSc). High resolution computed tomography (HRCT) has become the gold standard for detection and evaluation of lung involvement in SSc. Several HRCT scoring methods have been described and used to characterize and quantify the disease. This article reviews the different scoring systems and how they have been validated clinically and applied to prognosticate patients, assess disease progression and evaluate response to treatment.},
author = {Assayag, D and Kaduri, S and Hudson, M and Hirsch, A and Baron, M},
doi = {10.4172/2161-1149.S1-003},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Assayag et al. - 2012 - High Resolution Computed Tomography Scoring Systems for Evaluating Interstitial Lung Disease in Systemic Scleros.pdf:pdf},
journal = {Rheumatology, an open access journal Assayag et al. Rheumatology},
keywords = {Computed tomography,Interstitial lung disease,Scleroderma,Scoring methods},
pages = {3},
title = {{High Resolution Computed Tomography Scoring Systems for Evaluating Interstitial Lung Disease in Systemic Sclerosis Patients}},
volume = {1},
year = {2012}
}
@article{Pedregosa2011,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
author = {Pedregosa, Fabian and Michel, Vincent and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Vanderplas, Jake and Cournapeau, David and Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Thirion, Bertrand and Grisel, Olivier and Dubourg, Vincent and Passos, Alexandre and Brucher, Matthieu and Perrot and{\'{E}}douardand, Matthieu and Duchesnay, And{\'{E}}douard and Duchesnay, FR{\'{E}}douard},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Pedregosa FABIANPEDREGOSA et al. - 2011 - Scikit-learn Machine Learning in Python Ga{\"{e}}l Varoquaux Bertrand Thirion Vincent Dubourg Alexan.pdf:pdf},
journal = {Journal of Machine Learning Research},
keywords = {Python,model selection,supervised learning,unsupervised learning},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://scikit-learn.sourceforge.net.},
volume = {12},
year = {2011}
}
@article{Ikeda2007,
abstract = {Objectives: To differentiate among atypical adenomatous hyperplasia (AAH), bronchioloalveolar carcinoma (BAC), and adenocarcinoma showing ground-glass opacity (GGO) on CT scans, we conducted a study to determine the optimal parameter on CT number analysis using threedimensional (3D) computerized quantification. Methods: From the CT numbers of GGO lesions obtained by 3D computerized quantification, CT number histogram pattern, peak CT number on the histogram, mean CT number, and the 5th to 95th percentile CT numbers were analyzed to determine the optimal parameter for differentiation among AAH (n = 10), BAC (n = 21), and adenocarcinoma (n = 12). Results: While the CT number histogram showed one peak in all 10 of the AAH lesions (100%), it showed two peaks in 8 of 21 BAC lesions (38%), and in 5 of 12 adenocarcinoma lesions (42%). For differentiation between AAH and BAC, the 75th percentile CT number with a cutoff value of -584 Hounsfield units (HU) was optimal, with a sensitivity of 0.90 and a specificity of 0.81. For differentiation between BAC and adenocarcinoma, a mean CT number with a cutoff value of -472 HU was optimal, with a sensitivity of 0.75 and a specificity of 0.81. Conclusions: From the analysis of CT numbers of GGO lesions obtained by 3D computerized quantification, we conclude the following: (1) two peaks on the CT number histogram can rule out AAH; (2) the 75th percentile is the optimal CT number for differentiating between AAH and BAC; and (3) the mean CT number is the optimal CT number for differentiating between BAC and adenocarcinoma. {\textcopyright} 2007 American College of Chest Physicians.},
author = {Ikeda, Koei and Awai, Kazuo and Mori, Takeshi and Kawanaka, Koichi and Yamashita, Yasuyuki and Nomori, Hiroaki},
doi = {10.1378/chest.07-0793},
issn = {19313543},
journal = {Chest},
keywords = {Lung cancer,Pathology lung cancer,Radiology lung cancer},
month = {sep},
number = {3},
pages = {984--990},
pmid = {17573486},
publisher = {American College of Chest Physicians},
title = {{Differential diagnosis of ground-glass opacity nodules: CT number analysis by three-dimensional computerized quantification}},
volume = {132},
year = {2007}
}
@inproceedings{Li2007,
abstract = {In the Computer-Aided Detection (CAD) of lung nodules in x-ray computed tomography (CT) scans of the thorax, lung segmentation is the preliminary step. This paper proposes a fast, fully automated lung segmentation method for application in X-ray computed tomography. The segmentation method bases on mathematical morphology, which is known for its speed. The method operates slice and slice by three main steps: (1) the lung region is extracted from the CT images by gray-level thresholding, (2) the trachea or bronchi is removed from lung regions and the lung borders are smoothed by morphological operations, and (3) the left and right lungs are separated by geodesic dilation. The performance of the automated segmentation method was evaluated using 1099 computed tomography images (126 thick slice and 973 thin slice scans). The proposed method successfully segmented 95.6% of the 126 thick slice images and 98.3% of the 973 thin slice images. The fast, fully automated lung segmentation method has advantages over other methods in speed, robustness and accuracy.},
author = {Li, W. and Nie, S. D. and Cheng, J. J.},
booktitle = {IFMBE Proceedings},
doi = {10.1007/978-3-540-36841-0_610},
isbn = {9783540368397},
issn = {14339277},
keywords = {Computer-aided detection,Geodesic dilation,Lung segmentation,Mathematical morphology},
number = {1},
pages = {2419--2422},
publisher = {Springer Verlag},
title = {{A fast automatic method of lung segmentation in CT images using mathematical morphology}},
url = {https://link.springer.com/chapter/10.1007/978-3-540-36841-0_610},
volume = {14},
year = {2007}
}
@inproceedings{Harrison2017,
abstract = {Pathological lung segmentation (PLS) is an important, yet challenging, medical image application due to the wide variability of pathological lung appearance and shape. Because PLS is often a pre-requisite for other imaging analytics, methodological simplicity and generality are key factors in usability. Along those lines, we present a bottom-up deep-learning based approach that is expressive enough to handle variations in appearance, while remaining unaffected by any variations in shape. We incorporate the deeply supervised learning framework, but enhance it with a simple, yet effective, progressive multi-path scheme, which more reliably merges outputs from different network stages. The result is a deep model able to produce finer detailed masks, which we call progressive holistically-nested networks (P-HNNs). Using extensive cross-validation, our method is tested on a multi-institutional dataset comprising 929 CT scans (848 publicly available), of pathological lungs, reporting mean dice scores of 0.985 and demonstrating significant qualitative and quantitative improvements over state-of-the art approaches.},
archivePrefix = {arXiv},
arxivId = {1706.03702},
author = {Harrison, Adam P. and Xu, Ziyue and George, Kevin and Lu, Le and Summers, Ronald M. and Mollura, Daniel J.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-66179-7_71},
eprint = {1706.03702},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Harrison et al. - 2017 - Progressive and multi-path holistically nested neural networks for pathological lung segmentation from CT image.pdf:pdf},
isbn = {9783319661780},
issn = {16113349},
keywords = {Holistically nested neural networks,Pathological lung segmentation,Progressive and multi-path convolutional neural ne},
month = {sep},
pages = {621--629},
publisher = {Springer Verlag},
title = {{Progressive and multi-path holistically nested neural networks for pathological lung segmentation from CT images}},
url = {http://hpc.nih.gov},
volume = {10435 LNCS},
year = {2017}
}
@techreport{Mcfee,
abstract = {Sound event detection (SED) methods are tasked with labeling segments of audio recordings by the presence of active sound sources. SED is typically posed as a supervised machine learning problem, requiring strong annotations for the presence or absence of each sound source at every time instant within the recording. However, strong annotations of this type are both labor-and cost-intensive for human annotators to produce, which limits the practical scalability of SED methods. In this work, we treat SED as a multiple instance learning (MIL) problem, where training labels are static over a short excerpt, indicating the presence or absence of sound sources but not their temporal locality. The models, however, must still produce temporally dynamic predictions, which must be aggregated (pooled) when comparing against static labels during training. To facilitate this aggregation, we develop a family of adaptive pooling operators-referred to as auto-pool-which smoothly interpolate between common pooling operators, such as min-, max-, or average-pooling, and automatically adapt to the characteristics of the sound sources in question. We evaluate the proposed pooling operators on three datasets, and demonstrate that in each case, the proposed methods outperform non-adaptive pooling operators for static prediction, and nearly match the performance of models trained with strong, dynamic annotations. The proposed method is evaluated in conjunction with convolutional neural networks, but can be readily applied to any differentiable model for time-series label prediction. While this article focuses on SED applications, the proposed methods are general, and could be applied widely to MIL problems in any domain.},
archivePrefix = {arXiv},
arxivId = {1804.10070v2},
author = {Mcfee, Brian and Salamon, Justin and {Pablo Bello}, Juan},
eprint = {1804.10070v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Mcfee, Salamon, Pablo Bello - Unknown - IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGE PROCESSING, IN PRESS, 2018 Adaptive pooling oper.pdf:pdf},
keywords = {Index Terms-Sound event detection,deep learning,machine learning,mul-tiple instance learning},
title = {{IEEE TRANSACTIONS ON AUDIO, SPEECH AND LANGUAGE PROCESSING, IN PRESS, 2018 Adaptive pooling operators for weakly labeled sound event detection}}
}
@techreport{Redmon2016,
abstract = {We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation. Since the whole detection pipeline is a single network, it can be optimized end-to-end directly on detection performance. Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork.},
author = {Redmon, Joseph and Divvala, Santosh and Girshick, Ross and Farhadi, Ali},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Redmon et al. - 2016 - You Only Look Once Unified, Real-Time Object Detection.pdf:pdf},
pages = {779--788},
title = {{You Only Look Once: Unified, Real-Time Object Detection}},
url = {http://pjreddie.com/yolo/},
year = {2016}
}
@article{Domingues2020,
abstract = {Medical imaging is a rich source of invaluable information necessary for clinical judgements. However, the analysis of those exams is not a trivial assignment. In recent times, the use of deep learning (DL) techniques, supervised or unsupervised, has been empowered and it is one of the current research key areas in medical image analysis. This paper presents a survey of the use of DL architectures in computer-assisted imaging contexts, attending two different image modalities: the actively studied computed tomography and the under-studied positron emission tomography, as well as the combination of both modalities, which has been an important landmark in several decisions related to numerous diseases. In the making of this review, we analysed over 180 relevant studies, published between 2014 and 2019, that are sectioned by the purpose of the research and the imaging modality type. We conclude by addressing research issues and suggesting future directions for further improvement. To our best knowledge, there is no previous work making a review of this issue.},
author = {Domingues, In{\^{e}}s and Pereira, Gis{\`{e}}le and Martins, Pedro and Duarte, Hugo and Santos, Jo{\~{a}}o and Abreu, Pedro Henriques},
doi = {10.1007/s10462-019-09788-3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Domingues et al. - 2020 - Using deep learning techniques in medical imaging a systematic review of applications on CT and PET.pdf:pdf},
issn = {15737462},
journal = {Artificial Intelligence Review},
keywords = {Computed tomography,Deep learning,Medical imaging,Positron emission tomography},
month = {aug},
number = {6},
pages = {4093--4160},
publisher = {Springer},
title = {{Using deep learning techniques in medical imaging: a systematic review of applications on CT and PET}},
url = {https://doi.org/10.1007/s10462-019-09788-3},
volume = {53},
year = {2020}
}
@article{Xu2019,
abstract = {Organ localization is an essential preprocessing step for many medical image analysis tasks, such as image registration, organ segmentation, and lesion detection. In this paper, we propose an efficient method for multiple organ localization in CT image using a 3D region proposal network. Compared with other convolutional neural network-based methods that successively detect the target organs in all slices to assemble the final 3D bounding box, our method is fully implemented in a 3D manner, and thus, it can take full advantages of the spatial context information in CT image to perform efficient organ localization with only one prediction. We also propose a novel backbone network architecture that generates high-resolution feature maps to further improve the localization performance on small organs. We evaluate our method on two clinical datasets, where 11 body organs and 12 head organs (or anatomical structures) are included. As our results shown, the proposed method achieves higher detection precision and localization accuracy than the current state-of-the-art methods with approximate 4 to 18 times faster processing speed. Additionally, we have established a public dataset dedicated for organ localization on http://dx.doi.org/10.21227/df8g-pq27. The full implementation of the proposed method has also been made publicly available on https://github.com/superxuang/caffe-3d-faster-rcnn.},
author = {Xu, Xuanang and Zhou, Fugen and Liu, Bo and Fu, Dongshan and Bai, Xiangzhi},
doi = {10.1109/TMI.2019.2894854},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {CT image,Organ localization,convolutional neural network,region proposal network},
month = {aug},
number = {8},
pages = {1885--1898},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Efficient Multiple Organ Localization in CT Image Using 3D Region Proposal Network}},
volume = {38},
year = {2019}
}
@article{Allanore2015,
abstract = {Systemic sclerosis is a complex autoimmune disease characterized by a chronic and frequently progressive course and by extensive patient-to-patient variability. Like other autoimmune diseases, systemic sclerosis occurs more frequently in women, with a peak of onset in the fifth decade of life. The exact cause of systemic sclerosis remains elusive but is likely to involve environmental factors in a genetically primed individual. Pathogenesis is dominated by vascular changes; evidence of autoimmunity with distinct autoantibodies and activation of both innate and adaptive immunity; and fibrosis of the skin and visceral organs that results in irreversible scarring and organ failure. Intractable progression of vascular and fibrotic organ damage accounts for the chronic morbidity and high mortality. Early and accurate diagnosis and classification might improve patient outcomes. Screening strategies facilitate timely recognition of life-threatening complications and initiation of targeted therapies to halt their progression. Effective treatments of organ-based complications are now within reach. Discovery of biomarkers - including autoantibodies that identify patient subsets at high risk for particular disease complications or rapid progression - is a research priority. Understanding the key pathogenetic pathways, cell types and mediators underlying disease manifestations opens the door for the development of targeted therapies with true disease-modifying potential. For an illustrated summary of this Primer, visit: http://go.nature.com/lchkcA.},
author = {Allanore, Yannick and Simms, Robert and Distler, Oliver and Trojanowska, Maria and Pope, Janet and Denton, Christopher P. and Varga, John},
doi = {10.1038/nrdp.2015.2},
issn = {2056676X},
journal = {Nature Reviews Disease Primers},
keywords = {Autoimmune diseases,Raynaud phenomenon,Systemic sclerosis},
month = {apr},
number = {1},
pages = {1--21},
pmid = {27189141},
publisher = {Nature Publishing Group},
title = {{Systemic sclerosis}},
url = {https://www.nature.com/articles/nrdp20152},
volume = {1},
year = {2015}
}
@misc{Denton2017,
abstract = {Systemic sclerosis, also called scleroderma, is an immune-mediated rheumatic disease that is characterised by fibrosis of the skin and internal organs and vasculopathy. Although systemic sclerosis is uncommon, it has a high morbidity and mortality. Improved understanding of systemic sclerosis has allowed better management of the disease, including improved classification and more systematic assessment and follow-up. Additionally, treatments for specific complications have emerged and a growing evidence base supports the use of immune suppression for the treatment of skin and lung fibrosis. Some manifestations of the disease, such as scleroderma renal crisis, pulmonary arterial hypertension, digital ulceration, and gastro-oesophageal reflux, are now treatable. However, the burden of non-lethal complications associated with systemic sclerosis is substantial and is likely to become more of a challenge. Here, we review the clinical features of systemic sclerosis and describe the best practice approaches for its management. Furthermore, we identify future areas for development.},
author = {Denton, Christopher P. and Khanna, Dinesh},
booktitle = {The Lancet},
doi = {10.1016/S0140-6736(17)30933-9},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Denton, Khanna - 2017 - Systemic sclerosis.pdf:pdf},
issn = {1474547X},
month = {oct},
number = {10103},
pages = {1685--1699},
pmid = {28413064},
publisher = {Lancet Publishing Group},
title = {{Systemic sclerosis}},
volume = {390},
year = {2017}
}
@article{Giavarina2015,
abstract = {In a contemporary clinical laboratory it is very common to have to assess the agreement between two quantitative methods of measurement. The correct statistical approach to assess this degree of agreement is not obvious. Correlation and regression studies are frequently proposed. However, correlation studies the relationship between one variable and another, not the differences, and it is not recommended as a method for assessing the comparability between methods. In 1983 Altman and Bland (B&A) proposed an alternative analysis, based on the quantification of the agreement between two quantitative measurements by studying the mean difference and constructing limits of agreement. The B&A plot analysis is a simple way to evaluate a bias between the mean differences, and to estimate an agreement interval, within which 95% of the differences of the second method, compared to the first one, fall. Data can be analyzed both as unit differences plot and as percentage differences plot. The B&A plot method only defines the intervals of agreements, it does not say whether those limits are acceptable or not. Acceptable limits must be defined a priori, based on clinical necessity, biological considerations or other goals. The aim of this article is to provide guidance on the use and interpretation of Bland Altman analysis in method comparison studies.},
author = {Giavarina, Davide},
doi = {10.11613/BM.2015.015},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Giavarina - 2015 - Understanding Bland Altman analysis Lessons in biostatistics.pdf:pdf},
journal = {Biochemia Medica},
keywords = {Bland-Altman,agreement analysis,correlation of data,laboratory research,method comparison},
number = {2},
pages = {141--51},
title = {{Understanding Bland Altman analysis Lessons in biostatistics}},
url = {http://dx.doi.org/10.11613/BM.2015.015},
volume = {25},
year = {2015}
}

@techreport{Chris,
author = {Chris, {\textcopyright} and Reviewer, Knox and Marshall, Ellen},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chris, Reviewer, Marshall - Unknown - community project encouraging academics to share statistics support resources All stcp resources a.pdf:pdf},
title = {{community project encouraging academics to share statistics support resources All stcp resources are released under a Creative Commons licence}}
}
@article{Acharya2013b,
abstract = {Systemic sclerosis (SSc) is a multisystem autoimmune connective tissue disease of unknown etiology. Pulmonary involvement is known to occur in SSc in form of progressive fibrosis and alveolitis. Pulmonary hypertension is another spectrum of involvement. We present a case of limited cutaneous scleroderma who presented with progressive dysnea and was diagnosed to have Interstitial lung disease (ILD).},
author = {Acharya, Sourya and Shukla, Samarth and Mahajan, S. N. and Banode, Pankaj and Mahure, Chetan and Mathew, Leny},
doi = {10.1164/rccm.200706-877oc},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Acharya et al. - 2013 - Interstitial lung disease in systemic sclerosis.pdf:pdf},
issn = {09743901},
journal = {Journal of Datta Meghe Institute of Medical Sciences University},
keywords = {Alveolitis,Fibrosis,ILD,Systemic sclerosis},
month = {dec},
number = {1},
pages = {57--59},
publisher = {American Thoracic Society},
title = {{Interstitial lung disease in systemic sclerosis}},
url = {www.atsjournals.org},
volume = {8},
year = {2013}
}
@article{Dabiri2020,
abstract = {Computed Tomography (CT) imaging is widely used for studying body composition, i.e., the proportion of muscle and fat tissues with applications in areas such as nutrition or chemotherapy dose design. In particular, axial CT slices from the 3rd lumbar (L3) vertebral location are commonly used for body composition analysis. However, selection of the third lumbar vertebral slice and the segmentation of muscle/fat in the slice is a tedious operation if performed manually. The objective of this study is to automatically find the middle axial slice at L3 level from a full or partial body CT scan volume and segment the skeletal muscle (SM), subcutaneous adipose tissue (SAT), visceral adipose tissue (VAT) and intermuscular adipose tissue (IMAT) on that slice. The proposed algorithm includes an L3 axial slice localization network followed by a muscle-fat segmentation network. The localization network is a fully convolutional classifier trained on more than 12,000 images. The segmentation network is a convolutional neural network with an encoderâdecoder architecture. Three datasets with CT images taken for patients with different types of cancers are used for training and validation of the networks. The mean slice error of 0.87Â±2.54 was achieved for L3 slice localization on 1748 CT scan volumes. The performance of five class tissue segmentation network evaluated on two datasets with 1327 and 1202 test samples. The mean Jaccard score of 97% was achieved for SM and VAT tissue segmentation on 1327 images. The mean Jaccard scores of 98% and 83% are corresponding to SAT and IMAT tissue segmentation on the same dataset. The localization and segmentation network performance indicates the potential for fully automated body composition analysis with high accuracy.},
author = {Dabiri, Setareh and Popuri, Karteek and Ma, Cydney and Chow, Vincent and Feliciano, Elizabeth M.Cespedes and Caan, Bette J. and Baracos, Vickie E. and Beg, Mirza Faisal},
doi = {10.1016/j.compmedimag.2020.101776},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dabiri et al. - 2020 - Deep learning method for localization and segmentation of abdominal CT.pdf:pdf},
issn = {18790771},
journal = {Computerized Medical Imaging and Graphics},
keywords = {CT scan,Convolutional neural network,Fat segmentation,Muscle segmentation,Third lumbar vertebra},
month = {oct},
pages = {101776},
pmid = {32862015},
publisher = {Elsevier Ltd},
title = {{Deep learning method for localization and segmentation of abdominal CT}},
volume = {85},
year = {2020}
}
@techreport{Kanavati2019,
abstract = {1 Abstract Objective To demonstrate the effectiveness of using a deep learning-based approach for a fully automated slice-based measurement of muscle mass for assessing sarcopenia on CT scans of the abdomen without any case exclusion criteria. Materials and Methods This retrospective study was conducted using a collection of public and privately available CT images (n = 1070). The method consisted of two stages: slice detection from a CT volume and single-slice CT segmentation. Both stages used Fully Convolutional Neural Networks (FCNN) and were based on a UNet-like architecture. Input data consisted of CT volumes with a variety of fields of view. The output consisted of a segmented muscle mass on a CT slice at the level of L3 vertebra. The muscle mass is segmented into erector spinae, psoas, and rectus abdominus muscle groups. The output was tested against manual ground-truth segmentation by an expert annotator. Results 3-fold cross validation was used to evaluate the proposed method. The slice detection cross validation error was 1.41Â±5.02 (in slices). The segmentation cross validation Dice overlaps were 0.97Â±0.02, 0.95Â±0.04, 0.94Â±0.04 for erector spinae, psoas, and rectus abdominus, respectively, and 0.96Â±0.02 for the combined muscle mass. Conclusion A deep learning approach to detect CT slices and segment muscle mass to perform slice-based analysis of sarcopenia is an effective and promising approach. The use of FCNN to accurately and efficiently detect a slice in CT volumes with a variety of fields of view, occlusions, and slice thicknesses was demonstrated. 2 Summary Automated slice detection and muscle mass segmentation from CT data is efficient and feasible using deep learning. 3 Key Points â¢ For slice detection, 3-fold cross validation mean slice error was 1.41Â±5.02 (median 0.50). The inter-radiologist error was 1.94Â±2.36 (median 0.80). â¢ For muscle segmentation, 3-fold cross validation Dice scores were 0.97Â±0.02, 0.95Â±0.04, 0.94Â±0.04 for erector spinae, psoas, and rectus abdominus, respectively, and 0.96Â±0.02 for the combined muscle mass.},
archivePrefix = {arXiv},
arxivId = {2006.06432v1},
author = {Kanavati, Fahdi and Islam, Shah and Arain, Zohaib and Aboagye, Eric O and Rockall, Andrea},
eprint = {2006.06432v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kanavati et al. - 2019 - Fully-automated deep learning slice-based muscle estimation from CT images for sarcopenia assessment.pdf:pdf},
title = {{Fully-automated deep learning slice-based muscle estimation from CT images for sarcopenia assessment}},
year = {2019}
}
@article{YU2019,
author = {YU, TAI-FENG and LIU, PAUL and PENG, YU-LAN and LIU, JING-YAN and YIN, HAO and LIU, DONG C.},
doi = {10.12783/dtetr/icicr2019/30578},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/YU et al. - 2019 - Slice Localization for Three-Dimensional Breast Ultrasound Volume Using Deep Learning.pdf:pdf},
isbn = {9781605956336},
journal = {DEStech Transactions on Engineering and Technology Research},
keywords = {automated breast ultrasound system,fully connected,localization,robotic arms},
number = {icicr},
pages = {251--257},
title = {{Slice Localization for Three-Dimensional Breast Ultrasound Volume Using Deep Learning}},
volume = {d},
year = {2019}
}
@inproceedings{Hatt2019,
abstract = {In this work, a convolutional neural network (CNN) based method for automated lung boundary estimation from computed tomography (CT) scans is presented and validated. The CNN model was trained to regress the locations of the superior and inferior borders of the lungs from multiple tissue-specific 2D projections of thoracic CT images. The model utilized a DenseNet architecture and was trained and evaluated on CT images from the COPDGene study. The median (95th percentile) localization error was 2.51 (11.18) for the inferior border and 1.52 (7.21) for the superior border of the lungs.},
author = {Hatt, Charles R. and Ram, Sundaresh and Galban, Craig J.},
booktitle = {2019 IEEE Data Science Workshop, DSW 2019 - Proceedings},
doi = {10.1109/DSW.2019.8755594},
isbn = {9781728107080},
keywords = {Chronic Obstructive Pulmonary Disease,Computed Tomography,Computer Vision,Convolutional Neural Network,Image Processing},
month = {jun},
pages = {213--216},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{A Convolutional Neural Network Approach to Automated Lung Bounding Box Estimation from Computed Tomography Scans}},
year = {2019}
}
@article{Wang2017,
abstract = {Accurately assessment of adipose tissue volume inside a human body plays an important role in predicting disease or cancer risk, diagnosis and prognosis. In order to overcome limitation of using only one subjectively selected CT image slice to estimate size of fat areas, this study aims to develop and test a computer-aided detection (CAD) scheme based on deep learning technique to automatically segment subcutaneous fat areas (SFA) and visceral fat areas (VFA) depicting on volumetric CT images. A retrospectively collected CT image dataset was divided into two independent training and testing groups. The proposed CAD framework consisted of two steps with two convolution neural networks (CNNs) namely, Selection-CNN and Segmentation-CNN. The first CNN was trained using 2,240 CT slices to select abdominal CT slices depicting SFA and VFA. The second CNN was trained with 84,000 pixel patches and applied to the selected CT slices to identify fat-related pixels and assign them into SFA and VFA classes. Comparing to the manual CT slice selection and fat pixel segmentation results, the accuracy of CT slice selection using the Selection-CNN yielded 95.8%, while the accuracy of fat pixel segmentation using the Segmentation-CNN was 96.8%. This study demonstrated the feasibility of applying a new deep learning based CAD scheme to automatically recognize abdominal section of human body from CT scans and segment SFA and VFA from volumetric CT data with high accuracy or agreement with the manual segmentation results.},
author = {Wang, Yunzhi and Qiu, Yuchen and Thai, Theresa and Moore, Kathleen and Liu, Hong and Zheng, Bin},
doi = {10.1016/j.cmpb.2017.03.017},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang et al. - 2017 - A two-step convolutional neural network based computer-aided detection scheme for automatically segmenting adipose.pdf:pdf},
issn = {18727565},
journal = {Computer Methods and Programs in Biomedicine},
keywords = {Computer-aided detection (CAD),Convolution neural network (CNN),Deep learning,Segmentation of adipose tissue,Subcutaneous fat area (SFA),Visceral fat area (VFA)},
month = {jun},
pages = {97--104},
pmid = {28495009},
publisher = {Elsevier Ireland Ltd},
title = {{A two-step convolutional neural network based computer-aided detection scheme for automatically segmenting adipose tissue volume depicting on CT images}},
volume = {144},
year = {2017}
}
@inproceedings{Bridge2018,
abstract = {The amounts of muscle and fat in a person's body, known as body composition, are correlated with cancer risks, cancer survival, and cardiovascular risk. The current gold standard for measuring body composition requires time-consuming manual segmentation of CT images by an expert reader. In this work, we describe a two-step process to fully automate the analysis of CT body composition using a DenseNet to select the CT slice and U-Net to perform segmentation. We train and test our methods on independent cohorts. Our results show Dice scores (0.95â0.98) and correlation coefficients (R = 0.99) that are favorable compared to human readers. These results suggest that fully automated body composition analysis is feasible, which could enable both clinical use and large-scale population studies.},
archivePrefix = {arXiv},
arxivId = {1808.03844},
author = {Bridge, Christopher P and Rosenthal, Michael and Wright, Bradley and Kotecha, Gopal and Fintelmann, Florian and Troschel, Fabian and Miskin, Nityanand and Desai, Khanant and Wrobel, William and Babic, Ana and Khalaf, Natalia and Brais, Lauren and Welch, Marisa and Zellers, Caitlin and Tenenholtz, Neil and Michalski, Mark and Wolpin, Brian and Andriole, Katherine},
booktitle = {OR 2.0 Context-aware operating theaters, computer assisted robotic endoscopy, clinical image-based procedures, and skin image analysis},
doi = {10.1007/978-3-030-01201-4_22},
eprint = {1808.03844},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Bridge et al. - Unknown - Fully-Automated Analysis of Body Composition from CT in Cancer Patients Using Convolutional Neural Networks.pdf:pdf},
isbn = {9783030012007},
issn = {16113349},
pages = {204--213},
publisher = {Springer, Cham},
title = {{Fully-automated analysis of body composition from CT in cancer patients using convolutional neural networks}},
volume = {11041 LNCS},
year = {2018}
}
@article{Belharbi2017,
abstract = {In this article, we present a complete automated system for spotting a particular slice in a complete 3D Computed Tomography exam (CT scan). Our approach does not require any assumptions on which part of the patient's body is covered by the scan. It relies on an original machine learning regression approach. Our models are learned using the transfer learning trick by exploiting deep architectures that have been pre-trained on imageNet database, and therefore it requires very little annotation for its training. The whole pipeline consists of three steps: i) conversion of the CT scans into Maximum Intensity Projection (MIP) images, ii) prediction from a Convolutional Neural Network (CNN) applied in a sliding window fashion over the MIP image, and iii) robust analysis of the prediction sequence to predict the height of the desired slice within the whole CT scan. Our approach is applied to the detection of the third lumbar vertebra (L3) slice that has been found to be representative to the whole body composition. Our system is evaluated on a database collected in our clinical center, containing 642 CT scans from different patients. We obtained an average localization error of 1.91Â±2.69 slices (less than 5 mm) in an average time of less than 2.5 s/CT scan, allowing integration of the proposed system into daily clinical routines.},
author = {Belharbi, Soufiane and Chatelain, Cl{\'{e}}ment and H{\'{e}}rault, Romain and Adam, S{\'{e}}bastien and Thureau, S{\'{e}}bastien and Chastan, Mathieu and Modzelewski, Romain},
doi = {10.1016/j.compbiomed.2017.05.018},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Belharbi et al. - 2017 - Spotting L3 slice in CT scans using deep convolutional network and transfer learning.pdf:pdf},
issn = {18790534},
journal = {Computers in Biology and Medicine},
keywords = {Convolutional neural networks,Deep learning,Maximum intensity projection,Sarcopenia,Slice detection},
month = {aug},
pages = {95--103},
pmid = {28558319},
publisher = {Elsevier Ltd},
title = {{Spotting L3 slice in CT scans using deep convolutional network and transfer learning}},
volume = {87},
year = {2017}
}
@article{Lo2012,
abstract = {This paper describes a framework for establishing a reference airway tree segmentation, which was used to quantitatively evaluate 15 different airway tree extraction algorithms in a standardized manner. Because of the sheer difficulty involved in manually constructing a complete reference standard from scratch, we propose to construct the reference using results from all algorithms that are to be evaluated. We start by subdividing each segmented airway tree into its individual branch segments. Each branch segment is then visually scored by trained observers to determine whether or not it is a correctly segmented part of the airway tree. Finally, the reference airway trees are constructed by taking the union of all correctly extracted branch segments. Fifteen airway tree extraction algorithms from different research groups are evaluated on a diverse set of 20 chest computed tomography (CT) scans of subjects ranging from healthy volunteers to patients with severe pathologies, scanned at different sites, with different CT scanner brands, models, and scanning protocols. Three performance measures covering different aspects of segmentation quality were computed for all participating algorithms. Results from the evaluation showed that no single algorithm could extract more than an average of 74% of the total length of all branches in the reference standard, indicating substantial differences between the algorithms. A fusion scheme that obtained superior results is presented, demonstrating that there is complementary information provided by the different algorithms and there is still room for further improvements in airway segmentation algorithms. {\textcopyright} 1982-2012 IEEE.},
author = {Lo, Pechin and {Van Ginneken}, Bram and Reinhardt, Joseph M. and Yavarna, Tarunashree and {De Jong}, Pim A. and Irving, Benjamin and Fetita, Catalin and Ortner, Margarete and Pinho, R{\^{o}}mulo and Sijbers, Jan and Feuerstein, Marco and Fabijanska, Anna and Bauer, Christian and Beichel, Reinhard and Mendoza, Carlos S. and Wiemker, Rafael and Lee, Jaesung and Reeves, Anthony P. and Born, Silvia and Weinheimer, Oliver and {Van Rikxoort}, Eva M. and Tschirren, Juerg and Mori, Ken and Odry, Benjamin and Naidich, David P. and Hartmann, Ieneke and Hoffman, Eric A. and Prokop, Mathias and Pedersen, Jesper H. and {De Bruijne}, Marleen},
doi = {10.1109/TMI.2012.2209674},
file = {:E\:/jjia/papers/vessel AV/Lo_TMI12.pdf:pdf},
issn = {02780062},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Computed tomography,evaluation,pulmonary airways,segmentation},
number = {11},
pages = {2093--2107},
pmid = {22855226},
title = {{Extraction of airways from CT (EXACT'09)}},
volume = {31},
year = {2012}
}
@article{Ross2012,
annote = {method: based on scale-space particles. Biomakers(proxi- mal vasculature dilates to compensate for the increase in resistance. This).

evaluation: phantom and real case.},
author = {Ross, James C and Krissian, Karl and Washko, George R and Kindlmann, Gordon L and Schultz, Thomas},
file = {:E\:/jjia/papers/vessel AV/estepar2012.pdf:pdf},
isbn = {9781457718588},
journal = {Methods},
pages = {1479--1482},
title = {{COMPUTATIONAL VASCULAR MORPHOMETRY FOR THE ASSESSMENT OF PULMONARY VASCULAR DISEASE BASED ON SCALE-SPACE PARTICLES ul San Jos Â´ e Est Â´ Brigham and Women ' s Hospital , Boston , MA University of Las Palmas de Gran Canaria , Spain University of Chicago , C}},
year = {2012}
}
@article{Guo2020,
abstract = {The accurate modeling of the liver vessel network structure is an important prerequisite for developing a preoperative plan for the liver. Considering that extracting liver blood vessels from patient's abdominal computed tomography(CT) images requires several manual operations, this study proposed an automatic segmentation method of liver vessels based on graph cut, thinning, and vascular combination, which can obtain a complete liver vascular network. First, the CT image was preprocessed by grayscale mapping based on sigmoid function, vessel enhancement based on Hessian filter, and denoising based on anisotropic filter to enhance the grayscale contrast between the vascular and non-vascular parts of the liver. Then, the liver vessels were initially segmented based on the improved three-dimensional graph cut algorithm. Based on the obtained liver vascular structure, the vessel centerline of the liver was then extracted by the proposed thinning algorithm that continuously traversed the foreground voxel points and iteratively deleted the simple points. Finally, the combination of vascular centerline optimization was used to predict and link the vascular centerline fractured portion. The under-segmented liver vessels were complemented based on the complete vascular centerline tree. To verify the proposed hepatic vascular segmentation and complementation algorithm, the open 3D Image Reconstruction for Comparison of Algorithm Database (3Dircadb) was applied to test and quantify the results. The results showed that the proposed algorithm can accurately and effectively segment the vascular network structure from abdominal CT images, and the proposed vascular complementation method can restore the true information of under-segmented liver vessels. [Figure not available: see fulltext.].},
author = {Guo, Xiaoyu and Xiao, Ruoxiu and Zhang, Tao and Chen, Cheng and Wang, Jiayu and Wang, Zhiliang},
doi = {10.1007/s11517-020-02128-6},
file = {:E\:/jjia/papers/vessel AV/Guo2020_Article_ANovelMethodToModelHepaticVasc.pdf:pdf},
issn = {17410444},
journal = {Medical and Biological Engineering and Computing},
keywords = {Centerline extraction,Graph cut,Vascular combination and optimization,Vascular complementation,Vessel segmentation},
number = {4},
pages = {709--724},
publisher = {Medical & Biological Engineering & Computing},
title = {{A novel method to model hepatic vascular network using vessel segmentation, thinning, and completion}},
volume = {58},
year = {2020}
}
@article{Shang2011,
abstract = {In this paper, a novel active contour model is proposed for vessel tree segmentation. First, we introduce a region competition-based active contour model exploiting the Gaussian mixture model, which mainly segments thick vessels. Second, we define a vascular vector field to evolve the active contour along its center line into the thin and weak vessels. The vector field is derived from the eigenanalysis of the Hessian matrix of the image intensity in a multiscale framework. Finally, a dual curvature strategy, which uses a vesselness measure-dependent function selecting between a minimal principal curvature and a mean curvature criterion, is added to smoothen the surface of the vessel without changing its shape. The developed model is used to extract the liver and lung vessel tree as well as the coronary artery from high-resolution volumetric computed tomography images. Comparisons are made with several classical active contour models and manual extraction. The experiments show that our model is more accurate and robust than these classical models and is, therefore, more suited for automatic vessel tree extraction. {\textcopyright} 2011 IEEE.},
author = {Shang, Yanfeng and Deklerck, Rudi and Nyssen, Edgard and Markova, Aneta and {De Mey}, Johan and Yang, Xin and Sun, Kun},
doi = {10.1109/TBME.2010.2097596},
file = {:E\:/jjia/papers/vessel AV/yanfengshang2011.pdf:pdf},
issn = {00189294},
journal = {IEEE Transactions on Biomedical Engineering},
keywords = {Active contour,Hessian matrix,level set,multiscale,segmentation,vessel},
number = {4},
pages = {1023--1032},
pmid = {21138795},
title = {{Vascular active contour for vessel tree segmentation}},
volume = {58},
year = {2011}
}
@book{Ravishankar2017,
abstract = {Segmentation of anatomy on abdominal CT enables patient-specific image guidance in clinical endoscopic procedures and in endoscopy training. Because robust interpatient registration of abdom-inal images is necessary for existing multi-atlas-and statistical-shape-model-based segmentations, but remains challenging, there is a need for automated multi-organ segmentation that does not rely on regis-tration. We present a deep-learning-based algorithm for segmenting the liver, pancreas, stomach, and esophagus using dilated convolution units with dense skip connections and a new spatial prior. The algorithm was evaluated with an 8-fold cross-validation and compared to a joint-label-fusion-based segmentation based on Dice scores and boundary distances. The proposed algorithm yielded more accurate segmentations than the joint-label-fusion-based algorithm for the pancreas (median Dice scores 66 vs 37), stomach (83 vs 72) and esophagus (73 vs 54) and marginally less accurate segmentation for the liver (92 vs 93). We conclude that dilated convolutional networks with dense skip connections can segment the liver, pancreas, stomach and esophagus from abdominal CT with-out image registration and have the potential to support image-guided navigation in gastrointestinal endoscopy procedures.},
archivePrefix = {arXiv},
arxivId = {1710.04783},
author = {Ravishankar, H and Venkataramani, R B and Thiruvenkadam, S and Sudhakar, P},
booktitle = {Miccai 2017},
doi = {10.1007/978-3-319-66182-7},
eprint = {1710.04783},
file = {:E\:/jjia/papers/vessel AV/2017_Book_MedicalImageComputingAndComput.pdf:pdf},
isbn = {9783319661827},
issn = {978-3-319-66181-0},
keywords = {lungs,machine learning,mri,multi-atlas segmentation,random forests},
number = {2},
pages = {203--211},
title = {{MICCAI 2017-2}},
volume = {10433},
year = {2017}
}
@article{VanDongen2010,
abstract = {A system for the automatic segmentation of the pulmonary vasculature in thoracic CT scans is presented. The method is based on a vesselness filter and includes a local thresholding procedure to accurately segment vessels of varying diameters. The output of an automatic segmentation of the airways is used to remove false positive detections in the airway walls. The algorithm is tested with a quantitative evaluation framework based on manual classification of well-dispersed local maxima and random points on ten axial sections in a scan. The algorithm has been applied to ten low dose CT scans annotated by two observers. Results show that local thresholding and airway wall removal both improve segmentation performance and that the accuracy of the proposed method approaches the interobserver variability. {\textcopyright} 2010 IEEE.},
author = {{Van Dongen}, Evelien and {Van Ginneken}, Bram},
doi = {10.1109/ISBI.2010.5490088},
file = {:E\:/jjia/papers/vessel AV/vandongen2010.pdf:pdf},
isbn = {9781424441266},
journal = {2010 7th IEEE International Symposium on Biomedical Imaging: From Nano to Macro, ISBI 2010 - Proceedings},
keywords = {Airway wall removal,Computed tomography,Optimal thresholding,Pulmonary image analysis,Vessel enhancement,Vessel segmentation},
pages = {668--671},
title = {{Automatic segmentation of pulmonary vasculature in thoracic CT scans with local thresholding and airway wall removal}},
year = {2010}
}

@article{Selle2002,
abstract = {For liver surgical planning, the structure and morphology of the hepatic vessels and their relationship to tumors are of major interest. To achieve a fast and robust assistance with optimal quantitative and visual information, we present methods for a geometrical and structural analysis of vessel systems. Starting from the raw image data a sequence of image processing steps has to be carried out until a three-dimensional representation of the relevant anatomic and pathologic structures is generated. Based on computed tomography (CT) scans, the following steps are performed. 1) The volume data is preprocessed and the vessels are segmented. 2) The skeleton of the vessels is determined and transformed into a graph enabling a geometrical and structural shape analysis. Using this information the different intrahepatic vessel systems are identified automatically. 3) Based on the structural analysis of the branches of the portal vein, their vascular territories are approximated with different methods. These methods are compared and validated anatomically by means of corrosion casts of human livers. 4) Vessels are visualized with graphics primitives fitted to the skeleton to provide smooth visualizations without aliasing artifacts. The image analysis techniques have been evaluated in the clinical environment and have been used in more than 170 cases so far to plan interventions and transplantations.},
author = {Selle, Dirk and Preim, Bernhard and Schenk, Andrea and Peitgen, Heinz Otto},
doi = {10.1109/TMI.2002.801166},
file = {:E\:/jjia/papers/vessel AV/TMI.2002.801166.pdf:pdf},
issn = {02780062},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Feature extraction,Image segmentation,Liver surgery,Vessel visualization},
number = {11},
pages = {1344--1357},
pmid = {12575871},
title = {{Analysis of vasculature for liver surgical planning}},
volume = {21},
year = {2002}
}
@inproceedings{Cui2019,
annote = {dataset: 300 CT scans with manual annotation.

method: 2.5D U-Net++

post-processing: connected parts with over 10 nodes.

Metrics: Dice, Precision, Recall.

Comparison: 2D, 3D.},
author = {Cui, Hejie and Liu, Xinglong and Huang, Ning},
booktitle = {MICCAI 2019},
doi = {10.1007/978-3-030-32226-7},
file = {:E\:/jjia/papers/vessel AV/Cui2019_Chapter_PulmonaryVesselSegmentationBas.pdf:pdf},
isbn = {9783030322267},
keywords = {2,2.5D CNN,5d cnn,Pulmonary vessel segmentation,U-Net++,pulmonary vessel segmentation,u-net},
pages = {293--300},
publisher = {Springer International Publishing},
title = {{Pulmonary Vessel Segmentation Based on Orthogonal Fused U-Net++ of Chest CT Images}},
url = {http://dx.doi.org/10.1007/978-3-030-32226-7_33},
volume = {1},
year = {2019}
}
@article{Gu2019,
abstract = {Purpose: The suppression of pulmonary vessels in chest computed tomography (CT) images can enhance the conspicuity of lung nodules, thereby improving the detection rate of early lung cancer. This study aimed to develop two key techniques in vessel suppression, that is, segmentation and removal of pulmonary vessels while preserving the nodules. Methods: Pulmonary vessel segmentation and removal methods in CT images were developed. The vessel segmentation method used a framework of two cascaded convolutional neural networks (CNNs). A bi-class segmentation network was utilized in the first step to extract high-intensity structures, including both vessels and nonvascular tissues such as nodules. A tri-class segmentation network was employed in the second step to distinguish the vessels from nonvascular tissues (mainly nodules) and the lung parenchyma. In the vessel removal method, the voxels in the segmented vessels were replaced with randomly selected voxels from the surrounding lung parenchyma. The dataset in this study comprised 50 three-dimensional (3D) low-dose chest CT images. The labels for vessel and nodule segmentation were annotated with a semi automatic approach. The two cascaded networks for pulmonary vessel segmentation were trained with CT images of 40 cases and tested with CT images of ten cases. Pulmonary vessels were removed from the ten testing scans based on the predicted segmentation results. In addition to qualitative evaluation to the effects of segmentation and removal, the segmentation results were quantitatively evaluated using Dice coefficient (DICE), Jaccard index (JAC), and volumetric similarity (VS) and the removal results were evaluated using contrast-to-noise ratio (CNR). Results: In the first step of vessel segmentation, the mean DICE, JAC, and VS for high-intensity tissues, including both vessels and nodules, were 0.943, 0.893, and 0.991, respectively. In the second step, all the nodules were separated from the vessels, and the mean DICE, JAC, and VS for the vessels were 0.941, 0.890, and 0.991, respectively. After vessel removal, the mean CNR for nodules was improved from 4.23 (6.26Â dB) to 6.95 (8.42Â dB). Conclusions: Quantitative and qualitative evaluations demonstrated that the proposed method achieved a high accuracy for pulmonary vessel segmentation and a good effect on pulmonary vessel suppression.},
author = {Gu, Xiaomeng and Wang, Jiyong and Zhao, Jun and Li, Qiang},
doi = {10.1002/mp.13648},
file = {:E\:/jjia/papers/vessel AV/gu2019.pdf:pdf},
issn = {00942405},
journal = {Medical Physics},
keywords = {CNN,low-dose CT,lung nodule,vessel segmentation,vessel suppression},
number = {8},
pages = {3603--3614},
pmid = {31240721},
title = {{Segmentation and suppression of pulmonary vessels in low-dose chest CT scans}},
volume = {46},
year = {2019}
}
@book{Martel2020a,
author = {Martel, Anne L and Abolmaesumi, Purang and Stoyanov, Danail and Mateus, Diana and Zuluaga, Maria A and Zhou, S Kevin and Racoceanu, Daniel and Joskowicz, Leo and Goos, Gerhard},
doi = {10.1007/978-3-030-00928-1},
file = {:E\:/jjia/papers/vessel AV/2018_Book_MedicalImageComputingAndComput.pdf:pdf},
isbn = {9783030597092},
title = {{MICCAI 2018}},
year = {2020}
}
@book{Maier-hein2017,
author = {Maier-hein, Maxime Descoteaux Lena and Franz, Alfred and Jannin, Pierre and Collins, D Louis and Duchesne, Simon and Hutchison, David},
doi = {10.1007/978-3-319-66185-8},
file = {:E\:/jjia/papers/vessel AV/2017_Book_MedicalImageComputingAndComput_1.pdf:pdf},
isbn = {9783319661810},
title = {{MICCAI 2017-1}},
year = {2017}
}
@book{Wang2019a,
abstract = {The past few years have witnessed the great success of applying deep neural networks (DNNs) in computer-aided diagnosis. However, little attention has been paid to provide pathological evidence in the existing DNNs for medical diagnosis. In fact, feature visualization in DNNs is able to help understanding how the computer make decisions, and thus it shows promise on finding pathological evidence from computer-aided diagnosis. In this paper, we propose a novel pathology-aware visualization approach for DNN-based glaucoma classification, which is used to locate the pathological evidence from fundus images for glaucoma. Besides, we apply the visualization framework to the glaucoma images synthesis task, through which specific pathological areas of synthesized images can be enhanced. Finally, experimental results show that the visualization heat maps can pinpoint different glaucoma pathologies with high accuracy, and that the generated glaucoma images are more pathophysiologically clear in rim loss (RL) and retinal neural fiber layer damage (RNFLD), which is verified by the ophthalmologist.},
author = {Wang, Xiaofei and Xu, Mai and Li, Liu and Wang, Zulin and Guan, Zhenyu},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-32239-7_47},
file = {:E\:/jjia/papers/vessel AV/2019_Book_MedicalImageComputingAndComput (1).pdf:pdf},
isbn = {9783030322380},
issn = {16113349},
keywords = {Deep neural networks,Glaucoma,Image synthesis,Visualization},
pages = {423--431},
title = {{MICCAI 2019}},
volume = {11764 LNCS},
year = {2019}
}
@book{Jia2020,
abstract = {Brain glioma segmentation using multi-parametric magnetic resonance (MR) imaging has significant clinical value. Although 3D convolutional neural networks (CNNs) have become increasingly prevalent in delivering this segmentation task, these models still suffer from an insufficient ability to high-resolution feature representation for small and irregular regions, limited local receptive fields, and poor long-range dependencies. In this paper, we propose a 3D High-resolution and Non-local Feature Network (HNF-Net) for brain glioma segmentation using multi-parametric MR imaging. We construct HNF-Net based mainly on the parallel multi-scale fusion (PMF) module, which helps produce strong high-resolution feature representation and aggregate multi-scale contextual information. We also introduce the expectation-maximization attention (EMA) module to HNF-Net, aiming to capture the long-range dependent contextual information and reduce the feature redundancy in a lightweight fashion. We evaluated our HNF-Net on the BraTS 2019 Challenge dataset against eight top-ranking methods listed on the challenge leaderboard. Our results suggest that the proposed HNF-Net achieves improved overall performance over these methods, and our ablation study demonstrates the effectiveness of the PMF module and EMA module.},
author = {Jia, Haozhe and Xia, Yong and Cai, Weidong and Huang, Heng},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-59719-1_47},
file = {:E\:/jjia/papers/vessel AV/2020_Book_MedicalImageComputingAndComput.pdf:pdf},
isbn = {9783030597184},
issn = {16113349},
keywords = {Brain glioma segmentation,High-resolution feature representation,Lightweight non-local module},
pages = {480--490},
title = {{MICCAI 2020}},
volume = {12264 LNCS},
year = {2020}
}
@article{Rudyanto2014,
abstract = {The VESSEL12 (VESsel SEgmentation in the Lung) challenge objectively compares the performance of different algorithms to identify vessels in thoracic computed tomography (CT) scans. Vessel segmentation is fundamental in computer aided processing of data generated by 3D imaging modalities. As manual vessel segmentation is prohibitively time consuming, any real world application requires some form of automation. Several approaches exist for automated vessel segmentation, but judging their relative merits is difficult due to a lack of standardized evaluation. We present an annotated reference dataset containing 20 CT scans and propose nine categories to perform a comprehensive evaluation of vessel segmentation algorithms from both academia and industry. Twenty algorithms participated in the VESSEL12 challenge, held at International Symposium on Biomedical Imaging (ISBI) 2012. All results have been published at the VESSEL12 website http://vessel12.grand-challenge.org. The challenge remains ongoing and open to new participants. Our three contributions are: (1) an annotated reference dataset available online for evaluation of new algorithms; (2) a quantitative scoring system for objective comparison of algorithms; and (3) performance analysis of the strengths and weaknesses of the various vessel segmentation methods in the presence of various lung diseases. {\textcopyright} 2014 .},
author = {Rudyanto, Rina D. and Kerkstra, Sjoerd and van Rikxoort, Eva M. and Fetita, Catalin and Brillet, Pierre Yves and Lefevre, Christophe and Xue, Wenzhe and Zhu, Xiangjun and Liang, Jianming and lkay {\"{O}}ks{\"{u}}z, I. and {\"{U}}nay, Devrim and KadipaÅaoÇ§lu, Kamuran and Est{\'{e}}par, Ra{\'{u}}l San Jos{\'{e}} and Ross, James C. and Washko, George R. and Prieto, Juan Carlos and Hoyos, Marcela Hern{\'{a}}ndez and Orkisz, Maciej and Meine, Hans and H{\"{u}}llebrand, Markus and St{\"{o}}cker, Christina and Mir, Fernando Lopez and Naranjo, Valery and Villanueva, Eliseo and Staring, Marius and Xiao, Changyan and Stoel, Berend C. and Fabijanska, Anna and Smistad, Erik and Elster, Anne C. and Lindseth, Frank and Foruzan, Amir Hossein and Kiros, Ryan and Popuri, Karteek and Cobzas, Dana and Jimenez-Carretero, Daniel and Santos, Andres and Ledesma-Carbayo, Maria J. and Helmberger, Michael and Urschler, Martin and Pienn, Michael and Bosboom, Dennis G.H. and Campo, Arantza and Prokop, Mathias and de Jong, Pim A. and Ortiz-de-Solorzano, Carlos and Mu{\~{n}}oz-Barrutia, Arrate and van Ginneken, Bram},
doi = {10.1016/j.media.2014.07.003},
file = {:E\:/jjia/papers/vessel AV/1-s2.0-S136184151400111X-main.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Algorithm comparison,Lung vessels,Thoracic computed tomography},
number = {7},
pages = {1217--1232},
pmid = {25113321},
title = {{Comparing algorithms for automated vessel segmentation in computed tomography scans of the lung: The VESSEL12 study}},
volume = {18},
year = {2014}
}
@article{Jia2021,
author = {Jia, Jingnan and Zhai, Zhiwei and Bakker, M Els and Gir{\'{o}}n, I Hern{\'{a}}ndez and Staring, Marius and Stoel, Berend C and Box, P O},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Jia et al. - Unknown - MULTI-TASK SEMI-SUPERVISED LEARNING FOR PULMONARY LOBE SEGMENTATION Division of Image Processing , Department of.pdf:pdf},
isbn = {9781665412469},
pages = {3--6},
title = {{MULTI-TASK SEMI-SUPERVISED LEARNING FOR PULMONARY LOBE SEGMENTATION Division of Image Processing , Department of Radiology , Leiden University Medical Center ( LUMC ),}},
year = {2021}
}
@article{Nardelli2017,
author = {Nardelli, P},
file = {:E\:/jjia/papers/vessel AV/ISBI_2017.pdf:pdf},
isbn = {9781509011728},
pages = {384--387},
title = {{DEEP-LEARNING STRATEGY FOR PULMONARY ARTERY-VEIN CLASSIFICATION OF NON-CONTRAST CT IMAGES M . J . Ledesma-Carbayo , Farbod N . Rahaghi , R . San Jos Â´ e Est Â´ epar Applied Chest Imaging Laboratory , Brigham and Women ' s Hospital , Boston , MA , USA Biome}},
year = {2017}
}
@article{Payer2016,
abstract = {Automated computer-aided analysis of lung vessels has shown to yield promising results for non-invasive diagnosis of lung diseases. To detect vascular changes which affect pulmonary arteries and veins differently, both compartments need to be identified. We present a novel, fully automatic method that separates arteries and veins in thoracic computed tomography images, by combining local as well as global properties of pulmonary vessels. We split the problem into two parts: the extraction of multiple distinct vessel subtrees, and their subsequent labeling into arteries and veins. Subtree extraction is performed with an integer program (IP), based on local vessel geometry. As naively solving this IP is time-consuming, we show how to drastically reduce computational effort by reformulating it as a Markov Random Field. Afterwards, each subtree is labeled as either arterial or venous by a second IP, using two anatomical properties of pulmonary vessels: the uniform distribution of arteries and veins, and the parallel configuration and close proximity of arteries and bronchi. We evaluate algorithm performance by comparing the results with 25 voxel-based manual reference segmentations. On this dataset, we show good performance of the subtree extraction, consisting of very few non-vascular structures (median value: 0.9%) and merged subtrees (median value: 0.6%). The resulting separation of arteries and veins achieves a median voxel-based overlap of 96.3% with the manual reference segmentations, outperforming a state-of-the-art interactive method. In conclusion, our novel approach provides an opportunity to become an integral part of computer aided pulmonary diagnosis, where artery/vein separation is important.},
author = {Payer, Christian and Pienn, Michael and B{\'{a}}lint, Zolt{\'{a}}n and Shekhovtsov, Alexander and Talakic, Emina and Nagy, Eszter and Olschewski, Andrea and Olschewski, Horst and Urschler, Martin},
doi = {10.1016/j.media.2016.05.002},
file = {:E\:/jjia/papers/vessel AV/payer2016.pdf:pdf},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Artery-vein separation,Computed tomography,Integer program,Lung,Vascular tree reconstruction},
pages = {109--122},
pmid = {27189777},
publisher = {Elsevier B.V.},
title = {{Automated integer programming based separation of arteries and veins from thoracic CT images}},
url = {http://dx.doi.org/10.1016/j.media.2016.05.002},
volume = {34},
year = {2016}
}
@article{Charbonnier2016,
abstract = {We present a method for automatic separation and classification of pulmonary arteries and veins in computed tomography. Our method takes advantage of local information to separate segmented vessels, and global information to perform the artery-vein classification. Given a vessel segmentation, a geometric graph is constructed that represents both the topology and the spatial distribution of the vessels. All nodes in the geometric graph where arteries and veins are potentially merged are identified based on graph pruning and individual branching patterns. At the identified nodes, the graph is split into subgraphs that each contain only arteries or veins. Based on the anatomical information that arteries and veins approach a common alveolar sag, an arterial subgraph is expected to be intertwined with a venous subgraph in the periphery of the lung. This relationship is quantified using periphery matching and is used to group subgraphs of the same artery-vein class. Artery-vein classification is performed on these grouped subgraphs based on the volumetric difference between arteries and veins. A quantitative evaluation was performed on 55 publicly available non-contrast CT scans. In all scans, two observers manually annotated randomly selected vessels as artery or vein. Our method was able to separate and classify arteries and veins with a median accuracy of 89%, closely approximating the inter-observer agreement. All CT scans used in this study, including all results of our system and all manual annotations, are publicly available at 'http://arteryvein.grand-challenge.org'.},
annote = {AV clf challenges: 1. seg results 2. AV touh each other 3. bifurcation trifurcation.

Literature review: [3-5] require manual interactions. [7] is automatically but rely on visible airways.

lack an extensive evaluation!

Vessel seg is from a paper in 2010.},
author = {Charbonnier, Jean Paul and Brink, Monique and Ciompi, Francesco and Scholten, Ernst T. and Schaefer-Prokop, Cornelia M. and {Van Rikxoort}, Eva M.},
doi = {10.1109/TMI.2015.2500279},
file = {:E\:/jjia/papers/vessel AV/charbonnier2016.pdf:pdf},
issn = {1558254X},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Artery-vein separation,automatic classification,chest computed tomography,pulmonary vessels},
number = {3},
pages = {882--892},
pmid = {26584489},
title = {{Automatic Pulmonary Artery-Vein Separation and Classification in Computed Tomography Using Tree Partitioning and Peripheral Vessel Matching}},
volume = {35},
year = {2016}
}
@article{Kitamura,
annote = {Method: CRF
1. Root detection
2. Vessel segmentation using graph-cut
3. AV classification

dataset: CTA,

validation datasets: 10 chest CTA, gdth from manully annotation which only apply to HU>-200.},
author = {Kitamura, Yoshiro and Li, Yuanzhong and Ito, Wataru and Ishikawa, Hiroshi},
file = {:E\:/jjia/papers/vessel AV/PIA2013.pdf:pdf},
keywords = {artery-vein segmentation,graph cuts,higher-order function},
pages = {53--61},
title = {{Pulmonary Artery-Vein Segmentation}}
}
@article{Nakamura2005,
annote = {Method: Distance to bronch, distance to interlobarèºå°å¶.

vessel segmentation results are from region growing.

Test data: 3 cased verified by experts.

Accuracy: 0.8-0.95},
author = {Nakamura, S. and Mekada, Y. and Ide, I. and Murase, H. and Hasegawa, J. and Toriwaki, J. and Otsuji, H.},
doi = {10.1016/j.ics.2005.03.098},
file = {:E\:/jjia/papers/vessel AV/E06-conference-mekada-1.pdf:pdf},
issn = {05315131},
journal = {International Congress Series},
keywords = {chest,pulmonary artery,pulmonary vein},
pages = {1403},
title = {{Pulmonary artery and vein classification method using spatial arrangement features from X-ray CT image}},
volume = {1281},
year = {2005}
}

@article{Bergstra2011,
abstract = {Several recent advances to the state of the art in image classification benchmarks have come from better configurations of existing techniques rather than novel approaches to feature learning. Traditionally, hyper-parameter optimization has been the job of humans because they can be very efficient in regimes where only a few trials are possible. Presently, computer clusters and GPU processors make it possible to run more trials and we show that algorithmic approaches can find better results. We present hyper-parameter optimization results on tasks of training neural networks and deep belief networks (DBNs). We optimize hyper-parameters using random search and two new greedy sequential methods based on the expected improvement criterion. Random search has been shown to be sufficiently efficient for learning neural networks for several datasets, but we show it is unreliable for training DBNs. The sequential algorithms are applied to the most difficult DBN learning problems from [1] and find significantly better results than the best previously reported. This work contributes novel techniques for making response surface models P(y|x) in which many elements of hyper-parameter assignment (x) are known to be irrelevant given particular values of other elements.},
author = {Bergstra, James and Bardenet, R{\'{e}}mi and Bengio, Yoshua and K{\'{e}}gl, Bal{\'{a}}zs},
file = {:C\:/Users/jjia/Documents/NIPS-2011-algorithms-for-hyper-parameter-optimization-Paper.pdf:pdf},
isbn = {9781618395993},
journal = {Advances in Neural Information Processing Systems 24: 25th Annual Conference on Neural Information Processing Systems 2011, NIPS 2011},
pages = {1--9},
title = {{Algorithms for hyper-parameter optimization}},
year = {2011}
}
@inproceedings{Liu2022,
abstract = {The "Roaring 20s" of visual recognition began with the introduction of Vision Transformers (ViTs), which quickly superseded ConvNets as the state-of-the-art image classification model. A vanilla ViT, on the other hand, faces difficulties when applied to general computer vision tasks such as object detection and semantic segmentation. It is the hierarchical Transformers (e.g., Swin Transformers) that reintroduced several ConvNet priors, making Transformers practically viable as a generic vision backbone and demonstrating remarkable performance on a wide variety of vision tasks. However, the effectiveness of such hybrid approaches is still largely credited to the intrinsic superiority of Transformers, rather than the inherent inductive biases of convolutions. In this work, we reexamine the design spaces and test the limits of what a pure ConvNet can achieve. We gradually "modernize" a standard ResNet toward the design of a vision Transformer, and discover several key components that contribute to the performance difference along the way. The outcome of this exploration is a family of pure ConvNet models dubbed ConvNeXt. Constructed entirely from standard ConvNet modules, ConvNeXts compete favorably with Transformers in terms of accuracy and scalability, achieving 87.8% ImageNet top-1 accuracy and outperforming Swin Transformers on COCO detection and ADE20K segmentation, while maintaining the simplicity and efficiency of standard ConvNets.},
archivePrefix = {arXiv},
arxivId = {2201.03545},
author = {Liu, Zhuang and Mao, Hanzi and Wu, Chao-Yuan and Feichtenhofer, Christoph and Darrell, Trevor and Xie, Saining},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/cvpr52688.2022.01167},
eprint = {2201.03545},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Liu et al. - Unknown - A ConvNet for the 2020s.pdf:pdf},
pages = {11966--11976},
title = {{A ConvNet for the 2020s}},
url = {https://github.com/facebookresearch/ConvNeXt http://arxiv.org/abs/2201.03545},
year = {2022}
}

@article{Wells2014,
abstract = {Based on international collaborative data, interstitial lung disease is now the most frequent cause of death in systemic sclerosis (SSc), having supplanted renal crisis in that regard. Despite detailed explorations of candidate mediators, no primary pathway in the pathogenesis of interstitial lung disease associated with SSc (SSc-ILD) has been definitively identified and, therefore, treatment with current agents is only partially successful. However, as immunomodulatory agents do, on average, retard progression of lung disease, early identification of SSc-ILD, using thoracic high resolution computed tomography (HRCT), is highly desirable. The decision whether to introduce therapy immediately is often difficult as the balance of risk and benefit favours a strategy of careful observation when lung disease is very limited, especially in long-standing SSc. The threshold for initiating treatment is substantially reduced when lung disease is severe, systemic disease is short in duration or ongoing progression is evident, based on pulmonary function tests and symptoms. This review summarises epidemiology, pathogenesis, difficult clinical problems and management issues in SSc-ILD.},
author = {Wells, Athol U.},
doi = {10.1016/J.LPM.2014.08.002},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wells - 2014 - Interstitial lung disease in systemic sclerosis.pdf:pdf},
issn = {0755-4982},
journal = {La Presse M{\'{e}}dicale},
month = {oct},
number = {10},
pages = {e329--e343},
pmid = {25217474},
publisher = {Elsevier Masson},
title = {{Interstitial lung disease in systemic sclerosis}},
volume = {43},
year = {2014}
}
@article{Acharya2013a,
abstract = {Systemic sclerosis (SSc) is a multisystem autoimmune connective tissue disease of unknown etiology. Pulmonary involvement is known to occur in SSc in form of progressive fibrosis and alveolitis. Pulmonary hypertension is another spectrum of involvement. We present a case of limited cutaneous scleroderma who presented with progressive dysnea and was diagnosed to have Interstitial lung disease (ILD).},
author = {Acharya, Sourya and Shukla, Samarth and Mahajan, S. N. and Banode, Pankaj and Mahure, Chetan and Mathew, Leny},
doi = {10.1164/rccm.200706-877oc},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Goh et al. - Unknown - Interstitial Lung Disease in Systemic Sclerosis a Simple Staging System Online Data Supplement.pdf:pdf},
issn = {09743901},
journal = {Journal of Datta Meghe Institute of Medical Sciences University},
keywords = {Alveolitis,Fibrosis,ILD,Systemic sclerosis},
number = {1},
pages = {57--59},
pmid = {18369202},
title = {{Interstitial lung disease in systemic sclerosis}},
volume = {8},
year = {2013}
}
@article{Wang,
abstract = {We proposed a deep learning method for inter-pretable diabetic retinopathy (DR) detection. The visual-interpretable feature of the proposed method is achieved by adding the regression activation map (RAM) after the global averaging pooling layer of the convolutional networks (CNN). With RAM, the proposed model can localize the discriminative regions of an retina image to show the specific region of interest in terms of its severity level. We believe this advantage of the proposed deep learning model is highly desired for DR detection because in practice, users are not only interested with high prediction performance, but also keen to understand the insights of DR detection and why the adopted learning model works. In the experiments conducted on a large scale of retina image dataset, we show that the proposed CNN model can achieve high performance on DR detection compared with the state-of-the-art while achieving the merits of providing the RAM to highlight the salient regions of the input image.},
archivePrefix = {arXiv},
arxivId = {1703.10757v3},
author = {Wang, Zhiguang and Yang, Jianbo},
eprint = {1703.10757v3},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Wang, Yang - Unknown - Diabetic Retinopathy Detection via Deep Convolutional Networks for Discriminative Localization and Visual Explana.pdf:pdf},
title = {{Diabetic Retinopathy Detection via Deep Convolutional Networks for Discriminative Localization and Visual Explanation}},
url = {http://www.who.int/mediacentre/factsheets/fs312/en/}
}
@inproceedings{Gonzalez2018,
abstract = {{\textcopyright} COPYRIGHT SPIE. Downloading of the abstract is permitted for personal use only. Introduction: The Agatston score is a well-established metric of cardiovascular disease related to clinical outcomes. It is computed from CT scans by a) measuring the volume and intensity of the atherosclerotic plaques and b) aggregating such information in an index. Objective: To generate a convolutional neural network that inputs a non-contrast chest CT scan and outputs the Agatston score associated with it directly, without a prior segmentation of Coronary Artery Calcifications (CAC). Materials and methods: We use a database of 5973 non-contrast non-ECG gated chest CT scans where the Agatston score has been manually computed. The heart of each scan is cropped automatically using an object detector. The database is split in 4973 cases for training and 1000 for testing. We train a 3D deep convolutional neural network to regress the Agatston score directly from the extracted hearts. Results: The proposed method yields a Pearson correlation coefficient of r = 0.93; p â¤ 0.0001 against manual reference standard in the 1000 test cases. It further stratifies correctly 72.6% of the cases with respect to standard risk groups. This compares to more complex state-of-the-art methods based on prior segmentations of the CACs, which achieve r = 0.94 in ECG-gated pulmonary CT. Conclusions: A convolutional neural network can regress the Agatston score from the image of the heart directly, without a prior segmentation of the CACs. This is a new and simpler paradigm in the Agatston score computation that yields similar results to the state-of-the-art literature.},
author = {Gonz{\'{a}}lez, Germ{\'{a}}n and Washko, George R. and Est{\'{e}}par, Ra{\'{u}}l San Jos{\'{e}} and Cazorla, Miguel and {Cano Espinosa}, Carlos},
booktitle = {Proceedings of SPIE--the International Society for Optical Engineering},
doi = {10.1117/12.2293681},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Gonz{\'{a}}lez et al. - 2018 - Automated Agatston score computation in non-ECG gated CT scans using deep learning.pdf:pdf},
isbn = {9781510616370},
issn = {0277-786X},
keywords = {Agatston score,computed aided detection,deep learning,pulmonary CT},
month = {mar},
pages = {91},
publisher = {SPIE-Intl Soc Optical Eng},
title = {{Automated Agatston score computation in non-ECG gated CT scans using deep learning}},
url = {/pmc/articles/PMC6095680/ /pmc/articles/PMC6095680/?report=abstract https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6095680/},
volume = {10574},
year = {2018}
}

@techreport{Kanavati,
abstract = {The analysis of single CT slices extracted at the third lumbar vertebra (L3) has gar-nered significant clinical interest in the past few years, in particular in regards to quantifying sarcopenia (muscle loss). In this paper, we propose an efficient method to automatically detect the L3 slice in 3D CT images. Our method works with images with a variety of fields of view, occlusions, and slice thicknesses. 3D CT images are first converted into 2D via Maximal Intensity Projection (MIP), reducing the dimensionality of the problem. The MIP images are then used as input to a 2D fully-convolutional network to predict the L3 slice locations in the form of 2D confidence maps. In addition we propose a variant architecture with less parameters allowing 1D confidence map prediction and slightly faster prediction time without loss of accuracy. Quantitative evaluation of our method on a dataset of 1006 3D CT images yields a median error of 1mm, similar to the inter-rater median error of 1mm obtained from two annotators, demonstrating the effectiveness of our method in efficiently and accurately detecting the L3 slice. Code and dataset will be made available at https://github.com/fk128/ct-slice-detection.},
archivePrefix = {arXiv},
arxivId = {1811.09244v1},
author = {Kanavati, Fahdi and Islam, Shah and Aboagye, Eric O and Rockall, Andrea},
eprint = {1811.09244v1},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kanavati et al. - Unknown - Automatic L3 slice detection in 3D CT images using fully-convolutional networks.pdf:pdf},
title = {{Automatic L3 slice detection in 3D CT images using fully-convolutional networks}},
url = {https://github.com/fk128/ct-slice-detection.}
}
@article{Chassagnon2020,
abstract = {The reported deep learningâbased method can be used to evaluate the extent of interstitial lung disease in systemic sclerosis with results comparable to those of radiologists.},
author = {Chassagnon, Guillaume and Vakalopoulou, Maria and R{\'{e}}gent, Alexis and Zacharaki, Evangelia I. and Aviram, Galit and Martin, Charlotte and Marini, Rafael and Bus, Norbert and Jerjir, Na{\"{i}}m and Mekinian, Ars{\`{e}}ne and Hua-Huy, Th{\^{o}}ng and Monnier-Cholley, Laurence and Benmostefa, Nouria and Mouthon, Luc and Dinh-Xuan, Anh-Tuan and Paragios, Nikos and Revel, Marie-Pierre},
doi = {10.1148/ryai.2020190006},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Chassagnon et al. - 2020 - Deep Learningâbased Approach for Automated Assessment of Interstitial Lung Disease in Systemic Sclerosis on C.pdf:pdf},
issn = {2638-6100},
journal = {Radiology: Artificial Intelligence},
month = {jul},
number = {4},
pages = {e190006},
publisher = {Radiological Society of North America},
title = {{Deep Learningâbased Approach for Automated Assessment of Interstitial Lung Disease in Systemic Sclerosis on CT Images}},
url = {https://pubs.rsna.org/doi/abs/10.1148/ryai.2020190006},
volume = {2},
year = {2020}
}
@article{Sogancioglu2021,
abstract = {Background: Total lung volume is an important quantitative biomarker and is used for the assessment of restrictive lung diseases. Purpose: In this study, we investigate the performance of several deep-learning approaches for automated measurement of total lung volume from chest radiographs. Methods: About 7621 posteroanterior and lateral view chest radiographs (CXR) were collected from patients with chest CT available. Similarly, 928 CXR studies were chosen from patients with pulmonary function test (PFT) results. The reference total lung volume was calculated from lung segmentation on CT or PFT data, respectively. This dataset was used to train deep-learning architectures to predict total lung volume from chest radiographs. The experiments were constructed in a stepwise fashion with increasing complexity to demonstrate the effect of training with CT-derived labels only and the sources of error. The optimal models were tested on 291 CXR studies with reference lung volume obtained from PFT. Mean absolute error (MAE), mean absolute percentage error (MAPE), and Pearson correlation coefficient (Pearson's r) were computed. Results: The optimal deep-learning regression model showed an MAE of 408 ml and an MAPE of 8.1% using both frontal and lateral chest radiographs as input. The predictions were highly correlated with the reference standard (Pearson's r = 0.92). CT-derived labels were useful for pretraining but the optimal performance was obtained by fine-tuning the network with PFT-derived labels. Conclusion: We demonstrate, for the first time, that state-of-the-art deep-learning solutions can accurately measure total lung volume from plain chest radiographs. The proposed model is made publicly available and can be used to obtain total lung volume from routinely acquired chest radiographs at no additional cost. This deep-learning system can be a useful tool to identify trends over time in patients referred regularly for chest X-ray.},
archivePrefix = {arXiv},
arxivId = {2105.01181},
author = {Sogancioglu, Ecem and Murphy, Keelin and Scholten, Ernst Th and Boulogne, Luuk H and Prokop, Mathias and van Ginneken, Bram},
doi = {10.1002/mp.15655},
eprint = {2105.01181},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Sogancioglu et al. - Unknown - Automated Estimation of Total Lung Volume using Chest Radiographs and Deep Learning.pdf:pdf},
issn = {00942405},
pmid = {35388486},
title = {{Automated Estimation of Total Lung Volume using Chest Radiographs and Deep Learning}},
url = {http://arxiv.org/abs/2105.01181},
year = {2021}
}
@article{Shadmi2018,
abstract = {The amount of calcium deposits in the coronary arteries is an important biomarker of cardiovascular disease. Coronary calcium has traditionally been quantified as an Agatston score using ECG-synchronized cardiac CT. Coronary calcium is rarely quantified from general chest CT scans, of which nearly 10 Million are performed in the US annually. We present an automatic method based on fully-convolutional deep neural network to segment coronary calcium and predict Agatston score from any non-contrast chest CT. We experimented with an internal dataset acquired through partnership with a large health organization in Israel. The dataset is composed of 1054 Chest CTs and reflects a variety of originating institutions, acquisition devices and manufacturers. In comparison to expert manual annotations, our algorithm achieved a Pearson correlation coefficient of 0.98. Bland-Altman analysis demonstrated a bias of 0.4 with 95% limits of agreement of [-189.9-190.7]). Our linearly weighted Kappa results are 0.89 for Agatston risk category assignment. We also applied our method on a very large (14,365 subjects) cohort from the National Lung Screening Trial (NLST). We demonstrate correlation of the algorithm predictions with cardiovascular-related clinical outcomes.},
author = {Shadmi, Ran and Mazo, Victoria and Bregman-Amitai, Orna and Elnekave, Eldad},
doi = {10.1109/ISBI.2018.8363515},
file = {:C\:/Users/jjia/Downloads/isbi-2018-final-041118_7.pdf:pdf},
journal = {Proceedings - International Symposium on Biomedical Imaging},
keywords = {Agatston score,Chest CT,Computer aided diagnosis,Coronary calcium,Deep learning,Segmentation},
month = {may},
pages = {24--28},
publisher = {IEEE Computer Society},
title = {{Fully-convolutional deep-learning based system for coronary calcium score prediction from non-contrast chest CT}},
volume = {2018-April},
year = {2018}
}
@article{Kim2023,
abstract = {Background Total lung capacity (TLC) has been estimated with use of chest radiographs based on time-consuming methods, such as planimetric techniques and manual measurements. Purpose To develop a deep learning-based, multidimensional model capable of estimating TLC from chest radiographs and demographic variables and validate its technical performance and clinical utility with use of multicenter retrospective data sets. Materials and Methods A deep learning model was pretrained with use of 50â000 consecutive chest CT scans performed between January 2015 and June 2017. The model was fine-tuned on 3523 pairs of posteroanterior chest radiographs and plethysmographic TLC measurements from consecutive patients who underwent pulmonary function testing on the same day. The model was tested with multicenter retrospective data sets from two tertiary care centers and one community hospital, including (a) an external test set 1 (n = 207) and external test set 2 (n = 216) for technical performance and (b) patients with idiopathic pulmonary fibrosis (n = 217) for clinical utility. Technical performance was evaluated with use of various agreement measures, and clinical utility was assessed in terms of the prognostic value for overall survival with use of multivariable Cox regression. Results The mean absolute difference and within-subject SD between observed and estimated TLC were 0.69 L and 0.73 L, respectively, in the external test set 1 (161 men; median age, 70 years [IQR: 61-76 years]) and 0.52 L and 0.53 L in the external test set 2 (113 men; median age, 63 years [IQR: 51-70 years]). In patients with idiopathic pulmonary fibrosis (145 men; median age, 67 years [IQR: 61-73 years]), greater estimated TLC percentage was associated with lower mortality risk (adjusted hazard ratio, 0.97 per percent; 95% CI: 0.95, 0.98; P < .001). Conclusion A fully automatic, deep learning-based model estimated total lung capacity from chest radiographs, and the model predicted survival in idiopathic pulmonary fibrosis. {\textcopyright} RSNA, 2022 Online supplemental material is available for this article. See also the editorial by Sorkness in this issue.},
author = {Kim, Hyungjin and Jin, Kwang Nam and Yoo, Seung Jin and Lee, Chang Hoon and Lee, Sang Min and Hong, Hyunsook and Witanto, Joseph Nathanael and Yoon, Soon Ho},
doi = {10.1148/RADIOL.220292/ASSET/IMAGES/LARGE/RADIOL.220292.TBL4.JPEG},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Kim et al. - 2023 - Deep Learning for Estimating Lung Capacity on Chest Radiographs Predicts Survival in Idiopathic Pulmonary Fibrosis.pdf:pdf},
issn = {15271315},
journal = {Radiology},
month = {mar},
number = {3},
pages = {e220292},
pmid = {36283113},
publisher = {NLM (Medline)},
title = {{Deep Learning for Estimating Lung Capacity on Chest Radiographs Predicts Survival in Idiopathic Pulmonary Fibrosis}},
url = {https://pubs.rsna.org/doi/10.1148/radiol.220292},
volume = {306},
year = {2023}
}

@article{Dubost,
abstract = {Enlarged perivascular spaces (EPVS) in the brain are an emerging imaging marker for cerebral small vessel disease, and have been shown to be related to increased risk of various neurological diseases, including stroke and dementia. Automated quantification of EPVS would greatly help to advance research into its etiology and its potential as a risk indicator of disease. We propose a convolutional network regression method to quantify the extent of EPVS in the basal ganglia from 3D brain MRI. We first segment the basal ganglia and subsequently apply a 3D convolutional regression network designed for small object detection within this region of interest. The network takes an image as input, and outputs a quantification score of EPVS. The network has significantly more convolution operations than pooling ones and no final activation, allowing it to span the space of real numbers. We validated our approach using a dataset of 2000 brain MRI scans scored visually. Experiments with varying sizes of training and test sets showed that a good performance can be achieved with a training set of only 200 scans. With a training set of 1000 scans, the intraclass correlation coefficient (ICC) between our scoring method and the expert's visual score was 0.74. Our method outperforms by a large margin-more than 0.10-four more conventional automated approaches based on intensities, scale-invariant feature transform, and random forest. We show that the network learns the structures of interest and investigate the influence of hyper-parameters on the performance. We also evaluate the reproducibility of our network using a set of 60 subjects scanned twice (scan-rescan reproducibility). On this set our network achieves an ICC of 0.93, while the intrarater agreement reaches 0.80. Furthermore, the automated EPVS scoring correlates similarly to age as visual scoring.},
archivePrefix = {arXiv},
arxivId = {1802.05914v2},
author = {Dubost, Florian and Adams, Hieab and Bortsova, Gerda and {Arfan Ikram}, M and Niessen, Wiro and Vernooij, Meike and {De Bruijne}, Marleen},
eprint = {1802.05914v2},
file = {:C\:/Users/jjia/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dubost et al. - Unknown - 3D Regression Neural Network for the Quantification of Enlarged Perivascular Spaces in Brain MRI.pdf:pdf},
keywords = {Deep learning,Dementia,Perivascular space,Regression,Virchow-Robin space,Weak labels},
title = {{3D Regression Neural Network for the Quantification of Enlarged Perivascular Spaces in Brain MRI}}
}

